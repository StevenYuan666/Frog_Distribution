{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml5R-mCvYZWi"
   },
   "source": [
    "Frog Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7ixJtvsnYVVJ"
   },
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Geospatial\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "import zarr # Not referenced, but required for xarray\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import fsspec\n",
    "import pystac\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import zipfile\n",
    "from itertools import cycle\n",
    "\n",
    "# Path to data folder with provided material\n",
    "data_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Z3YaIMD0Yj4S"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path+'training_data/'):\n",
    "    os.mkdir(data_path+'training_data/')\n",
    "    with zipfile.ZipFile(data_path+'Level_1_GBIF_training_data.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path+'training_data/')\n",
    "        \n",
    "def filter_bbox(frogs, bbox):\n",
    "    frogs = frogs[lambda x: \n",
    "        (x.decimalLongitude >= bbox[0]) &\n",
    "        (x.decimalLatitude >= bbox[1]) &\n",
    "        (x.decimalLongitude <= bbox[2]) &\n",
    "        (x.decimalLatitude <= bbox[3])\n",
    "    ]\n",
    "    return frogs\n",
    "\n",
    "def get_frogs(file, year_range=None, bbox=None):\n",
    "    \"\"\"Returns the dataframe of all frog occurrences for the bounding box specified.\"\"\"\n",
    "    columns = [\n",
    "        'gbifID','eventDate','country','continent','stateProvince',\n",
    "        'decimalLatitude','decimalLongitude','species'\n",
    "    ]\n",
    "    country_names = {\n",
    "        'AU':'Australia', 'CR':'Costa Rica', 'ZA':'South Africa','MX':'Mexico','HN':'Honduras',\n",
    "        'MZ':'Mozambique','BW':'Botswana','MW':'Malawi','CO':'Colombia','PA':'Panama','NI':'Nicaragua',\n",
    "        'BZ':'Belize','ZW':'Zimbabwe','SZ':'Eswatini','ZM':'Zambia','GT':'Guatemala','LS':'Lesotho',\n",
    "        'SV':'El Salvador', 'AO':'Angola', np.nan:'unknown or invalid'\n",
    "    }\n",
    "    continent_names = {\n",
    "        'AU':'Australia', 'CR':'Central America', 'ZA':'Africa','MX':'Central America','HN':'Central America',\n",
    "        'MZ':'Africa','BW':'Africa','MW':'Africa','CO':'Central America','PA':'Central America',\n",
    "        'NI':'Central America','BZ':'Central America','ZW':'Africa','SZ':'Africa','ZM':'Africa',\n",
    "        'GT':'Central America','LS':'Africa','SV':'Central America','AO':'Africa', np.nan:'unknown or invalid' \n",
    "    }\n",
    "    frogs = (\n",
    "        pd.read_csv(data_path+'training_data/occurrence.txt', sep='\\t', parse_dates=['eventDate'])\n",
    "        .assign(\n",
    "            country =  lambda x: x.countryCode.map(country_names),\n",
    "            continent =  lambda x: x.countryCode.map(continent_names),\n",
    "            species = lambda x: x.species.str.title()\n",
    "        )\n",
    "        [columns]\n",
    "    )\n",
    "    if year_range is not None:\n",
    "        frogs = frogs[lambda x: \n",
    "            (x.eventDate.dt.year >= year_range[0]) & \n",
    "            (x.eventDate.dt.year <= year_range[1])\n",
    "        ]\n",
    "    if bbox is not None:\n",
    "        frogs = filter_bbox(frogs, bbox)\n",
    "    return frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xMdyz-uzYnAd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbifID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>stateProvince</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>3108894201</td>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.699881</td>\n",
       "      <td>151.043367</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>3108882429</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.955790</td>\n",
       "      <td>150.976815</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>3108953063</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.755278</td>\n",
       "      <td>150.623221</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>3108952573</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.755291</td>\n",
       "      <td>150.623651</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>1452200212</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.951844</td>\n",
       "      <td>150.870430</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193471</th>\n",
       "      <td>3108863070</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.474900</td>\n",
       "      <td>150.172000</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193473</th>\n",
       "      <td>3108900314</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.789908</td>\n",
       "      <td>151.131394</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193476</th>\n",
       "      <td>3108938525</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.757622</td>\n",
       "      <td>150.618240</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193477</th>\n",
       "      <td>3108845537</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.718800</td>\n",
       "      <td>150.385000</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193735</th>\n",
       "      <td>1653525892</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.767500</td>\n",
       "      <td>151.117917</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gbifID  eventDate    country  continent    stateProvince  \\\n",
       "935     3108894201 2017-11-12  Australia  Australia  New South Wales   \n",
       "941     3108882429 2019-09-19  Australia  Australia  New South Wales   \n",
       "944     3108953063 2019-11-03  Australia  Australia  New South Wales   \n",
       "945     3108952573 2019-11-04  Australia  Australia  New South Wales   \n",
       "980     1452200212 2015-06-16  Australia  Australia  New South Wales   \n",
       "...            ...        ...        ...        ...              ...   \n",
       "193471  3108863070 2018-11-13  Australia  Australia  New South Wales   \n",
       "193473  3108900314 2019-10-30  Australia  Australia  New South Wales   \n",
       "193476  3108938525 2018-10-17  Australia  Australia  New South Wales   \n",
       "193477  3108845537 2019-10-15  Australia  Australia  New South Wales   \n",
       "193735  1653525892 2015-09-15  Australia  Australia  New South Wales   \n",
       "\n",
       "        decimalLatitude  decimalLongitude           species  \n",
       "935          -33.699881        151.043367    Litoria Fallax  \n",
       "941          -33.955790        150.976815  Crinia Signifera  \n",
       "944          -33.755278        150.623221    Litoria Fallax  \n",
       "945          -33.755291        150.623651    Litoria Fallax  \n",
       "980          -33.951844        150.870430    Litoria Fallax  \n",
       "...                 ...               ...               ...  \n",
       "193471       -33.474900        150.172000  Crinia Signifera  \n",
       "193473       -33.789908        151.131394    Litoria Fallax  \n",
       "193476       -33.757622        150.618240    Litoria Fallax  \n",
       "193477       -33.718800        150.385000  Crinia Signifera  \n",
       "193735       -33.767500        151.117917  Crinia Signifera  \n",
       "\n",
       "[9418 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the bounding box for Greater Sydney, NSW\n",
    "region_name = 'Greater Sydney, NSW'\n",
    "min_lon, min_lat = (150.15, -34.25)  # Lower-left corner\n",
    "max_lon, max_lat = (151.15, -33.25)  # Upper-right corner\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# Load in data\n",
    "all_frog_data = get_frogs(data_path+'/training_data/occurrence.txt', year_range=(2015, 2019), bbox=bbox)\n",
    "all_frog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbifID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>stateProvince</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>species</th>\n",
       "      <th>occurrenceStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>3108894201</td>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.699881</td>\n",
       "      <td>151.043367</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>3108882429</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.955790</td>\n",
       "      <td>150.976815</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>3108953063</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.755278</td>\n",
       "      <td>150.623221</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>3108952573</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.755291</td>\n",
       "      <td>150.623651</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>1452200212</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.951844</td>\n",
       "      <td>150.870430</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193471</th>\n",
       "      <td>3108863070</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.474900</td>\n",
       "      <td>150.172000</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193473</th>\n",
       "      <td>3108900314</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.789908</td>\n",
       "      <td>151.131394</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193476</th>\n",
       "      <td>3108938525</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.757622</td>\n",
       "      <td>150.618240</td>\n",
       "      <td>Litoria Fallax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193477</th>\n",
       "      <td>3108845537</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.718800</td>\n",
       "      <td>150.385000</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193735</th>\n",
       "      <td>1653525892</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.767500</td>\n",
       "      <td>151.117917</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9418 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gbifID  eventDate    country  continent    stateProvince  \\\n",
       "935     3108894201 2017-11-12  Australia  Australia  New South Wales   \n",
       "941     3108882429 2019-09-19  Australia  Australia  New South Wales   \n",
       "944     3108953063 2019-11-03  Australia  Australia  New South Wales   \n",
       "945     3108952573 2019-11-04  Australia  Australia  New South Wales   \n",
       "980     1452200212 2015-06-16  Australia  Australia  New South Wales   \n",
       "...            ...        ...        ...        ...              ...   \n",
       "193471  3108863070 2018-11-13  Australia  Australia  New South Wales   \n",
       "193473  3108900314 2019-10-30  Australia  Australia  New South Wales   \n",
       "193476  3108938525 2018-10-17  Australia  Australia  New South Wales   \n",
       "193477  3108845537 2019-10-15  Australia  Australia  New South Wales   \n",
       "193735  1653525892 2015-09-15  Australia  Australia  New South Wales   \n",
       "\n",
       "        decimalLatitude  decimalLongitude           species  occurrenceStatus  \n",
       "935          -33.699881        151.043367    Litoria Fallax                 1  \n",
       "941          -33.955790        150.976815  Crinia Signifera                 0  \n",
       "944          -33.755278        150.623221    Litoria Fallax                 1  \n",
       "945          -33.755291        150.623651    Litoria Fallax                 1  \n",
       "980          -33.951844        150.870430    Litoria Fallax                 1  \n",
       "...                 ...               ...               ...               ...  \n",
       "193471       -33.474900        150.172000  Crinia Signifera                 0  \n",
       "193473       -33.789908        151.131394    Litoria Fallax                 1  \n",
       "193476       -33.757622        150.618240    Litoria Fallax                 1  \n",
       "193477       -33.718800        150.385000  Crinia Signifera                 0  \n",
       "193735       -33.767500        151.117917  Crinia Signifera                 0  \n",
       "\n",
       "[9418 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_species = 'Litoria Fallax'\n",
    "\n",
    "all_frog_data = (\n",
    "    all_frog_data\n",
    "    # Assign the occurrenceStatus to 1 for the target species and 0 for all other species.\n",
    "    # as well as a key for joining (later)\n",
    "    .assign(\n",
    "        occurrenceStatus = lambda x: np.where(x.species == target_species, 1, 0)\n",
    "    )\n",
    ")\n",
    "all_frog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DvVT6q92YY8o"
   },
   "outputs": [],
   "source": [
    "target_species_frog_data = all_frog_data[all_frog_data.occurrenceStatus == 1]\n",
    "frog_data = (\n",
    "    all_frog_data\n",
    "    [lambda x: x.occurrenceStatus == 0]\n",
    "    .sample(\n",
    "        len(target_species_frog_data), random_state=420\n",
    "    )\n",
    "    .append(target_species_frog_data)\n",
    "    # assign key for joining purposes\n",
    "    .reset_index(drop=True)\n",
    "    .assign(key=lambda x: x.index)\n",
    ")\n",
    "# Bar charts\n",
    "bar_data = all_frog_data.occurrenceStatus.map({1:'Present', 0:'Absent'}).value_counts()\n",
    "balanced_bar_data = frog_data.occurrenceStatus.map({1:'Present', 0:'Absent'}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4AQoyqkgaURj"
   },
   "outputs": [],
   "source": [
    "def get_terraclimate(bbox, metrics, time_slice=None, assets=None, features=None, interp_dims=None, verbose=True):\n",
    "    \"\"\"Returns terraclimate metrics for a given area, allowing results to be interpolated onto a larger image.\n",
    "    \n",
    "    Attributes:\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    metrics -- Nested dictionary in the form {<metric_name>:{'fn':<metric_function>,'params':<metric_kwargs_dict>}, ... }\n",
    "    time_slice -- Tuple of datetime strings to select data between, e.g. ('2015-01-01','2019-12-31')\n",
    "    assets -- list of terraclimate assets to take\n",
    "    features -- list of asset metrics to take, specified by strings in the form '<asset_name>_<metric_name>'\n",
    "    interp_dims -- Tuple of dimensions (n, m) to interpolate results to\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    collection = pystac.read_file(\"https://planetarycomputer.microsoft.com/api/stac/v1/collections/terraclimate\")\n",
    "    asset = collection.assets[\"zarr-https\"]\n",
    "    store = fsspec.get_mapper(asset.href)\n",
    "    data = xr.open_zarr(store, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    \n",
    "    # Select datapoints that overlap region\n",
    "    if time_slice is not None:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat),time=slice(time_slice[0],time_slice[1]))\n",
    "    else:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat))\n",
    "    if assets is not None:\n",
    "        data = data[assets]\n",
    "    print('Loading data') if verbose else None\n",
    "    data = data.rename(lat='y', lon='x').to_array().compute()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    combined_values = []\n",
    "    combined_bands = []\n",
    "    for name, metric in metrics.items():\n",
    "        print(f'Calculating {name}') if verbose else None\n",
    "        sum_data = xr.apply_ufunc(\n",
    "            metric['fn'], data, input_core_dims=[[\"time\"]], kwargs=metric['params'], dask = 'allowed', vectorize = True\n",
    "        ).rename(variable='band')\n",
    "        xcoords = sum_data.x\n",
    "        ycoords = sum_data.y\n",
    "        dims = sum_data.dims\n",
    "        combined_values.append(sum_data.values)\n",
    "        for band in sum_data.band.values:\n",
    "            combined_bands.append(band+'_'+name)\n",
    "        \n",
    "    # Combine metrics\n",
    "    combined_values = np.concatenate(\n",
    "        combined_values,\n",
    "        axis=0\n",
    "    )\n",
    "    combined_data = xr.DataArray(\n",
    "        data=combined_values,\n",
    "        dims=dims,\n",
    "        coords=dict(\n",
    "            band=combined_bands,\n",
    "            y=ycoords,\n",
    "            x=xcoords\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    # Take relevant bands:\n",
    "    combined_data = combined_data.sel(band=features)\n",
    "    \n",
    "    if interp_dims is not None:\n",
    "        print(f'Interpolating image') if verbose else None\n",
    "        interp_coords = (np.linspace(bbox[0], bbox[2], interp_dims[0]), np.linspace(bbox[1], bbox[3], interp_dims[1]))\n",
    "        combined_data = combined_data.interp(x=interp_coords[0], y=interp_coords[1], method='nearest', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2tai6frpaZq7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Calculating mean\n",
      "Calculating min\n",
      "Calculating max\n",
      "Interpolating image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['tmax_mean', 'tmin_mean', 'ppt_mean', 'soil_mean'], dtype='<U9')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics to measure over time dimension\n",
    "tc_metrics = {\n",
    "    'mean':{\n",
    "        'fn':np.nanmean,\n",
    "        'params':{}\n",
    "    },\n",
    "    'min':{\n",
    "        'fn':np.nanmin,\n",
    "        'params':{}\n",
    "    },\n",
    "    'max':{\n",
    "        'fn':np.nanmax,\n",
    "        'params':{}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Date range to take\n",
    "time_slice = ('2015-01-01','2019-12-31')\n",
    "\n",
    "# Measurements to take\n",
    "assets=['tmax', 'tmin', 'ppt', 'soil']\n",
    "\n",
    "# Features to take, in form '<asset>_<metric>'\n",
    "features=['tmax_mean', 'tmin_mean', 'ppt_mean', 'soil_mean']\n",
    "\n",
    "# Interpolate values to a 512x512 image\n",
    "interp_dims = (512, 512)\n",
    "\n",
    "weather_data = get_terraclimate(bbox, tc_metrics, time_slice=time_slice, assets=assets, features=features, interp_dims=interp_dims)\n",
    "display(weather_data.band.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IKjoy5JKawdn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbifID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>stateProvince</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>species</th>\n",
       "      <th>occurrenceStatus</th>\n",
       "      <th>key</th>\n",
       "      <th>ppt_mean</th>\n",
       "      <th>soil_mean</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmin_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3463704693</td>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.466600</td>\n",
       "      <td>150.185000</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.349998</td>\n",
       "      <td>65.083336</td>\n",
       "      <td>17.966669</td>\n",
       "      <td>7.081669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3463455363</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.833166</td>\n",
       "      <td>151.014700</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.383331</td>\n",
       "      <td>50.116665</td>\n",
       "      <td>24.088335</td>\n",
       "      <td>13.050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3463662977</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.714100</td>\n",
       "      <td>151.143000</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>96.599998</td>\n",
       "      <td>74.966667</td>\n",
       "      <td>23.010002</td>\n",
       "      <td>12.643335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2806506373</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.907400</td>\n",
       "      <td>150.833720</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>63.183334</td>\n",
       "      <td>44.816666</td>\n",
       "      <td>24.073334</td>\n",
       "      <td>11.728335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3463505407</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.759766</td>\n",
       "      <td>151.113259</td>\n",
       "      <td>Crinia Signifera</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>84.050003</td>\n",
       "      <td>65.483330</td>\n",
       "      <td>23.581669</td>\n",
       "      <td>13.054999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gbifID  eventDate    country  continent    stateProvince  \\\n",
       "0  3463704693 2019-11-10  Australia  Australia  New South Wales   \n",
       "1  3463455363 2018-10-08  Australia  Australia  New South Wales   \n",
       "2  3463662977 2018-11-04  Australia  Australia  New South Wales   \n",
       "3  2806506373 2016-07-15  Australia  Australia  New South Wales   \n",
       "4  3463505407 2018-12-21  Australia  Australia  New South Wales   \n",
       "\n",
       "   decimalLatitude  decimalLongitude           species  occurrenceStatus  key  \\\n",
       "0       -33.466600        150.185000  Crinia Signifera                 0    0   \n",
       "1       -33.833166        151.014700  Crinia Signifera                 0    1   \n",
       "2       -33.714100        151.143000  Crinia Signifera                 0    2   \n",
       "3       -33.907400        150.833720  Crinia Signifera                 0    3   \n",
       "4       -33.759766        151.113259  Crinia Signifera                 0    4   \n",
       "\n",
       "    ppt_mean  soil_mean  tmax_mean  tmin_mean  \n",
       "0  73.349998  65.083336  17.966669   7.081669  \n",
       "1  70.383331  50.116665  24.088335  13.050002  \n",
       "2  96.599998  74.966667  23.010002  12.643335  \n",
       "3  63.183334  44.816666  24.073334  11.728335  \n",
       "4  84.050003  65.483330  23.581669  13.054999  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_frogs(frogs, data):\n",
    "    \"\"\"Collects the data for each frog location and joins it onto the frog data \n",
    "\n",
    "    Arguments:\n",
    "    frogs -- dataframe containing the response variable along with [\"decimalLongitude\", \"decimalLatitude\", \"key\"]\n",
    "    data -- xarray dataarray of features, indexed with geocoordinates\n",
    "    \"\"\"\n",
    "    return frogs.merge(\n",
    "        (\n",
    "            data\n",
    "            .rename('data')\n",
    "            .sel(\n",
    "                x=xr.DataArray(frog_data.decimalLongitude, dims=\"key\", coords={\"key\": frog_data.key}), \n",
    "                y=xr.DataArray(frog_data.decimalLatitude, dims=\"key\", coords={\"key\": frog_data.key}),\n",
    "                method=\"nearest\"\n",
    "            )\n",
    "            .to_dataframe()\n",
    "            .assign(val = lambda x: x.iloc[:, -1])\n",
    "            [['val']]\n",
    "            .reset_index()\n",
    "            .drop_duplicates()\n",
    "            .pivot(index=\"key\", columns=\"band\", values=\"val\")\n",
    "            .reset_index()\n",
    "        ),\n",
    "        on = ['key'],\n",
    "        how = 'inner'\n",
    "    )\n",
    "    \n",
    "model_data = join_frogs(frog_data, weather_data)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "m1ne1IImay_V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model = LogisticRegression()\n",
    "# Separate the predictor variables from the response\n",
    "X = (\n",
    "    model_data\n",
    "    .drop(['gbifID', 'eventDate', 'decimalLatitude', 'decimalLongitude', 'species',\n",
    "       'country', 'continent', 'stateProvince', 'occurrenceStatus', 'key'], 1)\n",
    ")\n",
    "y = model_data.occurrenceStatus.astype(int)\n",
    "\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(X, y, test_size=0.2, random_state=207)\n",
    "\n",
    "# Fit model\n",
    "full_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "H7oIr2Svaz9W"
   },
   "outputs": [],
   "source": [
    "train_predictions = full_model.predict(train_x)\n",
    "validation_predictions = full_model.predict(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.67\n",
      "Training Accuracy: 0.64\n",
      "Validation F1 Score: 0.7\n",
      "Validation Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training F1 Score: {np.mean(f1_score(train_y, train_predictions)).round(2)}\")\n",
    "print(f\"Training Accuracy: {np.mean(accuracy_score(train_y, train_predictions)).round(2)}\")\n",
    "print(f\"Validation F1 Score: {np.mean(f1_score(validation_y, validation_predictions)).round(2)}\")\n",
    "print(f\"Validation Accuracy: {np.mean(accuracy_score(validation_y, validation_predictions)).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(4,)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.7860 - accuracy: 0.5892 - val_loss: 0.6393 - val_accuracy: 0.6470\n",
      "Epoch 2/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.6207 - accuracy: 0.6467 - val_loss: 0.6046 - val_accuracy: 0.6604\n",
      "Epoch 3/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.6054 - accuracy: 0.6577 - val_loss: 0.5826 - val_accuracy: 0.6703\n",
      "Epoch 4/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5951 - accuracy: 0.6613 - val_loss: 0.5706 - val_accuracy: 0.6756\n",
      "Epoch 5/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5875 - accuracy: 0.6703 - val_loss: 0.5692 - val_accuracy: 0.6461\n",
      "Epoch 6/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.6770 - val_loss: 0.5759 - val_accuracy: 0.6532\n",
      "Epoch 7/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.6776 - val_loss: 0.5727 - val_accuracy: 0.6703\n",
      "Epoch 8/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5757 - accuracy: 0.6794 - val_loss: 0.5661 - val_accuracy: 0.6461\n",
      "Epoch 9/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.6783 - val_loss: 0.5607 - val_accuracy: 0.6819\n",
      "Epoch 10/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5776 - accuracy: 0.6830 - val_loss: 0.5545 - val_accuracy: 0.6667\n",
      "Epoch 11/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5772 - accuracy: 0.6792 - val_loss: 0.5526 - val_accuracy: 0.6658\n",
      "Epoch 12/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5722 - accuracy: 0.6862 - val_loss: 0.5704 - val_accuracy: 0.6846\n",
      "Epoch 13/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5699 - accuracy: 0.6821 - val_loss: 0.5586 - val_accuracy: 0.6819\n",
      "Epoch 14/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5659 - accuracy: 0.6913 - val_loss: 0.5599 - val_accuracy: 0.6756\n",
      "Epoch 15/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5641 - accuracy: 0.6924 - val_loss: 0.5592 - val_accuracy: 0.6747\n",
      "Epoch 16/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5637 - accuracy: 0.6884 - val_loss: 0.5538 - val_accuracy: 0.7043\n",
      "Epoch 17/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5580 - accuracy: 0.6962 - val_loss: 0.5451 - val_accuracy: 0.6882\n",
      "Epoch 18/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.6951 - val_loss: 0.5503 - val_accuracy: 0.7097\n",
      "Epoch 19/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5545 - accuracy: 0.6960 - val_loss: 0.5407 - val_accuracy: 0.7133\n",
      "Epoch 20/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.6976 - val_loss: 0.5326 - val_accuracy: 0.7168\n",
      "Epoch 21/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.6960 - val_loss: 0.5336 - val_accuracy: 0.7115\n",
      "Epoch 22/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5518 - accuracy: 0.6983 - val_loss: 0.5337 - val_accuracy: 0.7222\n",
      "Epoch 23/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7047 - val_loss: 0.5290 - val_accuracy: 0.7097\n",
      "Epoch 24/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7030 - val_loss: 0.5252 - val_accuracy: 0.7276\n",
      "Epoch 25/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5476 - accuracy: 0.7014 - val_loss: 0.5218 - val_accuracy: 0.7294\n",
      "Epoch 26/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7014 - val_loss: 0.5249 - val_accuracy: 0.7177\n",
      "Epoch 27/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7039 - val_loss: 0.5230 - val_accuracy: 0.7133\n",
      "Epoch 28/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7041 - val_loss: 0.5201 - val_accuracy: 0.7213\n",
      "Epoch 29/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7081 - val_loss: 0.5208 - val_accuracy: 0.7159\n",
      "Epoch 30/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7095 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 31/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7041 - val_loss: 0.5157 - val_accuracy: 0.7106\n",
      "Epoch 32/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7063 - val_loss: 0.5181 - val_accuracy: 0.7070\n",
      "Epoch 33/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7121 - val_loss: 0.5220 - val_accuracy: 0.7061\n",
      "Epoch 34/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7135 - val_loss: 0.5184 - val_accuracy: 0.7106\n",
      "Epoch 35/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5314 - accuracy: 0.7202 - val_loss: 0.5161 - val_accuracy: 0.7007\n",
      "Epoch 36/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5307 - accuracy: 0.7155 - val_loss: 0.5151 - val_accuracy: 0.7079\n",
      "Epoch 37/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7202 - val_loss: 0.5156 - val_accuracy: 0.7204\n",
      "Epoch 38/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7193 - val_loss: 0.5137 - val_accuracy: 0.7177\n",
      "Epoch 39/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.7198 - val_loss: 0.5125 - val_accuracy: 0.7231\n",
      "Epoch 40/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.7254 - val_loss: 0.5188 - val_accuracy: 0.7133\n",
      "Epoch 41/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.7265 - val_loss: 0.5116 - val_accuracy: 0.7133\n",
      "Epoch 42/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.7224 - val_loss: 0.5119 - val_accuracy: 0.7124\n",
      "Epoch 43/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7251 - val_loss: 0.5103 - val_accuracy: 0.7213\n",
      "Epoch 44/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7263 - val_loss: 0.5076 - val_accuracy: 0.7133\n",
      "Epoch 45/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7265 - val_loss: 0.5071 - val_accuracy: 0.7231\n",
      "Epoch 46/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7280 - val_loss: 0.5088 - val_accuracy: 0.7195\n",
      "Epoch 47/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7265 - val_loss: 0.5086 - val_accuracy: 0.7249\n",
      "Epoch 48/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5246 - accuracy: 0.7267 - val_loss: 0.5105 - val_accuracy: 0.7294\n",
      "Epoch 49/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7307 - val_loss: 0.5107 - val_accuracy: 0.7195\n",
      "Epoch 50/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5241 - accuracy: 0.7274 - val_loss: 0.5056 - val_accuracy: 0.7339\n",
      "Epoch 51/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7301 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 52/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7292 - val_loss: 0.5057 - val_accuracy: 0.7384\n",
      "Epoch 53/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.5247 - accuracy: 0.7305 - val_loss: 0.5079 - val_accuracy: 0.7276\n",
      "Epoch 54/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7287 - val_loss: 0.5048 - val_accuracy: 0.7249\n",
      "Epoch 55/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7292 - val_loss: 0.5090 - val_accuracy: 0.7177\n",
      "Epoch 56/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7303 - val_loss: 0.5108 - val_accuracy: 0.7240\n",
      "Epoch 57/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7310 - val_loss: 0.5042 - val_accuracy: 0.7213\n",
      "Epoch 58/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7319 - val_loss: 0.5075 - val_accuracy: 0.7518\n",
      "Epoch 59/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7328 - val_loss: 0.5072 - val_accuracy: 0.7267\n",
      "Epoch 60/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7312 - val_loss: 0.5096 - val_accuracy: 0.7321\n",
      "Epoch 61/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7303 - val_loss: 0.5061 - val_accuracy: 0.7240\n",
      "Epoch 62/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.7348 - val_loss: 0.5034 - val_accuracy: 0.7267\n",
      "Epoch 63/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7375 - val_loss: 0.5067 - val_accuracy: 0.7357\n",
      "Epoch 64/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7354 - val_loss: 0.5047 - val_accuracy: 0.7240\n",
      "Epoch 65/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7363 - val_loss: 0.5037 - val_accuracy: 0.7258\n",
      "Epoch 66/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7366 - val_loss: 0.5056 - val_accuracy: 0.7285\n",
      "Epoch 67/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7345 - val_loss: 0.5046 - val_accuracy: 0.7410\n",
      "Epoch 68/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7375 - val_loss: 0.5059 - val_accuracy: 0.7473\n",
      "Epoch 69/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5166 - accuracy: 0.7401 - val_loss: 0.5089 - val_accuracy: 0.7455\n",
      "Epoch 70/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7397 - val_loss: 0.5130 - val_accuracy: 0.7294\n",
      "Epoch 71/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7321 - val_loss: 0.5083 - val_accuracy: 0.7312\n",
      "Epoch 72/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7339 - val_loss: 0.5060 - val_accuracy: 0.7428\n",
      "Epoch 73/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7345 - val_loss: 0.5089 - val_accuracy: 0.7455\n",
      "Epoch 74/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.7359 - val_loss: 0.5070 - val_accuracy: 0.7428\n",
      "Epoch 75/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.7339 - val_loss: 0.5112 - val_accuracy: 0.7482\n",
      "Epoch 76/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7343 - val_loss: 0.5095 - val_accuracy: 0.7437\n",
      "Epoch 77/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7341 - val_loss: 0.5118 - val_accuracy: 0.7446\n",
      "Epoch 78/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7287 - val_loss: 0.5033 - val_accuracy: 0.7509\n",
      "Epoch 79/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5280 - accuracy: 0.7294 - val_loss: 0.4986 - val_accuracy: 0.7545\n",
      "Epoch 80/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7321 - val_loss: 0.4950 - val_accuracy: 0.7509\n",
      "Epoch 81/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7336 - val_loss: 0.4949 - val_accuracy: 0.7285\n",
      "Epoch 82/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7388 - val_loss: 0.4943 - val_accuracy: 0.7581\n",
      "Epoch 83/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7399 - val_loss: 0.4952 - val_accuracy: 0.7339\n",
      "Epoch 84/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7406 - val_loss: 0.4965 - val_accuracy: 0.7392\n",
      "Epoch 85/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7419 - val_loss: 0.4952 - val_accuracy: 0.7357\n",
      "Epoch 86/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7444 - val_loss: 0.4941 - val_accuracy: 0.7384\n",
      "Epoch 87/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5139 - accuracy: 0.7408 - val_loss: 0.4931 - val_accuracy: 0.7419\n",
      "Epoch 88/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5119 - accuracy: 0.7437 - val_loss: 0.4969 - val_accuracy: 0.7366\n",
      "Epoch 89/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7440 - val_loss: 0.4971 - val_accuracy: 0.7455\n",
      "Epoch 90/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5101 - accuracy: 0.7440 - val_loss: 0.4984 - val_accuracy: 0.7482\n",
      "Epoch 91/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.7462 - val_loss: 0.4943 - val_accuracy: 0.7419\n",
      "Epoch 92/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7475 - val_loss: 0.4926 - val_accuracy: 0.7608\n",
      "Epoch 93/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7469 - val_loss: 0.4956 - val_accuracy: 0.7527\n",
      "Epoch 94/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7475 - val_loss: 0.4945 - val_accuracy: 0.7509\n",
      "Epoch 95/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7457 - val_loss: 0.4958 - val_accuracy: 0.7625\n",
      "Epoch 96/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5090 - accuracy: 0.7462 - val_loss: 0.4975 - val_accuracy: 0.7616\n",
      "Epoch 97/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7478 - val_loss: 0.4979 - val_accuracy: 0.7581\n",
      "Epoch 98/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.4995 - val_accuracy: 0.7572\n",
      "Epoch 99/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7482 - val_loss: 0.4946 - val_accuracy: 0.7545\n",
      "Epoch 100/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7446 - val_loss: 0.4952 - val_accuracy: 0.7527\n",
      "Epoch 101/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7431 - val_loss: 0.4956 - val_accuracy: 0.7545\n",
      "Epoch 102/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5067 - accuracy: 0.7457 - val_loss: 0.4930 - val_accuracy: 0.7563\n",
      "Epoch 103/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.7496 - val_loss: 0.4910 - val_accuracy: 0.7616\n",
      "Epoch 104/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7469 - val_loss: 0.4955 - val_accuracy: 0.7518\n",
      "Epoch 105/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7491 - val_loss: 0.4965 - val_accuracy: 0.7634\n",
      "Epoch 106/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7522 - val_loss: 0.4967 - val_accuracy: 0.7401\n",
      "Epoch 107/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.7549 - val_loss: 0.4953 - val_accuracy: 0.7608\n",
      "Epoch 108/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7489 - val_loss: 0.4923 - val_accuracy: 0.7590\n",
      "Epoch 109/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.7513 - val_loss: 0.4903 - val_accuracy: 0.7625\n",
      "Epoch 110/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7540 - val_loss: 0.4981 - val_accuracy: 0.7554\n",
      "Epoch 111/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.7522 - val_loss: 0.4939 - val_accuracy: 0.7599\n",
      "Epoch 112/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7513 - val_loss: 0.4955 - val_accuracy: 0.7608\n",
      "Epoch 113/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7511 - val_loss: 0.4984 - val_accuracy: 0.7625\n",
      "Epoch 114/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7516 - val_loss: 0.4990 - val_accuracy: 0.7581\n",
      "Epoch 115/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7493 - val_loss: 0.5051 - val_accuracy: 0.7652\n",
      "Epoch 116/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7507 - val_loss: 0.5031 - val_accuracy: 0.7599\n",
      "Epoch 117/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.7489 - val_loss: 0.5035 - val_accuracy: 0.7634\n",
      "Epoch 118/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7451 - val_loss: 0.5128 - val_accuracy: 0.7590\n",
      "Epoch 119/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7509 - val_loss: 0.5020 - val_accuracy: 0.7688\n",
      "Epoch 120/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7552 - val_loss: 0.4963 - val_accuracy: 0.7679\n",
      "Epoch 121/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7543 - val_loss: 0.5022 - val_accuracy: 0.7652\n",
      "Epoch 122/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7549 - val_loss: 0.5086 - val_accuracy: 0.7616\n",
      "Epoch 123/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7610 - val_loss: 0.5056 - val_accuracy: 0.7634\n",
      "Epoch 124/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7567 - val_loss: 0.5081 - val_accuracy: 0.7643\n",
      "Epoch 125/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.7574 - val_loss: 0.5066 - val_accuracy: 0.7661\n",
      "Epoch 126/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7547 - val_loss: 0.4959 - val_accuracy: 0.7608\n",
      "Epoch 127/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7581 - val_loss: 0.5023 - val_accuracy: 0.7625\n",
      "Epoch 128/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7527 - val_loss: 0.5051 - val_accuracy: 0.7634\n",
      "Epoch 129/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7560 - val_loss: 0.4999 - val_accuracy: 0.7608\n",
      "Epoch 130/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7558 - val_loss: 0.5104 - val_accuracy: 0.7563\n",
      "Epoch 131/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7520 - val_loss: 0.5018 - val_accuracy: 0.7634\n",
      "Epoch 132/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4967 - accuracy: 0.7578 - val_loss: 0.5056 - val_accuracy: 0.7652\n",
      "Epoch 133/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7556 - val_loss: 0.5118 - val_accuracy: 0.7679\n",
      "Epoch 134/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7547 - val_loss: 0.5035 - val_accuracy: 0.7652\n",
      "Epoch 135/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7572 - val_loss: 0.5118 - val_accuracy: 0.7608\n",
      "Epoch 136/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7549 - val_loss: 0.5038 - val_accuracy: 0.7661\n",
      "Epoch 137/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7592 - val_loss: 0.5144 - val_accuracy: 0.7706\n",
      "Epoch 138/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7560 - val_loss: 0.5051 - val_accuracy: 0.7590\n",
      "Epoch 139/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7569 - val_loss: 0.5115 - val_accuracy: 0.7590\n",
      "Epoch 140/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7590 - val_loss: 0.5029 - val_accuracy: 0.7616\n",
      "Epoch 141/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7587 - val_loss: 0.5007 - val_accuracy: 0.7715\n",
      "Epoch 142/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7592 - val_loss: 0.5083 - val_accuracy: 0.7599\n",
      "Epoch 143/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4910 - accuracy: 0.7614 - val_loss: 0.4967 - val_accuracy: 0.7634\n",
      "Epoch 144/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7625 - val_loss: 0.4977 - val_accuracy: 0.7608\n",
      "Epoch 145/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.7639 - val_loss: 0.4945 - val_accuracy: 0.7652\n",
      "Epoch 146/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7634 - val_loss: 0.5015 - val_accuracy: 0.7599\n",
      "Epoch 147/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7608 - val_loss: 0.4949 - val_accuracy: 0.7643\n",
      "Epoch 148/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.7646 - val_loss: 0.4848 - val_accuracy: 0.7643\n",
      "Epoch 149/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.7605 - val_loss: 0.4902 - val_accuracy: 0.7670\n",
      "Epoch 150/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7657 - val_loss: 0.4951 - val_accuracy: 0.7697\n",
      "Epoch 151/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7643 - val_loss: 0.4936 - val_accuracy: 0.7688\n",
      "Epoch 152/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7616 - val_loss: 0.5081 - val_accuracy: 0.7643\n",
      "Epoch 153/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7616 - val_loss: 0.4878 - val_accuracy: 0.7634\n",
      "Epoch 154/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7641 - val_loss: 0.4831 - val_accuracy: 0.7724\n",
      "Epoch 155/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7596 - val_loss: 0.4872 - val_accuracy: 0.7724\n",
      "Epoch 156/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7605 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 157/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7639 - val_loss: 0.4851 - val_accuracy: 0.7733\n",
      "Epoch 158/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7608 - val_loss: 0.4854 - val_accuracy: 0.7697\n",
      "Epoch 159/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7643 - val_loss: 0.4826 - val_accuracy: 0.7715\n",
      "Epoch 160/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7603 - val_loss: 0.4792 - val_accuracy: 0.7715\n",
      "Epoch 161/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7610 - val_loss: 0.4788 - val_accuracy: 0.7715\n",
      "Epoch 162/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4855 - accuracy: 0.7594 - val_loss: 0.4787 - val_accuracy: 0.7724\n",
      "Epoch 163/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7616 - val_loss: 0.4831 - val_accuracy: 0.7742\n",
      "Epoch 164/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7605 - val_loss: 0.4823 - val_accuracy: 0.7715\n",
      "Epoch 165/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4857 - accuracy: 0.7605 - val_loss: 0.4774 - val_accuracy: 0.7715\n",
      "Epoch 166/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4872 - accuracy: 0.7630 - val_loss: 0.4745 - val_accuracy: 0.7733\n",
      "Epoch 167/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4891 - accuracy: 0.7614 - val_loss: 0.4794 - val_accuracy: 0.7724\n",
      "Epoch 168/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7596 - val_loss: 0.4777 - val_accuracy: 0.7733\n",
      "Epoch 169/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4896 - accuracy: 0.7601 - val_loss: 0.4768 - val_accuracy: 0.7670\n",
      "Epoch 170/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.7574 - val_loss: 0.4792 - val_accuracy: 0.7652\n",
      "Epoch 171/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4879 - accuracy: 0.7583 - val_loss: 0.4733 - val_accuracy: 0.7688\n",
      "Epoch 172/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4916 - accuracy: 0.7578 - val_loss: 0.4717 - val_accuracy: 0.7733\n",
      "Epoch 173/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4906 - accuracy: 0.7563 - val_loss: 0.4727 - val_accuracy: 0.7688\n",
      "Epoch 174/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.7576 - val_loss: 0.4740 - val_accuracy: 0.7715\n",
      "Epoch 175/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7543 - val_loss: 0.4722 - val_accuracy: 0.7742\n",
      "Epoch 176/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4909 - accuracy: 0.7525 - val_loss: 0.4753 - val_accuracy: 0.7643\n",
      "Epoch 177/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7567 - val_loss: 0.4730 - val_accuracy: 0.7643\n",
      "Epoch 178/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7569 - val_loss: 0.4745 - val_accuracy: 0.7715\n",
      "Epoch 179/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7569 - val_loss: 0.4747 - val_accuracy: 0.7643\n",
      "Epoch 180/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7558 - val_loss: 0.4726 - val_accuracy: 0.7706\n",
      "Epoch 181/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4870 - accuracy: 0.7610 - val_loss: 0.4745 - val_accuracy: 0.7697\n",
      "Epoch 182/2000\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.4879 - accuracy: 0.7625 - val_loss: 0.4737 - val_accuracy: 0.7715\n",
      "Epoch 183/2000\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.4872 - accuracy: 0.7641 - val_loss: 0.4734 - val_accuracy: 0.7679\n",
      "Epoch 184/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4865 - accuracy: 0.7560 - val_loss: 0.4726 - val_accuracy: 0.7670\n",
      "Epoch 185/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4855 - accuracy: 0.7614 - val_loss: 0.4743 - val_accuracy: 0.7652\n",
      "Epoch 186/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7632 - val_loss: 0.4745 - val_accuracy: 0.7652\n",
      "Epoch 187/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.7630 - val_loss: 0.4748 - val_accuracy: 0.7599\n",
      "Epoch 188/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7632 - val_loss: 0.4759 - val_accuracy: 0.7599\n",
      "Epoch 189/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7610 - val_loss: 0.4742 - val_accuracy: 0.7616\n",
      "Epoch 190/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4841 - accuracy: 0.7648 - val_loss: 0.4776 - val_accuracy: 0.7652\n",
      "Epoch 191/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.7643 - val_loss: 0.4776 - val_accuracy: 0.7643\n",
      "Epoch 192/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7659 - val_loss: 0.4764 - val_accuracy: 0.7616\n",
      "Epoch 193/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7619 - val_loss: 0.4769 - val_accuracy: 0.7608\n",
      "Epoch 194/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4856 - accuracy: 0.7628 - val_loss: 0.4745 - val_accuracy: 0.7554\n",
      "Epoch 195/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7637 - val_loss: 0.4761 - val_accuracy: 0.7608\n",
      "Epoch 196/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.4783 - val_accuracy: 0.7545\n",
      "Epoch 197/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4826 - accuracy: 0.7637 - val_loss: 0.4809 - val_accuracy: 0.7554\n",
      "Epoch 198/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7646 - val_loss: 0.4772 - val_accuracy: 0.7616\n",
      "Epoch 199/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4820 - accuracy: 0.7659 - val_loss: 0.4795 - val_accuracy: 0.7500\n",
      "Epoch 200/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7634 - val_loss: 0.4755 - val_accuracy: 0.7545\n",
      "Epoch 201/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4828 - accuracy: 0.7621 - val_loss: 0.4744 - val_accuracy: 0.7608\n",
      "Epoch 202/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4826 - accuracy: 0.7623 - val_loss: 0.4744 - val_accuracy: 0.7608\n",
      "Epoch 203/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7594 - val_loss: 0.4725 - val_accuracy: 0.7554\n",
      "Epoch 204/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4843 - accuracy: 0.7614 - val_loss: 0.4744 - val_accuracy: 0.7581\n",
      "Epoch 205/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4818 - accuracy: 0.7643 - val_loss: 0.4741 - val_accuracy: 0.7688\n",
      "Epoch 206/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.7643 - val_loss: 0.4814 - val_accuracy: 0.7679\n",
      "Epoch 207/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7661 - val_loss: 0.4755 - val_accuracy: 0.7697\n",
      "Epoch 208/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7675 - val_loss: 0.4729 - val_accuracy: 0.7697\n",
      "Epoch 209/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4800 - accuracy: 0.7666 - val_loss: 0.4727 - val_accuracy: 0.7688\n",
      "Epoch 210/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4807 - accuracy: 0.7632 - val_loss: 0.4720 - val_accuracy: 0.7679\n",
      "Epoch 211/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4805 - accuracy: 0.7661 - val_loss: 0.4684 - val_accuracy: 0.7697\n",
      "Epoch 212/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7657 - val_loss: 0.4700 - val_accuracy: 0.7652\n",
      "Epoch 213/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.7681 - val_loss: 0.4688 - val_accuracy: 0.7706\n",
      "Epoch 214/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7634 - val_loss: 0.4739 - val_accuracy: 0.7706\n",
      "Epoch 215/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.7670 - val_loss: 0.4772 - val_accuracy: 0.7688\n",
      "Epoch 216/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4796 - accuracy: 0.7614 - val_loss: 0.4738 - val_accuracy: 0.7661\n",
      "Epoch 217/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4787 - accuracy: 0.7648 - val_loss: 0.4770 - val_accuracy: 0.7661\n",
      "Epoch 218/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4767 - accuracy: 0.7693 - val_loss: 0.4735 - val_accuracy: 0.7688\n",
      "Epoch 219/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7681 - val_loss: 0.4704 - val_accuracy: 0.7706\n",
      "Epoch 220/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4786 - accuracy: 0.7668 - val_loss: 0.4747 - val_accuracy: 0.7697\n",
      "Epoch 221/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4773 - accuracy: 0.7677 - val_loss: 0.4770 - val_accuracy: 0.7706\n",
      "Epoch 222/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.4732 - val_accuracy: 0.7688\n",
      "Epoch 223/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4776 - accuracy: 0.7672 - val_loss: 0.4708 - val_accuracy: 0.7769\n",
      "Epoch 224/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7677 - val_loss: 0.4707 - val_accuracy: 0.7742\n",
      "Epoch 225/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7675 - val_loss: 0.4734 - val_accuracy: 0.7733\n",
      "Epoch 226/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4758 - accuracy: 0.7670 - val_loss: 0.4737 - val_accuracy: 0.7760\n",
      "Epoch 227/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4766 - accuracy: 0.7679 - val_loss: 0.4782 - val_accuracy: 0.7733\n",
      "Epoch 228/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7657 - val_loss: 0.4774 - val_accuracy: 0.7670\n",
      "Epoch 229/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7679 - val_loss: 0.4851 - val_accuracy: 0.7608\n",
      "Epoch 230/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7684 - val_loss: 0.4806 - val_accuracy: 0.7643\n",
      "Epoch 231/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7646 - val_loss: 0.4849 - val_accuracy: 0.7634\n",
      "Epoch 232/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7641 - val_loss: 0.4868 - val_accuracy: 0.7670\n",
      "Epoch 233/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7639 - val_loss: 0.4834 - val_accuracy: 0.7652\n",
      "Epoch 234/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4760 - accuracy: 0.7661 - val_loss: 0.4936 - val_accuracy: 0.7643\n",
      "Epoch 235/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4787 - accuracy: 0.7623 - val_loss: 0.4921 - val_accuracy: 0.7625\n",
      "Epoch 236/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7634 - val_loss: 0.4909 - val_accuracy: 0.7643\n",
      "Epoch 237/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.7646 - val_loss: 0.4952 - val_accuracy: 0.7643\n",
      "Epoch 238/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4799 - accuracy: 0.7610 - val_loss: 0.4872 - val_accuracy: 0.7715\n",
      "Epoch 239/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4779 - accuracy: 0.7630 - val_loss: 0.4841 - val_accuracy: 0.7724\n",
      "Epoch 240/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4769 - accuracy: 0.7641 - val_loss: 0.4874 - val_accuracy: 0.7769\n",
      "Epoch 241/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4768 - accuracy: 0.7608 - val_loss: 0.4821 - val_accuracy: 0.7787\n",
      "Epoch 242/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7634 - val_loss: 0.4817 - val_accuracy: 0.7778\n",
      "Epoch 243/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4771 - accuracy: 0.7623 - val_loss: 0.4844 - val_accuracy: 0.7715\n",
      "Epoch 244/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7628 - val_loss: 0.4849 - val_accuracy: 0.7697\n",
      "Epoch 245/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4786 - accuracy: 0.7652 - val_loss: 0.4830 - val_accuracy: 0.7760\n",
      "Epoch 246/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4774 - accuracy: 0.7621 - val_loss: 0.4756 - val_accuracy: 0.7742\n",
      "Epoch 247/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7666 - val_loss: 0.4745 - val_accuracy: 0.7652\n",
      "Epoch 248/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.7637 - val_loss: 0.4825 - val_accuracy: 0.7670\n",
      "Epoch 249/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7639 - val_loss: 0.4757 - val_accuracy: 0.7679\n",
      "Epoch 250/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7668 - val_loss: 0.4758 - val_accuracy: 0.7661\n",
      "Epoch 251/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7679 - val_loss: 0.4798 - val_accuracy: 0.7688\n",
      "Epoch 252/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7659 - val_loss: 0.4800 - val_accuracy: 0.7706\n",
      "Epoch 253/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7681 - val_loss: 0.4782 - val_accuracy: 0.7706\n",
      "Epoch 254/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4752 - accuracy: 0.7637 - val_loss: 0.4777 - val_accuracy: 0.7679\n",
      "Epoch 255/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7672 - val_loss: 0.4820 - val_accuracy: 0.7625\n",
      "Epoch 256/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4738 - accuracy: 0.7657 - val_loss: 0.4797 - val_accuracy: 0.7670\n",
      "Epoch 257/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4752 - accuracy: 0.7666 - val_loss: 0.4814 - val_accuracy: 0.7643\n",
      "Epoch 258/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4772 - accuracy: 0.7643 - val_loss: 0.4741 - val_accuracy: 0.7661\n",
      "Epoch 259/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4735 - val_accuracy: 0.7751\n",
      "Epoch 260/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4744 - accuracy: 0.7677 - val_loss: 0.4790 - val_accuracy: 0.7742\n",
      "Epoch 261/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7672 - val_loss: 0.4791 - val_accuracy: 0.7661\n",
      "Epoch 262/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.7655 - val_loss: 0.4810 - val_accuracy: 0.7670\n",
      "Epoch 263/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.7681 - val_loss: 0.4809 - val_accuracy: 0.7724\n",
      "Epoch 264/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4748 - accuracy: 0.7686 - val_loss: 0.4811 - val_accuracy: 0.7715\n",
      "Epoch 265/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4727 - accuracy: 0.7702 - val_loss: 0.4825 - val_accuracy: 0.7715\n",
      "Epoch 266/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7679 - val_loss: 0.4788 - val_accuracy: 0.7742\n",
      "Epoch 267/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.7639 - val_loss: 0.4730 - val_accuracy: 0.7733\n",
      "Epoch 268/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4845 - accuracy: 0.7641 - val_loss: 0.4774 - val_accuracy: 0.7688\n",
      "Epoch 269/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4917 - accuracy: 0.7569 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
      "Epoch 270/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4939 - accuracy: 0.7563 - val_loss: 0.4753 - val_accuracy: 0.7733\n",
      "Epoch 271/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7668 - val_loss: 0.4737 - val_accuracy: 0.7679\n",
      "Epoch 272/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7672 - val_loss: 0.4697 - val_accuracy: 0.7688\n",
      "Epoch 273/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4791 - accuracy: 0.7679 - val_loss: 0.4729 - val_accuracy: 0.7733\n",
      "Epoch 274/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7652 - val_loss: 0.4732 - val_accuracy: 0.7670\n",
      "Epoch 275/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4757 - accuracy: 0.7668 - val_loss: 0.4690 - val_accuracy: 0.7769\n",
      "Epoch 276/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4743 - accuracy: 0.7675 - val_loss: 0.4685 - val_accuracy: 0.7778\n",
      "Epoch 277/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4778 - accuracy: 0.7686 - val_loss: 0.4697 - val_accuracy: 0.7814\n",
      "Epoch 278/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7695 - val_loss: 0.4720 - val_accuracy: 0.7849\n",
      "Epoch 279/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7690 - val_loss: 0.4714 - val_accuracy: 0.7742\n",
      "Epoch 280/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7704 - val_loss: 0.4728 - val_accuracy: 0.7769\n",
      "Epoch 281/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7715 - val_loss: 0.4688 - val_accuracy: 0.7805\n",
      "Epoch 282/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4717 - accuracy: 0.7735 - val_loss: 0.4684 - val_accuracy: 0.7778\n",
      "Epoch 283/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7728 - val_loss: 0.4679 - val_accuracy: 0.7778\n",
      "Epoch 284/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7715 - val_loss: 0.4680 - val_accuracy: 0.7751\n",
      "Epoch 285/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7697 - val_loss: 0.4665 - val_accuracy: 0.7760\n",
      "Epoch 286/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7733 - val_loss: 0.4669 - val_accuracy: 0.7814\n",
      "Epoch 287/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7720 - val_loss: 0.4718 - val_accuracy: 0.7760\n",
      "Epoch 288/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4747 - accuracy: 0.7690 - val_loss: 0.4696 - val_accuracy: 0.7778\n",
      "Epoch 289/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7735 - val_loss: 0.4687 - val_accuracy: 0.7751\n",
      "Epoch 290/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7722 - val_loss: 0.4701 - val_accuracy: 0.7787\n",
      "Epoch 291/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7720 - val_loss: 0.4678 - val_accuracy: 0.7769\n",
      "Epoch 292/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7737 - val_loss: 0.4686 - val_accuracy: 0.7742\n",
      "Epoch 293/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4673 - accuracy: 0.7746 - val_loss: 0.4714 - val_accuracy: 0.7733\n",
      "Epoch 294/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4671 - accuracy: 0.7733 - val_loss: 0.4729 - val_accuracy: 0.7805\n",
      "Epoch 295/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7764 - val_loss: 0.4712 - val_accuracy: 0.7787\n",
      "Epoch 296/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7762 - val_loss: 0.4667 - val_accuracy: 0.7787\n",
      "Epoch 297/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7735 - val_loss: 0.4686 - val_accuracy: 0.7751\n",
      "Epoch 298/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7751 - val_loss: 0.4646 - val_accuracy: 0.7733\n",
      "Epoch 299/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7746 - val_loss: 0.4617 - val_accuracy: 0.7796\n",
      "Epoch 300/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7695 - val_loss: 0.4613 - val_accuracy: 0.7778\n",
      "Epoch 301/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7715 - val_loss: 0.4668 - val_accuracy: 0.7787\n",
      "Epoch 302/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7735 - val_loss: 0.4662 - val_accuracy: 0.7751\n",
      "Epoch 303/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7733 - val_loss: 0.4618 - val_accuracy: 0.7760\n",
      "Epoch 304/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7672 - val_loss: 0.4794 - val_accuracy: 0.7581\n",
      "Epoch 305/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7608 - val_loss: 0.4670 - val_accuracy: 0.7814\n",
      "Epoch 306/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7585 - val_loss: 0.4694 - val_accuracy: 0.7876\n",
      "Epoch 307/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7592 - val_loss: 0.4669 - val_accuracy: 0.7769\n",
      "Epoch 308/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7681 - val_loss: 0.4674 - val_accuracy: 0.7733\n",
      "Epoch 309/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7612 - val_loss: 0.4640 - val_accuracy: 0.7841\n",
      "Epoch 310/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7666 - val_loss: 0.4692 - val_accuracy: 0.7769\n",
      "Epoch 311/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.7697 - val_loss: 0.4671 - val_accuracy: 0.7769\n",
      "Epoch 312/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7699 - val_loss: 0.4672 - val_accuracy: 0.7715\n",
      "Epoch 313/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7753 - val_loss: 0.4679 - val_accuracy: 0.7769\n",
      "Epoch 314/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7717 - val_loss: 0.4691 - val_accuracy: 0.7778\n",
      "Epoch 315/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.7693 - val_loss: 0.4699 - val_accuracy: 0.7742\n",
      "Epoch 316/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4674 - accuracy: 0.7744 - val_loss: 0.4699 - val_accuracy: 0.7805\n",
      "Epoch 317/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4663 - accuracy: 0.7753 - val_loss: 0.4736 - val_accuracy: 0.7760\n",
      "Epoch 318/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7760 - val_loss: 0.4702 - val_accuracy: 0.7733\n",
      "Epoch 319/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4678 - accuracy: 0.7737 - val_loss: 0.4653 - val_accuracy: 0.7742\n",
      "Epoch 320/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7762 - val_loss: 0.4666 - val_accuracy: 0.7733\n",
      "Epoch 321/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7742 - val_loss: 0.4707 - val_accuracy: 0.7805\n",
      "Epoch 322/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4733 - accuracy: 0.7742 - val_loss: 0.4678 - val_accuracy: 0.7841\n",
      "Epoch 323/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4703 - accuracy: 0.7764 - val_loss: 0.4661 - val_accuracy: 0.7769\n",
      "Epoch 324/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4688 - accuracy: 0.7758 - val_loss: 0.4661 - val_accuracy: 0.7769\n",
      "Epoch 325/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4648 - val_accuracy: 0.7724\n",
      "Epoch 326/2000\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.4696 - accuracy: 0.7733 - val_loss: 0.4637 - val_accuracy: 0.7751\n",
      "Epoch 327/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4705 - accuracy: 0.7726 - val_loss: 0.4673 - val_accuracy: 0.7832\n",
      "Epoch 328/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7742 - val_loss: 0.4708 - val_accuracy: 0.7823\n",
      "Epoch 329/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.7720 - val_loss: 0.4742 - val_accuracy: 0.7688\n",
      "Epoch 330/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4702 - accuracy: 0.7722 - val_loss: 0.4793 - val_accuracy: 0.7823\n",
      "Epoch 331/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4718 - accuracy: 0.7717 - val_loss: 0.4800 - val_accuracy: 0.7742\n",
      "Epoch 332/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.7762 - val_loss: 0.4767 - val_accuracy: 0.7769\n",
      "Epoch 333/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4696 - accuracy: 0.7751 - val_loss: 0.4746 - val_accuracy: 0.7787\n",
      "Epoch 334/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7782 - val_loss: 0.4767 - val_accuracy: 0.7733\n",
      "Epoch 335/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7773 - val_loss: 0.4750 - val_accuracy: 0.7706\n",
      "Epoch 336/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7773 - val_loss: 0.4752 - val_accuracy: 0.7733\n",
      "Epoch 337/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7744 - val_loss: 0.4745 - val_accuracy: 0.7733\n",
      "Epoch 338/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4695 - accuracy: 0.7735 - val_loss: 0.4753 - val_accuracy: 0.7706\n",
      "Epoch 339/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4707 - accuracy: 0.7715 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 340/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7737 - val_loss: 0.4713 - val_accuracy: 0.7760\n",
      "Epoch 341/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7780 - val_loss: 0.4724 - val_accuracy: 0.7724\n",
      "Epoch 342/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7773 - val_loss: 0.4739 - val_accuracy: 0.7742\n",
      "Epoch 343/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4685 - accuracy: 0.7767 - val_loss: 0.4702 - val_accuracy: 0.7742\n",
      "Epoch 344/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7825 - val_loss: 0.4702 - val_accuracy: 0.7742\n",
      "Epoch 345/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4662 - accuracy: 0.7787 - val_loss: 0.4730 - val_accuracy: 0.7769\n",
      "Epoch 346/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7744 - val_loss: 0.4738 - val_accuracy: 0.7706\n",
      "Epoch 347/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7814 - val_loss: 0.4725 - val_accuracy: 0.7760\n",
      "Epoch 348/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7809 - val_loss: 0.4690 - val_accuracy: 0.7760\n",
      "Epoch 349/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7814 - val_loss: 0.4691 - val_accuracy: 0.7841\n",
      "Epoch 350/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.7802 - val_loss: 0.4755 - val_accuracy: 0.7670\n",
      "Epoch 351/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7805 - val_loss: 0.4713 - val_accuracy: 0.7805\n",
      "Epoch 352/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4612 - accuracy: 0.7807 - val_loss: 0.4730 - val_accuracy: 0.7805\n",
      "Epoch 353/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7825 - val_loss: 0.4762 - val_accuracy: 0.7823\n",
      "Epoch 354/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4626 - accuracy: 0.7805 - val_loss: 0.4735 - val_accuracy: 0.7778\n",
      "Epoch 355/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7838 - val_loss: 0.4719 - val_accuracy: 0.7742\n",
      "Epoch 356/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7814 - val_loss: 0.4698 - val_accuracy: 0.7769\n",
      "Epoch 357/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7793 - val_loss: 0.4773 - val_accuracy: 0.7715\n",
      "Epoch 358/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7814 - val_loss: 0.4698 - val_accuracy: 0.7841\n",
      "Epoch 359/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7800 - val_loss: 0.4722 - val_accuracy: 0.7787\n",
      "Epoch 360/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7807 - val_loss: 0.4694 - val_accuracy: 0.7787\n",
      "Epoch 361/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7820 - val_loss: 0.4675 - val_accuracy: 0.7769\n",
      "Epoch 362/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7823 - val_loss: 0.4701 - val_accuracy: 0.7751\n",
      "Epoch 363/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7796 - val_loss: 0.4734 - val_accuracy: 0.7697\n",
      "Epoch 364/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7807 - val_loss: 0.4787 - val_accuracy: 0.7796\n",
      "Epoch 365/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4640 - accuracy: 0.7832 - val_loss: 0.4739 - val_accuracy: 0.7796\n",
      "Epoch 366/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7798 - val_loss: 0.4716 - val_accuracy: 0.7796\n",
      "Epoch 367/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7832 - val_loss: 0.4722 - val_accuracy: 0.7796\n",
      "Epoch 368/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7809 - val_loss: 0.4727 - val_accuracy: 0.7796\n",
      "Epoch 369/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7816 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 370/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4609 - accuracy: 0.7811 - val_loss: 0.4724 - val_accuracy: 0.7751\n",
      "Epoch 371/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4619 - accuracy: 0.7832 - val_loss: 0.4732 - val_accuracy: 0.7805\n",
      "Epoch 372/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7789 - val_loss: 0.4739 - val_accuracy: 0.7858\n",
      "Epoch 373/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7802 - val_loss: 0.4746 - val_accuracy: 0.7841\n",
      "Epoch 374/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7758 - val_loss: 0.4775 - val_accuracy: 0.7751\n",
      "Epoch 375/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7796 - val_loss: 0.4804 - val_accuracy: 0.7751\n",
      "Epoch 376/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.7820 - val_loss: 0.4815 - val_accuracy: 0.7572\n",
      "Epoch 377/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7796 - val_loss: 0.4778 - val_accuracy: 0.7778\n",
      "Epoch 378/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7807 - val_loss: 0.4897 - val_accuracy: 0.7527\n",
      "Epoch 379/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.7780 - val_loss: 0.4886 - val_accuracy: 0.7563\n",
      "Epoch 380/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7753 - val_loss: 0.4829 - val_accuracy: 0.7670\n",
      "Epoch 381/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7699 - val_loss: 0.4753 - val_accuracy: 0.7733\n",
      "Epoch 382/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7764 - val_loss: 0.4747 - val_accuracy: 0.7643\n",
      "Epoch 383/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7767 - val_loss: 0.4688 - val_accuracy: 0.7751\n",
      "Epoch 384/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7744 - val_loss: 0.4682 - val_accuracy: 0.7706\n",
      "Epoch 385/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7706 - val_loss: 0.4718 - val_accuracy: 0.7778\n",
      "Epoch 386/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4774 - accuracy: 0.7695 - val_loss: 0.4719 - val_accuracy: 0.7706\n",
      "Epoch 387/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4724 - accuracy: 0.7753 - val_loss: 0.4706 - val_accuracy: 0.7733\n",
      "Epoch 388/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7715 - val_loss: 0.4697 - val_accuracy: 0.7715\n",
      "Epoch 389/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7740 - val_loss: 0.4701 - val_accuracy: 0.7751\n",
      "Epoch 390/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4789 - accuracy: 0.7699 - val_loss: 0.4707 - val_accuracy: 0.7769\n",
      "Epoch 391/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7746 - val_loss: 0.4714 - val_accuracy: 0.7769\n",
      "Epoch 392/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7704 - val_loss: 0.4659 - val_accuracy: 0.7724\n",
      "Epoch 393/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7771 - val_loss: 0.4657 - val_accuracy: 0.7814\n",
      "Epoch 394/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7702 - val_loss: 0.4642 - val_accuracy: 0.7832\n",
      "Epoch 395/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7762 - val_loss: 0.4612 - val_accuracy: 0.7778\n",
      "Epoch 396/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7724 - val_loss: 0.4612 - val_accuracy: 0.7778\n",
      "Epoch 397/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7726 - val_loss: 0.4602 - val_accuracy: 0.7912\n",
      "Epoch 398/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7713 - val_loss: 0.4649 - val_accuracy: 0.7867\n",
      "Epoch 399/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7762 - val_loss: 0.4595 - val_accuracy: 0.7841\n",
      "Epoch 400/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.7724 - val_loss: 0.4632 - val_accuracy: 0.7751\n",
      "Epoch 401/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7715 - val_loss: 0.4664 - val_accuracy: 0.7823\n",
      "Epoch 402/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7717 - val_loss: 0.4671 - val_accuracy: 0.7715\n",
      "Epoch 403/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7686 - val_loss: 0.4632 - val_accuracy: 0.7849\n",
      "Epoch 404/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7668 - val_loss: 0.4697 - val_accuracy: 0.7832\n",
      "Epoch 405/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7706 - val_loss: 0.4742 - val_accuracy: 0.7742\n",
      "Epoch 406/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7690 - val_loss: 0.4688 - val_accuracy: 0.7832\n",
      "Epoch 407/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7740 - val_loss: 0.4745 - val_accuracy: 0.7805\n",
      "Epoch 408/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7713 - val_loss: 0.4645 - val_accuracy: 0.7760\n",
      "Epoch 409/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7720 - val_loss: 0.4639 - val_accuracy: 0.7733\n",
      "Epoch 410/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7733 - val_loss: 0.4602 - val_accuracy: 0.7832\n",
      "Epoch 411/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7720 - val_loss: 0.4613 - val_accuracy: 0.7805\n",
      "Epoch 412/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4653 - accuracy: 0.7742 - val_loss: 0.4676 - val_accuracy: 0.7751\n",
      "Epoch 413/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7764 - val_loss: 0.4630 - val_accuracy: 0.7733\n",
      "Epoch 414/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7780 - val_loss: 0.4626 - val_accuracy: 0.7706\n",
      "Epoch 415/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4624 - accuracy: 0.7771 - val_loss: 0.4684 - val_accuracy: 0.7787\n",
      "Epoch 416/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7751 - val_loss: 0.4742 - val_accuracy: 0.7715\n",
      "Epoch 417/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7791 - val_loss: 0.4707 - val_accuracy: 0.7733\n",
      "Epoch 418/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.4682 - val_accuracy: 0.7751\n",
      "Epoch 419/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7773 - val_loss: 0.4678 - val_accuracy: 0.7796\n",
      "Epoch 420/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7771 - val_loss: 0.4629 - val_accuracy: 0.7823\n",
      "Epoch 421/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7751 - val_loss: 0.4643 - val_accuracy: 0.7706\n",
      "Epoch 422/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7773 - val_loss: 0.4667 - val_accuracy: 0.7751\n",
      "Epoch 423/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7753 - val_loss: 0.4620 - val_accuracy: 0.7769\n",
      "Epoch 424/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.7782 - val_loss: 0.4659 - val_accuracy: 0.7814\n",
      "Epoch 425/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4643 - accuracy: 0.7758 - val_loss: 0.4633 - val_accuracy: 0.7832\n",
      "Epoch 426/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7796 - val_loss: 0.4654 - val_accuracy: 0.7787\n",
      "Epoch 427/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7789 - val_loss: 0.4701 - val_accuracy: 0.7733\n",
      "Epoch 428/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7802 - val_loss: 0.4797 - val_accuracy: 0.7634\n",
      "Epoch 429/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4836 - val_accuracy: 0.7527\n",
      "Epoch 430/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7787 - val_loss: 0.4916 - val_accuracy: 0.7518\n",
      "Epoch 431/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4671 - accuracy: 0.7780 - val_loss: 0.4827 - val_accuracy: 0.7563\n",
      "Epoch 432/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7764 - val_loss: 0.4937 - val_accuracy: 0.7509\n",
      "Epoch 433/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7740 - val_loss: 0.4758 - val_accuracy: 0.7796\n",
      "Epoch 434/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7724 - val_loss: 0.4725 - val_accuracy: 0.7661\n",
      "Epoch 435/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.4851 - val_accuracy: 0.7401\n",
      "Epoch 436/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7616\n",
      "Epoch 437/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4805 - val_accuracy: 0.7554\n",
      "Epoch 438/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7798 - val_loss: 0.4794 - val_accuracy: 0.7563\n",
      "Epoch 439/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7782 - val_loss: 0.4734 - val_accuracy: 0.7787\n",
      "Epoch 440/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4601 - accuracy: 0.7814 - val_loss: 0.4705 - val_accuracy: 0.7805\n",
      "Epoch 441/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7807 - val_loss: 0.4708 - val_accuracy: 0.7849\n",
      "Epoch 442/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7820 - val_loss: 0.4653 - val_accuracy: 0.7706\n",
      "Epoch 443/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7749 - val_loss: 0.4615 - val_accuracy: 0.7796\n",
      "Epoch 444/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7800 - val_loss: 0.4676 - val_accuracy: 0.7599\n",
      "Epoch 445/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7805 - val_loss: 0.4736 - val_accuracy: 0.7769\n",
      "Epoch 446/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7787 - val_loss: 0.4695 - val_accuracy: 0.7805\n",
      "Epoch 447/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7832 - val_loss: 0.4666 - val_accuracy: 0.7832\n",
      "Epoch 448/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7800 - val_loss: 0.4647 - val_accuracy: 0.7975\n",
      "Epoch 449/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7825 - val_loss: 0.4675 - val_accuracy: 0.7688\n",
      "Epoch 450/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7802 - val_loss: 0.4661 - val_accuracy: 0.7751\n",
      "Epoch 451/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7807 - val_loss: 0.4656 - val_accuracy: 0.7679\n",
      "Epoch 452/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7823 - val_loss: 0.4660 - val_accuracy: 0.7841\n",
      "Epoch 453/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7740 - val_loss: 0.4666 - val_accuracy: 0.7805\n",
      "Epoch 454/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7755 - val_loss: 0.4787 - val_accuracy: 0.7733\n",
      "Epoch 455/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7753 - val_loss: 0.4782 - val_accuracy: 0.7661\n",
      "Epoch 456/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7802 - val_loss: 0.4747 - val_accuracy: 0.7724\n",
      "Epoch 457/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7802 - val_loss: 0.4754 - val_accuracy: 0.7652\n",
      "Epoch 458/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7796 - val_loss: 0.4763 - val_accuracy: 0.7634\n",
      "Epoch 459/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7769 - val_loss: 0.4704 - val_accuracy: 0.7652\n",
      "Epoch 460/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7764 - val_loss: 0.4736 - val_accuracy: 0.7652\n",
      "Epoch 461/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7789 - val_loss: 0.4792 - val_accuracy: 0.7643\n",
      "Epoch 462/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7746 - val_loss: 0.4688 - val_accuracy: 0.7805\n",
      "Epoch 463/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7731 - val_loss: 0.4737 - val_accuracy: 0.7769\n",
      "Epoch 464/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7737 - val_loss: 0.4796 - val_accuracy: 0.7733\n",
      "Epoch 465/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7684 - val_loss: 0.4628 - val_accuracy: 0.7832\n",
      "Epoch 466/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7708 - val_loss: 0.4659 - val_accuracy: 0.7787\n",
      "Epoch 467/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7731 - val_loss: 0.4679 - val_accuracy: 0.7760\n",
      "Epoch 468/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7715 - val_loss: 0.4594 - val_accuracy: 0.7814\n",
      "Epoch 469/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.4533 - val_accuracy: 0.7939\n",
      "Epoch 470/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7773 - val_loss: 0.4571 - val_accuracy: 0.7814\n",
      "Epoch 471/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7764 - val_loss: 0.4534 - val_accuracy: 0.7823\n",
      "Epoch 472/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7771 - val_loss: 0.4571 - val_accuracy: 0.7832\n",
      "Epoch 473/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7796 - val_loss: 0.4553 - val_accuracy: 0.7849\n",
      "Epoch 474/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7778 - val_loss: 0.4524 - val_accuracy: 0.7858\n",
      "Epoch 475/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7735 - val_loss: 0.4524 - val_accuracy: 0.7867\n",
      "Epoch 476/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7802 - val_loss: 0.4544 - val_accuracy: 0.7796\n",
      "Epoch 477/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7782 - val_loss: 0.4535 - val_accuracy: 0.7867\n",
      "Epoch 478/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7764 - val_loss: 0.4547 - val_accuracy: 0.7805\n",
      "Epoch 479/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7805 - val_loss: 0.4521 - val_accuracy: 0.7805\n",
      "Epoch 480/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7798 - val_loss: 0.4525 - val_accuracy: 0.7832\n",
      "Epoch 481/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7800 - val_loss: 0.4532 - val_accuracy: 0.7867\n",
      "Epoch 482/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7811 - val_loss: 0.4587 - val_accuracy: 0.7787\n",
      "Epoch 483/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7764 - val_loss: 0.4522 - val_accuracy: 0.7858\n",
      "Epoch 484/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4615 - accuracy: 0.7735 - val_loss: 0.4562 - val_accuracy: 0.7894\n",
      "Epoch 485/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4625 - accuracy: 0.7776 - val_loss: 0.4574 - val_accuracy: 0.7975\n",
      "Epoch 486/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.7805 - val_loss: 0.4606 - val_accuracy: 0.7903\n",
      "Epoch 487/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4605 - accuracy: 0.7773 - val_loss: 0.4611 - val_accuracy: 0.7876\n",
      "Epoch 488/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.7807 - val_loss: 0.4580 - val_accuracy: 0.7930\n",
      "Epoch 489/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4607 - accuracy: 0.7827 - val_loss: 0.4628 - val_accuracy: 0.7903\n",
      "Epoch 490/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4659 - accuracy: 0.7737 - val_loss: 0.4587 - val_accuracy: 0.7903\n",
      "Epoch 491/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7820 - val_loss: 0.4610 - val_accuracy: 0.7849\n",
      "Epoch 492/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7758 - val_loss: 0.4562 - val_accuracy: 0.7930\n",
      "Epoch 493/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7823 - val_loss: 0.4596 - val_accuracy: 0.7894\n",
      "Epoch 494/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7780 - val_loss: 0.4596 - val_accuracy: 0.7867\n",
      "Epoch 495/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7782 - val_loss: 0.4616 - val_accuracy: 0.7930\n",
      "Epoch 496/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7771 - val_loss: 0.4638 - val_accuracy: 0.7894\n",
      "Epoch 497/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4603 - accuracy: 0.7809 - val_loss: 0.4616 - val_accuracy: 0.7867\n",
      "Epoch 498/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7780 - val_loss: 0.4668 - val_accuracy: 0.7832\n",
      "Epoch 499/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7798 - val_loss: 0.4603 - val_accuracy: 0.7966\n",
      "Epoch 500/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7807 - val_loss: 0.4541 - val_accuracy: 0.7921\n",
      "Epoch 501/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7789 - val_loss: 0.4616 - val_accuracy: 0.7841\n",
      "Epoch 502/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7809 - val_loss: 0.4596 - val_accuracy: 0.7867\n",
      "Epoch 503/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7796 - val_loss: 0.4565 - val_accuracy: 0.7787\n",
      "Epoch 504/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4576 - accuracy: 0.7841 - val_loss: 0.4508 - val_accuracy: 0.7832\n",
      "Epoch 505/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7836 - val_loss: 0.4543 - val_accuracy: 0.7894\n",
      "Epoch 506/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7791 - val_loss: 0.4584 - val_accuracy: 0.7832\n",
      "Epoch 507/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4638 - accuracy: 0.7720 - val_loss: 0.4645 - val_accuracy: 0.7787\n",
      "Epoch 508/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7780 - val_loss: 0.4620 - val_accuracy: 0.7921\n",
      "Epoch 509/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4593 - accuracy: 0.7811 - val_loss: 0.4635 - val_accuracy: 0.7930\n",
      "Epoch 510/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4590 - accuracy: 0.7793 - val_loss: 0.4621 - val_accuracy: 0.7876\n",
      "Epoch 511/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.7787 - val_loss: 0.4594 - val_accuracy: 0.7823\n",
      "Epoch 512/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7744 - val_loss: 0.4628 - val_accuracy: 0.7885\n",
      "Epoch 513/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4576 - accuracy: 0.7811 - val_loss: 0.4620 - val_accuracy: 0.7858\n",
      "Epoch 514/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7751 - val_loss: 0.4669 - val_accuracy: 0.7778\n",
      "Epoch 515/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.7742 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 516/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4723 - accuracy: 0.7679 - val_loss: 0.4866 - val_accuracy: 0.7581\n",
      "Epoch 517/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.7762 - val_loss: 0.4621 - val_accuracy: 0.7885\n",
      "Epoch 518/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7793 - val_loss: 0.4605 - val_accuracy: 0.7867\n",
      "Epoch 519/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7796 - val_loss: 0.4590 - val_accuracy: 0.7912\n",
      "Epoch 520/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4597 - accuracy: 0.7827 - val_loss: 0.4544 - val_accuracy: 0.7930\n",
      "Epoch 521/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4534 - val_accuracy: 0.7858\n",
      "Epoch 522/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4577 - accuracy: 0.7838 - val_loss: 0.4549 - val_accuracy: 0.7957\n",
      "Epoch 523/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7879 - val_loss: 0.4534 - val_accuracy: 0.7939\n",
      "Epoch 524/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7838 - val_loss: 0.4555 - val_accuracy: 0.7948\n",
      "Epoch 525/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.7863 - val_loss: 0.4484 - val_accuracy: 0.7957\n",
      "Epoch 526/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.7861 - val_loss: 0.4525 - val_accuracy: 0.7957\n",
      "Epoch 527/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.7858 - val_loss: 0.4526 - val_accuracy: 0.7921\n",
      "Epoch 528/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7845 - val_loss: 0.4569 - val_accuracy: 0.7858\n",
      "Epoch 529/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4517 - accuracy: 0.7888 - val_loss: 0.4542 - val_accuracy: 0.7841\n",
      "Epoch 530/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7879 - val_loss: 0.4526 - val_accuracy: 0.7876\n",
      "Epoch 531/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7883 - val_loss: 0.4572 - val_accuracy: 0.7894\n",
      "Epoch 532/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7870 - val_loss: 0.4538 - val_accuracy: 0.7867\n",
      "Epoch 533/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4511 - accuracy: 0.7852 - val_loss: 0.4540 - val_accuracy: 0.7894\n",
      "Epoch 534/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7863 - val_loss: 0.4589 - val_accuracy: 0.7805\n",
      "Epoch 535/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7827 - val_loss: 0.4595 - val_accuracy: 0.7858\n",
      "Epoch 536/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7867 - val_loss: 0.4643 - val_accuracy: 0.7867\n",
      "Epoch 537/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7863 - val_loss: 0.4657 - val_accuracy: 0.7939\n",
      "Epoch 538/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.4611 - val_accuracy: 0.7778\n",
      "Epoch 539/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7827 - val_loss: 0.4582 - val_accuracy: 0.7805\n",
      "Epoch 540/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7841 - val_loss: 0.4658 - val_accuracy: 0.7867\n",
      "Epoch 541/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7861 - val_loss: 0.4722 - val_accuracy: 0.7733\n",
      "Epoch 542/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7872 - val_loss: 0.4589 - val_accuracy: 0.7814\n",
      "Epoch 543/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7881 - val_loss: 0.4629 - val_accuracy: 0.7858\n",
      "Epoch 544/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7867 - val_loss: 0.4617 - val_accuracy: 0.7814\n",
      "Epoch 545/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7796 - val_loss: 0.4622 - val_accuracy: 0.7921\n",
      "Epoch 546/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7827 - val_loss: 0.4638 - val_accuracy: 0.7733\n",
      "Epoch 547/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7834 - val_loss: 0.4692 - val_accuracy: 0.7760\n",
      "Epoch 548/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7854 - val_loss: 0.4617 - val_accuracy: 0.7814\n",
      "Epoch 549/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.7872 - val_loss: 0.4620 - val_accuracy: 0.7751\n",
      "Epoch 550/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7845 - val_loss: 0.4571 - val_accuracy: 0.7975\n",
      "Epoch 551/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4558 - accuracy: 0.7845 - val_loss: 0.4596 - val_accuracy: 0.7912\n",
      "Epoch 552/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7811 - val_loss: 0.4663 - val_accuracy: 0.7903\n",
      "Epoch 553/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7784 - val_loss: 0.4726 - val_accuracy: 0.7823\n",
      "Epoch 554/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7800 - val_loss: 0.4587 - val_accuracy: 0.7876\n",
      "Epoch 555/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7796 - val_loss: 0.4632 - val_accuracy: 0.7957\n",
      "Epoch 556/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7827 - val_loss: 0.4642 - val_accuracy: 0.7814\n",
      "Epoch 557/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7818 - val_loss: 0.4593 - val_accuracy: 0.7885\n",
      "Epoch 558/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7791 - val_loss: 0.4599 - val_accuracy: 0.7652\n",
      "Epoch 559/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7811 - val_loss: 0.4806 - val_accuracy: 0.7590\n",
      "Epoch 560/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7811 - val_loss: 0.5027 - val_accuracy: 0.7527\n",
      "Epoch 561/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7798 - val_loss: 0.4925 - val_accuracy: 0.7464\n",
      "Epoch 562/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7811 - val_loss: 0.4824 - val_accuracy: 0.7599\n",
      "Epoch 563/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7823 - val_loss: 0.4769 - val_accuracy: 0.7697\n",
      "Epoch 564/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7749 - val_loss: 0.4802 - val_accuracy: 0.7832\n",
      "Epoch 565/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.4678 - val_accuracy: 0.7787\n",
      "Epoch 566/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4703 - accuracy: 0.7762 - val_loss: 0.4655 - val_accuracy: 0.7733\n",
      "Epoch 567/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7776 - val_loss: 0.4581 - val_accuracy: 0.7912\n",
      "Epoch 568/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7755 - val_loss: 0.4697 - val_accuracy: 0.7697\n",
      "Epoch 569/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4601 - accuracy: 0.7805 - val_loss: 0.4667 - val_accuracy: 0.7760\n",
      "Epoch 570/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7820 - val_loss: 0.4714 - val_accuracy: 0.7590\n",
      "Epoch 571/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7809 - val_loss: 0.4725 - val_accuracy: 0.7679\n",
      "Epoch 572/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7787 - val_loss: 0.4602 - val_accuracy: 0.7876\n",
      "Epoch 573/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7843 - val_loss: 0.4661 - val_accuracy: 0.7832\n",
      "Epoch 574/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7847 - val_loss: 0.4577 - val_accuracy: 0.7894\n",
      "Epoch 575/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7816 - val_loss: 0.4607 - val_accuracy: 0.7867\n",
      "Epoch 576/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7858 - val_loss: 0.4628 - val_accuracy: 0.7760\n",
      "Epoch 577/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7787 - val_loss: 0.4578 - val_accuracy: 0.7787\n",
      "Epoch 578/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7852 - val_loss: 0.4709 - val_accuracy: 0.7679\n",
      "Epoch 579/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7838 - val_loss: 0.4514 - val_accuracy: 0.7930\n",
      "Epoch 580/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7818 - val_loss: 0.4566 - val_accuracy: 0.7867\n",
      "Epoch 581/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7811 - val_loss: 0.4564 - val_accuracy: 0.7832\n",
      "Epoch 582/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.7825 - val_loss: 0.4481 - val_accuracy: 0.7903\n",
      "Epoch 583/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.7858 - val_loss: 0.4517 - val_accuracy: 0.7885\n",
      "Epoch 584/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7823 - val_loss: 0.4515 - val_accuracy: 0.7885\n",
      "Epoch 585/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7796 - val_loss: 0.4584 - val_accuracy: 0.7796\n",
      "Epoch 586/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7823 - val_loss: 0.4526 - val_accuracy: 0.7930\n",
      "Epoch 587/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7832 - val_loss: 0.4544 - val_accuracy: 0.7805\n",
      "Epoch 588/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4590 - accuracy: 0.7802 - val_loss: 0.4552 - val_accuracy: 0.7894\n",
      "Epoch 589/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7883 - val_loss: 0.4544 - val_accuracy: 0.7849\n",
      "Epoch 590/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7856 - val_loss: 0.4540 - val_accuracy: 0.7885\n",
      "Epoch 591/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7852 - val_loss: 0.4563 - val_accuracy: 0.7921\n",
      "Epoch 592/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7854 - val_loss: 0.4555 - val_accuracy: 0.7894\n",
      "Epoch 593/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7888 - val_loss: 0.4566 - val_accuracy: 0.7849\n",
      "Epoch 594/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7800 - val_loss: 0.4539 - val_accuracy: 0.7832\n",
      "Epoch 595/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.7825 - val_loss: 0.4658 - val_accuracy: 0.7814\n",
      "Epoch 596/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7802 - val_loss: 0.4599 - val_accuracy: 0.7867\n",
      "Epoch 597/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.7818 - val_loss: 0.4639 - val_accuracy: 0.7805\n",
      "Epoch 598/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7847 - val_loss: 0.4692 - val_accuracy: 0.7733\n",
      "Epoch 599/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7820 - val_loss: 0.4646 - val_accuracy: 0.7778\n",
      "Epoch 600/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7870 - val_loss: 0.4759 - val_accuracy: 0.7769\n",
      "Epoch 601/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7863 - val_loss: 0.4658 - val_accuracy: 0.7867\n",
      "Epoch 602/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7843 - val_loss: 0.4554 - val_accuracy: 0.7796\n",
      "Epoch 603/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7926 - val_loss: 0.4679 - val_accuracy: 0.7760\n",
      "Epoch 604/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7885 - val_loss: 0.4722 - val_accuracy: 0.7733\n",
      "Epoch 605/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7870 - val_loss: 0.4592 - val_accuracy: 0.7894\n",
      "Epoch 606/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7883 - val_loss: 0.4657 - val_accuracy: 0.7849\n",
      "Epoch 607/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7834 - val_loss: 0.4673 - val_accuracy: 0.7939\n",
      "Epoch 608/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7852 - val_loss: 0.4571 - val_accuracy: 0.7858\n",
      "Epoch 609/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7858 - val_loss: 0.4601 - val_accuracy: 0.7912\n",
      "Epoch 610/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7870 - val_loss: 0.4732 - val_accuracy: 0.7634\n",
      "Epoch 611/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7845 - val_loss: 0.4693 - val_accuracy: 0.7733\n",
      "Epoch 612/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7856 - val_loss: 0.4619 - val_accuracy: 0.7814\n",
      "Epoch 613/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4525 - accuracy: 0.7867 - val_loss: 0.4678 - val_accuracy: 0.7814\n",
      "Epoch 614/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7841 - val_loss: 0.4660 - val_accuracy: 0.7805\n",
      "Epoch 615/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7825 - val_loss: 0.4881 - val_accuracy: 0.7536\n",
      "Epoch 616/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7856 - val_loss: 0.4630 - val_accuracy: 0.7814\n",
      "Epoch 617/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7816 - val_loss: 0.4710 - val_accuracy: 0.7841\n",
      "Epoch 618/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7829 - val_loss: 0.4687 - val_accuracy: 0.7751\n",
      "Epoch 619/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7872 - val_loss: 0.4767 - val_accuracy: 0.7545\n",
      "Epoch 620/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7616\n",
      "Epoch 621/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7885 - val_loss: 0.4815 - val_accuracy: 0.7697\n",
      "Epoch 622/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7849 - val_loss: 0.4686 - val_accuracy: 0.7778\n",
      "Epoch 623/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7863 - val_loss: 0.4785 - val_accuracy: 0.7572\n",
      "Epoch 624/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7811 - val_loss: 0.4784 - val_accuracy: 0.7688\n",
      "Epoch 625/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7800 - val_loss: 0.4675 - val_accuracy: 0.7760\n",
      "Epoch 626/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7811 - val_loss: 0.4688 - val_accuracy: 0.7796\n",
      "Epoch 627/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7825 - val_loss: 0.4812 - val_accuracy: 0.7536\n",
      "Epoch 628/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7805 - val_loss: 0.4552 - val_accuracy: 0.7867\n",
      "Epoch 629/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7793 - val_loss: 0.4605 - val_accuracy: 0.7787\n",
      "Epoch 630/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7755 - val_loss: 0.4525 - val_accuracy: 0.7867\n",
      "Epoch 631/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4641 - accuracy: 0.7780 - val_loss: 0.4529 - val_accuracy: 0.7849\n",
      "Epoch 632/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7744 - val_loss: 0.4738 - val_accuracy: 0.7787\n",
      "Epoch 633/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7704 - val_loss: 0.4720 - val_accuracy: 0.7787\n",
      "Epoch 634/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7735 - val_loss: 0.4790 - val_accuracy: 0.7787\n",
      "Epoch 635/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7767 - val_loss: 0.4842 - val_accuracy: 0.7724\n",
      "Epoch 636/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7791 - val_loss: 0.4837 - val_accuracy: 0.7652\n",
      "Epoch 637/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7755 - val_loss: 0.4767 - val_accuracy: 0.7814\n",
      "Epoch 638/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7798 - val_loss: 0.4724 - val_accuracy: 0.7769\n",
      "Epoch 639/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7800 - val_loss: 0.4715 - val_accuracy: 0.7760\n",
      "Epoch 640/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4592 - accuracy: 0.7796 - val_loss: 0.4701 - val_accuracy: 0.7832\n",
      "Epoch 641/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7780 - val_loss: 0.4719 - val_accuracy: 0.7867\n",
      "Epoch 642/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7832 - val_loss: 0.4639 - val_accuracy: 0.7885\n",
      "Epoch 643/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7787 - val_loss: 0.4669 - val_accuracy: 0.7867\n",
      "Epoch 644/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7811 - val_loss: 0.4659 - val_accuracy: 0.7885\n",
      "Epoch 645/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7818 - val_loss: 0.4588 - val_accuracy: 0.7867\n",
      "Epoch 646/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7791 - val_loss: 0.4544 - val_accuracy: 0.7885\n",
      "Epoch 647/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7791 - val_loss: 0.4591 - val_accuracy: 0.7903\n",
      "Epoch 648/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7807 - val_loss: 0.4609 - val_accuracy: 0.7876\n",
      "Epoch 649/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7865 - val_loss: 0.4594 - val_accuracy: 0.7912\n",
      "Epoch 650/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7854 - val_loss: 0.4654 - val_accuracy: 0.7823\n",
      "Epoch 651/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7841 - val_loss: 0.4625 - val_accuracy: 0.7849\n",
      "Epoch 652/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7867 - val_loss: 0.4571 - val_accuracy: 0.7805\n",
      "Epoch 653/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4511 - accuracy: 0.7849 - val_loss: 0.4581 - val_accuracy: 0.7876\n",
      "Epoch 654/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7858 - val_loss: 0.4514 - val_accuracy: 0.7778\n",
      "Epoch 655/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7807 - val_loss: 0.4562 - val_accuracy: 0.7966\n",
      "Epoch 656/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4504 - accuracy: 0.7852 - val_loss: 0.4590 - val_accuracy: 0.7876\n",
      "Epoch 657/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7832 - val_loss: 0.4593 - val_accuracy: 0.7778\n",
      "Epoch 658/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7870 - val_loss: 0.4573 - val_accuracy: 0.7921\n",
      "Epoch 659/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4508 - accuracy: 0.7897 - val_loss: 0.4582 - val_accuracy: 0.7841\n",
      "Epoch 660/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7847 - val_loss: 0.4510 - val_accuracy: 0.7796\n",
      "Epoch 661/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7834 - val_loss: 0.4504 - val_accuracy: 0.7912\n",
      "Epoch 662/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4638 - accuracy: 0.7796 - val_loss: 0.4556 - val_accuracy: 0.7867\n",
      "Epoch 663/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.7829 - val_loss: 0.4561 - val_accuracy: 0.7849\n",
      "Epoch 664/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.7834 - val_loss: 0.4514 - val_accuracy: 0.7867\n",
      "Epoch 665/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.4555 - val_accuracy: 0.7841\n",
      "Epoch 666/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7897 - val_loss: 0.4584 - val_accuracy: 0.7858\n",
      "Epoch 667/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7883 - val_loss: 0.4557 - val_accuracy: 0.7966\n",
      "Epoch 668/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7894 - val_loss: 0.4576 - val_accuracy: 0.7814\n",
      "Epoch 669/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7905 - val_loss: 0.4518 - val_accuracy: 0.7930\n",
      "Epoch 670/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7910 - val_loss: 0.4544 - val_accuracy: 0.7885\n",
      "Epoch 671/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7883 - val_loss: 0.4611 - val_accuracy: 0.7787\n",
      "Epoch 672/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7905 - val_loss: 0.4560 - val_accuracy: 0.7939\n",
      "Epoch 673/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7905 - val_loss: 0.4583 - val_accuracy: 0.7993\n",
      "Epoch 674/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.7897 - val_loss: 0.4546 - val_accuracy: 0.7939\n",
      "Epoch 675/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7894 - val_loss: 0.4542 - val_accuracy: 0.7912\n",
      "Epoch 676/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7919 - val_loss: 0.4544 - val_accuracy: 0.8011\n",
      "Epoch 677/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7914 - val_loss: 0.4696 - val_accuracy: 0.7724\n",
      "Epoch 678/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7847 - val_loss: 0.4475 - val_accuracy: 0.7957\n",
      "Epoch 679/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7935 - val_loss: 0.4650 - val_accuracy: 0.7787\n",
      "Epoch 680/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7908 - val_loss: 0.4604 - val_accuracy: 0.7832\n",
      "Epoch 681/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7888 - val_loss: 0.4559 - val_accuracy: 0.7921\n",
      "Epoch 682/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7908 - val_loss: 0.4736 - val_accuracy: 0.7500\n",
      "Epoch 683/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7800 - val_loss: 0.4570 - val_accuracy: 0.7858\n",
      "Epoch 684/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7903 - val_loss: 0.4748 - val_accuracy: 0.7518\n",
      "Epoch 685/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7892 - val_loss: 0.4791 - val_accuracy: 0.7590\n",
      "Epoch 686/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.4767 - val_accuracy: 0.7527\n",
      "Epoch 687/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7928 - val_loss: 0.4845 - val_accuracy: 0.7518\n",
      "Epoch 688/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7870 - val_loss: 0.4709 - val_accuracy: 0.7643\n",
      "Epoch 689/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.4762 - val_accuracy: 0.7608\n",
      "Epoch 690/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7879 - val_loss: 0.4731 - val_accuracy: 0.7670\n",
      "Epoch 691/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7894 - val_loss: 0.4740 - val_accuracy: 0.7670\n",
      "Epoch 692/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7858 - val_loss: 0.4634 - val_accuracy: 0.7832\n",
      "Epoch 693/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7863 - val_loss: 0.4551 - val_accuracy: 0.7957\n",
      "Epoch 694/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4676 - accuracy: 0.7811 - val_loss: 0.4656 - val_accuracy: 0.7867\n",
      "Epoch 695/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4561 - accuracy: 0.7854 - val_loss: 0.4581 - val_accuracy: 0.7894\n",
      "Epoch 696/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7841 - val_loss: 0.4592 - val_accuracy: 0.7903\n",
      "Epoch 697/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.7870 - val_loss: 0.4576 - val_accuracy: 0.7957\n",
      "Epoch 698/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.7836 - val_loss: 0.4500 - val_accuracy: 0.7984\n",
      "Epoch 699/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7832 - val_loss: 0.4490 - val_accuracy: 0.7867\n",
      "Epoch 700/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7854 - val_loss: 0.4503 - val_accuracy: 0.7939\n",
      "Epoch 701/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.7823 - val_loss: 0.4545 - val_accuracy: 0.7948\n",
      "Epoch 702/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4496 - val_accuracy: 0.7939\n",
      "Epoch 703/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7845 - val_loss: 0.4541 - val_accuracy: 0.7858\n",
      "Epoch 704/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7849 - val_loss: 0.4627 - val_accuracy: 0.7805\n",
      "Epoch 705/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7852 - val_loss: 0.4592 - val_accuracy: 0.7814\n",
      "Epoch 706/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.4571 - val_accuracy: 0.7858\n",
      "Epoch 707/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7733 - val_loss: 0.4623 - val_accuracy: 0.7778\n",
      "Epoch 708/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7820 - val_loss: 0.4591 - val_accuracy: 0.7832\n",
      "Epoch 709/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7863 - val_loss: 0.4599 - val_accuracy: 0.7894\n",
      "Epoch 710/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7836 - val_loss: 0.4606 - val_accuracy: 0.7849\n",
      "Epoch 711/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7802 - val_loss: 0.4580 - val_accuracy: 0.7885\n",
      "Epoch 712/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7829 - val_loss: 0.4600 - val_accuracy: 0.7814\n",
      "Epoch 713/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4592 - accuracy: 0.7807 - val_loss: 0.4850 - val_accuracy: 0.7608\n",
      "Epoch 714/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7811 - val_loss: 0.4744 - val_accuracy: 0.7670\n",
      "Epoch 715/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7883 - val_loss: 0.4646 - val_accuracy: 0.7787\n",
      "Epoch 716/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7856 - val_loss: 0.4630 - val_accuracy: 0.7769\n",
      "Epoch 717/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7870 - val_loss: 0.4601 - val_accuracy: 0.7823\n",
      "Epoch 718/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4537 - accuracy: 0.7841 - val_loss: 0.4676 - val_accuracy: 0.7769\n",
      "Epoch 719/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7888 - val_loss: 0.4649 - val_accuracy: 0.7715\n",
      "Epoch 720/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7858 - val_loss: 0.4651 - val_accuracy: 0.7814\n",
      "Epoch 721/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7849 - val_loss: 0.4728 - val_accuracy: 0.7643\n",
      "Epoch 722/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7834 - val_loss: 0.4745 - val_accuracy: 0.7724\n",
      "Epoch 723/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.7863 - val_loss: 0.4678 - val_accuracy: 0.7760\n",
      "Epoch 724/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7827 - val_loss: 0.4685 - val_accuracy: 0.7778\n",
      "Epoch 725/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4518 - accuracy: 0.7858 - val_loss: 0.4922 - val_accuracy: 0.7679\n",
      "Epoch 726/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7845 - val_loss: 0.4673 - val_accuracy: 0.7814\n",
      "Epoch 727/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4554 - accuracy: 0.7832 - val_loss: 0.4659 - val_accuracy: 0.7858\n",
      "Epoch 728/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7849 - val_loss: 0.4613 - val_accuracy: 0.7876\n",
      "Epoch 729/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4501 - accuracy: 0.7881 - val_loss: 0.4631 - val_accuracy: 0.7939\n",
      "Epoch 730/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7894 - val_loss: 0.4696 - val_accuracy: 0.8011\n",
      "Epoch 731/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4563 - accuracy: 0.7838 - val_loss: 0.4750 - val_accuracy: 0.7814\n",
      "Epoch 732/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4554 - accuracy: 0.7858 - val_loss: 0.4742 - val_accuracy: 0.7903\n",
      "Epoch 733/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4531 - accuracy: 0.7879 - val_loss: 0.4711 - val_accuracy: 0.7841\n",
      "Epoch 734/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7874 - val_loss: 0.4707 - val_accuracy: 0.7858\n",
      "Epoch 735/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4630 - val_accuracy: 0.7778\n",
      "Epoch 736/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7838 - val_loss: 0.4520 - val_accuracy: 0.7867\n",
      "Epoch 737/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7834 - val_loss: 0.4561 - val_accuracy: 0.7805\n",
      "Epoch 738/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7834 - val_loss: 0.4560 - val_accuracy: 0.7867\n",
      "Epoch 739/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7834 - val_loss: 0.4551 - val_accuracy: 0.7867\n",
      "Epoch 740/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7782 - val_loss: 0.4624 - val_accuracy: 0.7814\n",
      "Epoch 741/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7780 - val_loss: 0.4668 - val_accuracy: 0.7903\n",
      "Epoch 742/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7767 - val_loss: 0.4573 - val_accuracy: 0.7832\n",
      "Epoch 743/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7827 - val_loss: 0.4634 - val_accuracy: 0.7894\n",
      "Epoch 744/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4510 - accuracy: 0.7814 - val_loss: 0.4621 - val_accuracy: 0.7858\n",
      "Epoch 745/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7811 - val_loss: 0.4601 - val_accuracy: 0.7778\n",
      "Epoch 746/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7834 - val_loss: 0.4561 - val_accuracy: 0.7823\n",
      "Epoch 747/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7832 - val_loss: 0.4605 - val_accuracy: 0.7912\n",
      "Epoch 748/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7870 - val_loss: 0.4539 - val_accuracy: 0.7841\n",
      "Epoch 749/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7861 - val_loss: 0.4559 - val_accuracy: 0.7885\n",
      "Epoch 750/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7832 - val_loss: 0.4678 - val_accuracy: 0.7742\n",
      "Epoch 751/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4469 - accuracy: 0.7894 - val_loss: 0.4660 - val_accuracy: 0.7814\n",
      "Epoch 752/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4486 - accuracy: 0.7879 - val_loss: 0.4622 - val_accuracy: 0.7760\n",
      "Epoch 753/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.7897 - val_loss: 0.4578 - val_accuracy: 0.7858\n",
      "Epoch 754/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7901 - val_loss: 0.4612 - val_accuracy: 0.7894\n",
      "Epoch 755/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7890 - val_loss: 0.4623 - val_accuracy: 0.7921\n",
      "Epoch 756/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7897 - val_loss: 0.4636 - val_accuracy: 0.7814\n",
      "Epoch 757/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.7894 - val_loss: 0.4577 - val_accuracy: 0.7930\n",
      "Epoch 758/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7908 - val_loss: 0.4655 - val_accuracy: 0.7823\n",
      "Epoch 759/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7912 - val_loss: 0.4556 - val_accuracy: 0.7966\n",
      "Epoch 760/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7861 - val_loss: 0.4544 - val_accuracy: 0.7832\n",
      "Epoch 761/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7838 - val_loss: 0.4651 - val_accuracy: 0.7787\n",
      "Epoch 762/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7876 - val_loss: 0.4576 - val_accuracy: 0.7867\n",
      "Epoch 763/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7914 - val_loss: 0.4585 - val_accuracy: 0.7912\n",
      "Epoch 764/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4494 - accuracy: 0.7849 - val_loss: 0.4572 - val_accuracy: 0.7957\n",
      "Epoch 765/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4490 - accuracy: 0.7865 - val_loss: 0.4623 - val_accuracy: 0.7903\n",
      "Epoch 766/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.7845 - val_loss: 0.4560 - val_accuracy: 0.7921\n",
      "Epoch 767/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7883 - val_loss: 0.4616 - val_accuracy: 0.7858\n",
      "Epoch 768/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7863 - val_loss: 0.4536 - val_accuracy: 0.7939\n",
      "Epoch 769/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7843 - val_loss: 0.4594 - val_accuracy: 0.7930\n",
      "Epoch 770/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7883 - val_loss: 0.4568 - val_accuracy: 0.7867\n",
      "Epoch 771/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7856 - val_loss: 0.4611 - val_accuracy: 0.7885\n",
      "Epoch 772/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.4754 - val_accuracy: 0.7670\n",
      "Epoch 773/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7841 - val_loss: 0.4667 - val_accuracy: 0.7688\n",
      "Epoch 774/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7852 - val_loss: 0.4585 - val_accuracy: 0.7885\n",
      "Epoch 775/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7809 - val_loss: 0.4542 - val_accuracy: 0.8011\n",
      "Epoch 776/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7843 - val_loss: 0.4580 - val_accuracy: 0.7984\n",
      "Epoch 777/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7832 - val_loss: 0.4574 - val_accuracy: 0.7984\n",
      "Epoch 778/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7872 - val_loss: 0.4638 - val_accuracy: 0.7948\n",
      "Epoch 779/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7856 - val_loss: 0.4564 - val_accuracy: 0.7930\n",
      "Epoch 780/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7816 - val_loss: 0.4578 - val_accuracy: 0.7948\n",
      "Epoch 781/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7820 - val_loss: 0.4575 - val_accuracy: 0.7957\n",
      "Epoch 782/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7820 - val_loss: 0.4581 - val_accuracy: 0.7975\n",
      "Epoch 783/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7841 - val_loss: 0.4600 - val_accuracy: 0.7885\n",
      "Epoch 784/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7849 - val_loss: 0.4697 - val_accuracy: 0.7832\n",
      "Epoch 785/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7849 - val_loss: 0.4591 - val_accuracy: 0.7903\n",
      "Epoch 786/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7879 - val_loss: 0.4650 - val_accuracy: 0.7841\n",
      "Epoch 787/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.7881 - val_loss: 0.4728 - val_accuracy: 0.7706\n",
      "Epoch 788/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7876 - val_loss: 0.4704 - val_accuracy: 0.7796\n",
      "Epoch 789/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7843 - val_loss: 0.4621 - val_accuracy: 0.7867\n",
      "Epoch 790/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7861 - val_loss: 0.4634 - val_accuracy: 0.7805\n",
      "Epoch 791/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7784 - val_loss: 0.4657 - val_accuracy: 0.7814\n",
      "Epoch 792/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7816 - val_loss: 0.4646 - val_accuracy: 0.7823\n",
      "Epoch 793/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7769 - val_loss: 0.4612 - val_accuracy: 0.7733\n",
      "Epoch 794/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7796 - val_loss: 0.4611 - val_accuracy: 0.7823\n",
      "Epoch 795/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7789 - val_loss: 0.4622 - val_accuracy: 0.7796\n",
      "Epoch 796/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7771 - val_loss: 0.4789 - val_accuracy: 0.7751\n",
      "Epoch 797/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7814 - val_loss: 0.4666 - val_accuracy: 0.7778\n",
      "Epoch 798/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7820 - val_loss: 0.4648 - val_accuracy: 0.7849\n",
      "Epoch 799/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7805 - val_loss: 0.4728 - val_accuracy: 0.7841\n",
      "Epoch 800/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7858 - val_loss: 0.4803 - val_accuracy: 0.7670\n",
      "Epoch 801/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7832 - val_loss: 0.4664 - val_accuracy: 0.7823\n",
      "Epoch 802/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7858 - val_loss: 0.4664 - val_accuracy: 0.7867\n",
      "Epoch 803/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7870 - val_loss: 0.4689 - val_accuracy: 0.7814\n",
      "Epoch 804/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7849 - val_loss: 0.4773 - val_accuracy: 0.7867\n",
      "Epoch 805/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7843 - val_loss: 0.4721 - val_accuracy: 0.7805\n",
      "Epoch 806/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.7870 - val_loss: 0.4724 - val_accuracy: 0.7849\n",
      "Epoch 807/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7805 - val_loss: 0.4721 - val_accuracy: 0.7894\n",
      "Epoch 808/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7802 - val_loss: 0.4721 - val_accuracy: 0.7885\n",
      "Epoch 809/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7838 - val_loss: 0.4688 - val_accuracy: 0.7876\n",
      "Epoch 810/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 0.7883 - val_loss: 0.4672 - val_accuracy: 0.7885\n",
      "Epoch 811/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7885 - val_loss: 0.4724 - val_accuracy: 0.7841\n",
      "Epoch 812/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7879 - val_loss: 0.4702 - val_accuracy: 0.7858\n",
      "Epoch 813/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7883 - val_loss: 0.4644 - val_accuracy: 0.7903\n",
      "Epoch 814/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7914 - val_loss: 0.4700 - val_accuracy: 0.7903\n",
      "Epoch 815/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7899 - val_loss: 0.4666 - val_accuracy: 0.7885\n",
      "Epoch 816/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7903 - val_loss: 0.4696 - val_accuracy: 0.7858\n",
      "Epoch 817/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.4691 - val_accuracy: 0.7921\n",
      "Epoch 818/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7908 - val_loss: 0.4657 - val_accuracy: 0.7930\n",
      "Epoch 819/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7892 - val_loss: 0.4757 - val_accuracy: 0.7894\n",
      "Epoch 820/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 0.4725 - val_accuracy: 0.7858\n",
      "Epoch 821/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7903 - val_loss: 0.4610 - val_accuracy: 0.7894\n",
      "Epoch 822/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7881 - val_loss: 0.4638 - val_accuracy: 0.7876\n",
      "Epoch 823/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7908 - val_loss: 0.4671 - val_accuracy: 0.7903\n",
      "Epoch 824/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7908 - val_loss: 0.4677 - val_accuracy: 0.7796\n",
      "Epoch 825/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7914 - val_loss: 0.4679 - val_accuracy: 0.7796\n",
      "Epoch 826/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7919 - val_loss: 0.4686 - val_accuracy: 0.7867\n",
      "Epoch 827/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7883 - val_loss: 0.4610 - val_accuracy: 0.7849\n",
      "Epoch 828/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7874 - val_loss: 0.4634 - val_accuracy: 0.7849\n",
      "Epoch 829/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7912 - val_loss: 0.4640 - val_accuracy: 0.7858\n",
      "Epoch 830/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7894 - val_loss: 0.4732 - val_accuracy: 0.7858\n",
      "Epoch 831/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7930 - val_loss: 0.4636 - val_accuracy: 0.7805\n",
      "Epoch 832/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7903 - val_loss: 0.4700 - val_accuracy: 0.7787\n",
      "Epoch 833/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7888 - val_loss: 0.4648 - val_accuracy: 0.7849\n",
      "Epoch 834/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7892 - val_loss: 0.4615 - val_accuracy: 0.7867\n",
      "Epoch 835/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7885 - val_loss: 0.4636 - val_accuracy: 0.7849\n",
      "Epoch 836/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7849 - val_loss: 0.4596 - val_accuracy: 0.7903\n",
      "Epoch 837/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7838 - val_loss: 0.4629 - val_accuracy: 0.7823\n",
      "Epoch 838/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7885 - val_loss: 0.4696 - val_accuracy: 0.7823\n",
      "Epoch 839/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7863 - val_loss: 0.4637 - val_accuracy: 0.7921\n",
      "Epoch 840/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.7818 - val_loss: 0.4537 - val_accuracy: 0.7849\n",
      "Epoch 841/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7867 - val_loss: 0.4629 - val_accuracy: 0.7823\n",
      "Epoch 842/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7836 - val_loss: 0.4513 - val_accuracy: 0.7993\n",
      "Epoch 843/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7802 - val_loss: 0.4602 - val_accuracy: 0.7796\n",
      "Epoch 844/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7843 - val_loss: 0.4710 - val_accuracy: 0.7841\n",
      "Epoch 845/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7823 - val_loss: 0.4631 - val_accuracy: 0.7814\n",
      "Epoch 846/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7872 - val_loss: 0.4615 - val_accuracy: 0.7823\n",
      "Epoch 847/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7872 - val_loss: 0.4709 - val_accuracy: 0.7858\n",
      "Epoch 848/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7800 - val_loss: 0.4671 - val_accuracy: 0.7885\n",
      "Epoch 849/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7870 - val_loss: 0.4599 - val_accuracy: 0.7867\n",
      "Epoch 850/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7809 - val_loss: 0.4567 - val_accuracy: 0.7903\n",
      "Epoch 851/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7876 - val_loss: 0.4626 - val_accuracy: 0.7975\n",
      "Epoch 852/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7849 - val_loss: 0.4618 - val_accuracy: 0.7921\n",
      "Epoch 853/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7870 - val_loss: 0.4635 - val_accuracy: 0.7930\n",
      "Epoch 854/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7845 - val_loss: 0.4701 - val_accuracy: 0.7796\n",
      "Epoch 855/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7793 - val_loss: 0.4611 - val_accuracy: 0.7948\n",
      "Epoch 856/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.4620 - val_accuracy: 0.7885\n",
      "Epoch 857/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.7823 - val_loss: 0.4945 - val_accuracy: 0.7787\n",
      "Epoch 858/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4856 - val_accuracy: 0.7733\n",
      "Epoch 859/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7858 - val_loss: 0.4861 - val_accuracy: 0.7733\n",
      "Epoch 860/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7791 - val_loss: 0.4760 - val_accuracy: 0.7823\n",
      "Epoch 861/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7845 - val_loss: 0.4731 - val_accuracy: 0.7849\n",
      "Epoch 862/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7816 - val_loss: 0.4690 - val_accuracy: 0.7876\n",
      "Epoch 863/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4508 - accuracy: 0.7820 - val_loss: 0.4646 - val_accuracy: 0.7823\n",
      "Epoch 864/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7872 - val_loss: 0.4739 - val_accuracy: 0.7661\n",
      "Epoch 865/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4466 - accuracy: 0.7863 - val_loss: 0.4658 - val_accuracy: 0.7885\n",
      "Epoch 866/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7858 - val_loss: 0.4745 - val_accuracy: 0.7760\n",
      "Epoch 867/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4700 - val_accuracy: 0.7867\n",
      "Epoch 868/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7838 - val_loss: 0.4670 - val_accuracy: 0.7841\n",
      "Epoch 869/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7827 - val_loss: 0.4538 - val_accuracy: 0.7867\n",
      "Epoch 870/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4531 - accuracy: 0.7858 - val_loss: 0.4638 - val_accuracy: 0.7975\n",
      "Epoch 871/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.4615 - val_accuracy: 0.7858\n",
      "Epoch 872/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7876 - val_loss: 0.4630 - val_accuracy: 0.7823\n",
      "Epoch 873/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4707 - val_accuracy: 0.7769\n",
      "Epoch 874/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7883 - val_loss: 0.4689 - val_accuracy: 0.7814\n",
      "Epoch 875/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7852 - val_loss: 0.4744 - val_accuracy: 0.7679\n",
      "Epoch 876/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7892 - val_loss: 0.4714 - val_accuracy: 0.7769\n",
      "Epoch 877/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.7870 - val_loss: 0.4602 - val_accuracy: 0.7849\n",
      "Epoch 878/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7858 - val_loss: 0.4639 - val_accuracy: 0.7948\n",
      "Epoch 879/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7874 - val_loss: 0.4580 - val_accuracy: 0.7921\n",
      "Epoch 880/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7874 - val_loss: 0.4507 - val_accuracy: 0.7930\n",
      "Epoch 881/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7807 - val_loss: 0.4573 - val_accuracy: 0.7903\n",
      "Epoch 882/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7847 - val_loss: 0.4616 - val_accuracy: 0.7769\n",
      "Epoch 883/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7879 - val_loss: 0.4510 - val_accuracy: 0.7948\n",
      "Epoch 884/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7863 - val_loss: 0.4628 - val_accuracy: 0.7814\n",
      "Epoch 885/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.4606 - val_accuracy: 0.7876\n",
      "Epoch 886/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7903 - val_loss: 0.4553 - val_accuracy: 0.7921\n",
      "Epoch 887/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4471 - accuracy: 0.7838 - val_loss: 0.4578 - val_accuracy: 0.7957\n",
      "Epoch 888/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7872 - val_loss: 0.4664 - val_accuracy: 0.7885\n",
      "Epoch 889/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7820 - val_loss: 0.4560 - val_accuracy: 0.7876\n",
      "Epoch 890/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7849 - val_loss: 0.4530 - val_accuracy: 0.7984\n",
      "Epoch 891/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7838 - val_loss: 0.4540 - val_accuracy: 0.7921\n",
      "Epoch 892/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7841 - val_loss: 0.4600 - val_accuracy: 0.7921\n",
      "Epoch 893/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4514 - accuracy: 0.7865 - val_loss: 0.4581 - val_accuracy: 0.7903\n",
      "Epoch 894/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.4562 - val_accuracy: 0.7957\n",
      "Epoch 895/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7912 - val_loss: 0.4525 - val_accuracy: 0.7984\n",
      "Epoch 896/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7919 - val_loss: 0.4549 - val_accuracy: 0.8011\n",
      "Epoch 897/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7908 - val_loss: 0.4602 - val_accuracy: 0.7993\n",
      "Epoch 898/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7910 - val_loss: 0.4549 - val_accuracy: 0.7939\n",
      "Epoch 899/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7876 - val_loss: 0.4541 - val_accuracy: 0.8002\n",
      "Epoch 900/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4414 - accuracy: 0.7926 - val_loss: 0.4603 - val_accuracy: 0.7921\n",
      "Epoch 901/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7885 - val_loss: 0.4555 - val_accuracy: 0.8047\n",
      "Epoch 902/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4541 - val_accuracy: 0.7957\n",
      "Epoch 903/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7914 - val_loss: 0.4579 - val_accuracy: 0.7948\n",
      "Epoch 904/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7905 - val_loss: 0.4594 - val_accuracy: 0.7876\n",
      "Epoch 905/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7885 - val_loss: 0.4550 - val_accuracy: 0.8047\n",
      "Epoch 906/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7879 - val_loss: 0.4495 - val_accuracy: 0.7975\n",
      "Epoch 907/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7872 - val_loss: 0.4529 - val_accuracy: 0.8011\n",
      "Epoch 908/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7879 - val_loss: 0.4607 - val_accuracy: 0.7912\n",
      "Epoch 909/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7872 - val_loss: 0.4556 - val_accuracy: 0.7921\n",
      "Epoch 910/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7901 - val_loss: 0.4576 - val_accuracy: 0.7984\n",
      "Epoch 911/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7854 - val_loss: 0.4610 - val_accuracy: 0.7939\n",
      "Epoch 912/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7879 - val_loss: 0.4531 - val_accuracy: 0.7912\n",
      "Epoch 913/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7890 - val_loss: 0.4566 - val_accuracy: 0.8002\n",
      "Epoch 914/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4486 - accuracy: 0.7892 - val_loss: 0.4638 - val_accuracy: 0.7885\n",
      "Epoch 915/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7912 - val_loss: 0.4572 - val_accuracy: 0.7957\n",
      "Epoch 916/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7910 - val_loss: 0.4612 - val_accuracy: 0.7885\n",
      "Epoch 917/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7863 - val_loss: 0.4662 - val_accuracy: 0.7832\n",
      "Epoch 918/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4608 - val_accuracy: 0.7858\n",
      "Epoch 919/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7894 - val_loss: 0.4501 - val_accuracy: 0.7948\n",
      "Epoch 920/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7919 - val_loss: 0.4596 - val_accuracy: 0.7796\n",
      "Epoch 921/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7863 - val_loss: 0.4654 - val_accuracy: 0.7733\n",
      "Epoch 922/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7845 - val_loss: 0.4579 - val_accuracy: 0.7885\n",
      "Epoch 923/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7858 - val_loss: 0.4557 - val_accuracy: 0.7903\n",
      "Epoch 924/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7867 - val_loss: 0.4598 - val_accuracy: 0.7921\n",
      "Epoch 925/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7843 - val_loss: 0.4565 - val_accuracy: 0.7984\n",
      "Epoch 926/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7861 - val_loss: 0.4541 - val_accuracy: 0.7966\n",
      "Epoch 927/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7843 - val_loss: 0.4621 - val_accuracy: 0.8020\n",
      "Epoch 928/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7798 - val_loss: 0.4607 - val_accuracy: 0.7858\n",
      "Epoch 929/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7814 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 930/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7793 - val_loss: 0.4762 - val_accuracy: 0.7849\n",
      "Epoch 931/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7872 - val_loss: 0.4694 - val_accuracy: 0.7823\n",
      "Epoch 932/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7849 - val_loss: 0.4595 - val_accuracy: 0.7832\n",
      "Epoch 933/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7879 - val_loss: 0.4597 - val_accuracy: 0.7948\n",
      "Epoch 934/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7885 - val_loss: 0.4615 - val_accuracy: 0.7930\n",
      "Epoch 935/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7852 - val_loss: 0.4663 - val_accuracy: 0.7805\n",
      "Epoch 936/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.7867 - val_loss: 0.4719 - val_accuracy: 0.7841\n",
      "Epoch 937/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4687 - val_accuracy: 0.7814\n",
      "Epoch 938/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7811 - val_loss: 0.4668 - val_accuracy: 0.7858\n",
      "Epoch 939/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7894 - val_loss: 0.4676 - val_accuracy: 0.7876\n",
      "Epoch 940/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7874 - val_loss: 0.4727 - val_accuracy: 0.7814\n",
      "Epoch 941/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7894 - val_loss: 0.4639 - val_accuracy: 0.7894\n",
      "Epoch 942/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7852 - val_loss: 0.4630 - val_accuracy: 0.7939\n",
      "Epoch 943/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7838 - val_loss: 0.4882 - val_accuracy: 0.7751\n",
      "Epoch 944/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7791 - val_loss: 0.4734 - val_accuracy: 0.7858\n",
      "Epoch 945/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7811 - val_loss: 0.4561 - val_accuracy: 0.7894\n",
      "Epoch 946/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7827 - val_loss: 0.4560 - val_accuracy: 0.7841\n",
      "Epoch 947/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7845 - val_loss: 0.4556 - val_accuracy: 0.7849\n",
      "Epoch 948/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.7856 - val_loss: 0.4672 - val_accuracy: 0.7769\n",
      "Epoch 949/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7805 - val_loss: 0.4612 - val_accuracy: 0.7787\n",
      "Epoch 950/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7863 - val_loss: 0.4631 - val_accuracy: 0.7724\n",
      "Epoch 951/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7870 - val_loss: 0.4571 - val_accuracy: 0.7814\n",
      "Epoch 952/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7867 - val_loss: 0.4634 - val_accuracy: 0.7733\n",
      "Epoch 953/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7885 - val_loss: 0.4643 - val_accuracy: 0.7760\n",
      "Epoch 954/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.7872 - val_loss: 0.4542 - val_accuracy: 0.7823\n",
      "Epoch 955/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7892 - val_loss: 0.4623 - val_accuracy: 0.7832\n",
      "Epoch 956/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7883 - val_loss: 0.4616 - val_accuracy: 0.7787\n",
      "Epoch 957/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4528 - val_accuracy: 0.7885\n",
      "Epoch 958/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7845 - val_loss: 0.4558 - val_accuracy: 0.7823\n",
      "Epoch 959/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7863 - val_loss: 0.4633 - val_accuracy: 0.7823\n",
      "Epoch 960/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7854 - val_loss: 0.4528 - val_accuracy: 0.7796\n",
      "Epoch 961/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.4575 - val_accuracy: 0.7921\n",
      "Epoch 962/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7912 - val_loss: 0.4494 - val_accuracy: 0.7894\n",
      "Epoch 963/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7901 - val_loss: 0.4612 - val_accuracy: 0.7814\n",
      "Epoch 964/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7881 - val_loss: 0.4682 - val_accuracy: 0.7796\n",
      "Epoch 965/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7838 - val_loss: 0.4679 - val_accuracy: 0.7805\n",
      "Epoch 966/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4475 - accuracy: 0.7912 - val_loss: 0.4525 - val_accuracy: 0.7939\n",
      "Epoch 967/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7870 - val_loss: 0.4622 - val_accuracy: 0.7849\n",
      "Epoch 968/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7841 - val_loss: 0.4678 - val_accuracy: 0.7814\n",
      "Epoch 969/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7829 - val_loss: 0.4733 - val_accuracy: 0.7849\n",
      "Epoch 970/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7809 - val_loss: 0.4887 - val_accuracy: 0.7742\n",
      "Epoch 971/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7773 - val_loss: 0.4655 - val_accuracy: 0.7832\n",
      "Epoch 972/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7802 - val_loss: 0.4683 - val_accuracy: 0.7814\n",
      "Epoch 973/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7820 - val_loss: 0.4745 - val_accuracy: 0.7814\n",
      "Epoch 974/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7845 - val_loss: 0.4738 - val_accuracy: 0.7778\n",
      "Epoch 975/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4505 - accuracy: 0.7820 - val_loss: 0.5042 - val_accuracy: 0.7563\n",
      "Epoch 976/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7829 - val_loss: 0.4671 - val_accuracy: 0.7814\n",
      "Epoch 977/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.4648 - val_accuracy: 0.7769\n",
      "Epoch 978/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7838 - val_loss: 0.4679 - val_accuracy: 0.7742\n",
      "Epoch 979/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7838 - val_loss: 0.4659 - val_accuracy: 0.7823\n",
      "Epoch 980/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7798 - val_loss: 0.4633 - val_accuracy: 0.7760\n",
      "Epoch 981/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7838 - val_loss: 0.4627 - val_accuracy: 0.7823\n",
      "Epoch 982/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7802 - val_loss: 0.4843 - val_accuracy: 0.7616\n",
      "Epoch 983/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7836 - val_loss: 0.4639 - val_accuracy: 0.7778\n",
      "Epoch 984/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4693 - val_accuracy: 0.7805\n",
      "Epoch 985/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7776 - val_loss: 0.4738 - val_accuracy: 0.7697\n",
      "Epoch 986/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7843 - val_loss: 0.4651 - val_accuracy: 0.7814\n",
      "Epoch 987/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7845 - val_loss: 0.4632 - val_accuracy: 0.7903\n",
      "Epoch 988/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7838 - val_loss: 0.4750 - val_accuracy: 0.7805\n",
      "Epoch 989/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7879 - val_loss: 0.4601 - val_accuracy: 0.7885\n",
      "Epoch 990/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7858 - val_loss: 0.4632 - val_accuracy: 0.7805\n",
      "Epoch 991/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7894 - val_loss: 0.4752 - val_accuracy: 0.7894\n",
      "Epoch 992/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7870 - val_loss: 0.4710 - val_accuracy: 0.7751\n",
      "Epoch 993/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7863 - val_loss: 0.4634 - val_accuracy: 0.7814\n",
      "Epoch 994/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7858 - val_loss: 0.4826 - val_accuracy: 0.7805\n",
      "Epoch 995/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7905 - val_loss: 0.4780 - val_accuracy: 0.7885\n",
      "Epoch 996/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7919 - val_loss: 0.4662 - val_accuracy: 0.7778\n",
      "Epoch 997/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7935 - val_loss: 0.4692 - val_accuracy: 0.7849\n",
      "Epoch 998/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7948 - val_loss: 0.4650 - val_accuracy: 0.7975\n",
      "Epoch 999/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4582 - val_accuracy: 0.7921\n",
      "Epoch 1000/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7908 - val_loss: 0.4629 - val_accuracy: 0.7823\n",
      "Epoch 1001/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7888 - val_loss: 0.4688 - val_accuracy: 0.7814\n",
      "Epoch 1002/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7847 - val_loss: 0.4647 - val_accuracy: 0.7832\n",
      "Epoch 1003/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7923 - val_loss: 0.4719 - val_accuracy: 0.7616\n",
      "Epoch 1004/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4635 - val_accuracy: 0.7939\n",
      "Epoch 1005/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7892 - val_loss: 0.4626 - val_accuracy: 0.7849\n",
      "Epoch 1006/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7885 - val_loss: 0.4641 - val_accuracy: 0.7849\n",
      "Epoch 1007/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7885 - val_loss: 0.4653 - val_accuracy: 0.7832\n",
      "Epoch 1008/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7852 - val_loss: 0.4698 - val_accuracy: 0.7751\n",
      "Epoch 1009/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7874 - val_loss: 0.4586 - val_accuracy: 0.7858\n",
      "Epoch 1010/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7874 - val_loss: 0.4564 - val_accuracy: 0.7805\n",
      "Epoch 1011/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7908 - val_loss: 0.4595 - val_accuracy: 0.7805\n",
      "Epoch 1012/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7881 - val_loss: 0.4618 - val_accuracy: 0.7760\n",
      "Epoch 1013/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7854 - val_loss: 0.4582 - val_accuracy: 0.7903\n",
      "Epoch 1014/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7849 - val_loss: 0.4583 - val_accuracy: 0.7903\n",
      "Epoch 1015/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7832 - val_loss: 0.4578 - val_accuracy: 0.7939\n",
      "Epoch 1016/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7879 - val_loss: 0.4669 - val_accuracy: 0.7885\n",
      "Epoch 1017/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7832 - val_loss: 0.4578 - val_accuracy: 0.7858\n",
      "Epoch 1018/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7836 - val_loss: 0.4628 - val_accuracy: 0.7769\n",
      "Epoch 1019/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4563 - accuracy: 0.7793 - val_loss: 0.4691 - val_accuracy: 0.7841\n",
      "Epoch 1020/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7832 - val_loss: 0.4723 - val_accuracy: 0.7652\n",
      "Epoch 1021/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7832 - val_loss: 0.4638 - val_accuracy: 0.7867\n",
      "Epoch 1022/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7874 - val_loss: 0.4798 - val_accuracy: 0.7760\n",
      "Epoch 1023/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7807 - val_loss: 0.4569 - val_accuracy: 0.7814\n",
      "Epoch 1024/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.4698 - val_accuracy: 0.7814\n",
      "Epoch 1025/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7843 - val_loss: 0.4576 - val_accuracy: 0.7814\n",
      "Epoch 1026/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7890 - val_loss: 0.4673 - val_accuracy: 0.7841\n",
      "Epoch 1027/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7890 - val_loss: 0.4639 - val_accuracy: 0.7823\n",
      "Epoch 1028/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7914 - val_loss: 0.4626 - val_accuracy: 0.7867\n",
      "Epoch 1029/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7897 - val_loss: 0.4732 - val_accuracy: 0.7787\n",
      "Epoch 1030/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7724\n",
      "Epoch 1031/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7858 - val_loss: 0.4781 - val_accuracy: 0.7849\n",
      "Epoch 1032/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.7883 - val_loss: 0.4746 - val_accuracy: 0.7724\n",
      "Epoch 1033/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7858 - val_loss: 0.4673 - val_accuracy: 0.7823\n",
      "Epoch 1034/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7890 - val_loss: 0.4678 - val_accuracy: 0.7832\n",
      "Epoch 1035/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7872 - val_loss: 0.4740 - val_accuracy: 0.7742\n",
      "Epoch 1036/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7870 - val_loss: 0.4627 - val_accuracy: 0.7823\n",
      "Epoch 1037/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7894 - val_loss: 0.4657 - val_accuracy: 0.7876\n",
      "Epoch 1038/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7901 - val_loss: 0.4673 - val_accuracy: 0.7912\n",
      "Epoch 1039/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7885 - val_loss: 0.4684 - val_accuracy: 0.7823\n",
      "Epoch 1040/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7888 - val_loss: 0.4685 - val_accuracy: 0.7823\n",
      "Epoch 1041/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7892 - val_loss: 0.4721 - val_accuracy: 0.7832\n",
      "Epoch 1042/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7843 - val_loss: 0.4696 - val_accuracy: 0.7849\n",
      "Epoch 1043/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7845 - val_loss: 0.4693 - val_accuracy: 0.7894\n",
      "Epoch 1044/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7897 - val_loss: 0.4868 - val_accuracy: 0.7742\n",
      "Epoch 1045/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7841 - val_loss: 0.4824 - val_accuracy: 0.7670\n",
      "Epoch 1046/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7879 - val_loss: 0.4852 - val_accuracy: 0.7805\n",
      "Epoch 1047/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7858 - val_loss: 0.4829 - val_accuracy: 0.7796\n",
      "Epoch 1048/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7901 - val_loss: 0.4816 - val_accuracy: 0.7832\n",
      "Epoch 1049/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7872 - val_loss: 0.4979 - val_accuracy: 0.7608\n",
      "Epoch 1050/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7872 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1051/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7883 - val_loss: 0.5069 - val_accuracy: 0.7572\n",
      "Epoch 1052/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7879 - val_loss: 0.4738 - val_accuracy: 0.7823\n",
      "Epoch 1053/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7897 - val_loss: 0.4865 - val_accuracy: 0.7823\n",
      "Epoch 1054/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4861 - val_accuracy: 0.7724\n",
      "Epoch 1055/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7843 - val_loss: 0.4907 - val_accuracy: 0.7841\n",
      "Epoch 1056/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7854 - val_loss: 0.4729 - val_accuracy: 0.7805\n",
      "Epoch 1057/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.7856 - val_loss: 0.4797 - val_accuracy: 0.7858\n",
      "Epoch 1058/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7838 - val_loss: 0.4734 - val_accuracy: 0.7858\n",
      "Epoch 1059/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.7802 - val_loss: 0.4516 - val_accuracy: 0.7912\n",
      "Epoch 1060/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7809 - val_loss: 0.4669 - val_accuracy: 0.7787\n",
      "Epoch 1061/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7843 - val_loss: 0.4520 - val_accuracy: 0.7885\n",
      "Epoch 1062/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7867 - val_loss: 0.4466 - val_accuracy: 0.7885\n",
      "Epoch 1063/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7820 - val_loss: 0.4504 - val_accuracy: 0.7948\n",
      "Epoch 1064/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7863 - val_loss: 0.4523 - val_accuracy: 0.8020\n",
      "Epoch 1065/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7858 - val_loss: 0.4692 - val_accuracy: 0.7823\n",
      "Epoch 1066/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4583 - val_accuracy: 0.7930\n",
      "Epoch 1067/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7883 - val_loss: 0.4631 - val_accuracy: 0.7867\n",
      "Epoch 1068/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7964 - val_loss: 0.4490 - val_accuracy: 0.7966\n",
      "Epoch 1069/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4471 - accuracy: 0.7903 - val_loss: 0.4606 - val_accuracy: 0.8002\n",
      "Epoch 1070/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7897 - val_loss: 0.4663 - val_accuracy: 0.7894\n",
      "Epoch 1071/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7832 - val_loss: 0.4612 - val_accuracy: 0.7867\n",
      "Epoch 1072/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.4575 - val_accuracy: 0.7912\n",
      "Epoch 1073/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7897 - val_loss: 0.4544 - val_accuracy: 0.8056\n",
      "Epoch 1074/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7914 - val_loss: 0.4724 - val_accuracy: 0.7876\n",
      "Epoch 1075/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4514 - accuracy: 0.7876 - val_loss: 0.4601 - val_accuracy: 0.7885\n",
      "Epoch 1076/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.7912 - val_loss: 0.4609 - val_accuracy: 0.7867\n",
      "Epoch 1077/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.4550 - val_accuracy: 0.8002\n",
      "Epoch 1078/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7879 - val_loss: 0.4581 - val_accuracy: 0.8002\n",
      "Epoch 1079/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7923 - val_loss: 0.4557 - val_accuracy: 0.8002\n",
      "Epoch 1080/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7908 - val_loss: 0.4534 - val_accuracy: 0.7948\n",
      "Epoch 1081/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7892 - val_loss: 0.4574 - val_accuracy: 0.7984\n",
      "Epoch 1082/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7890 - val_loss: 0.4556 - val_accuracy: 0.7993\n",
      "Epoch 1083/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7890 - val_loss: 0.4533 - val_accuracy: 0.8002\n",
      "Epoch 1084/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7883 - val_loss: 0.4597 - val_accuracy: 0.7939\n",
      "Epoch 1085/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7867 - val_loss: 0.4624 - val_accuracy: 0.7903\n",
      "Epoch 1086/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7849 - val_loss: 0.4654 - val_accuracy: 0.7930\n",
      "Epoch 1087/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7863 - val_loss: 0.4785 - val_accuracy: 0.7715\n",
      "Epoch 1088/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7897 - val_loss: 0.4602 - val_accuracy: 0.7912\n",
      "Epoch 1089/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.7856 - val_loss: 0.4620 - val_accuracy: 0.8011\n",
      "Epoch 1090/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4454 - accuracy: 0.7901 - val_loss: 0.4554 - val_accuracy: 0.8029\n",
      "Epoch 1091/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7888 - val_loss: 0.4563 - val_accuracy: 0.7939\n",
      "Epoch 1092/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7892 - val_loss: 0.4548 - val_accuracy: 0.7966\n",
      "Epoch 1093/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7856 - val_loss: 0.4539 - val_accuracy: 0.7948\n",
      "Epoch 1094/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7854 - val_loss: 0.4538 - val_accuracy: 0.8002\n",
      "Epoch 1095/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7883 - val_loss: 0.4528 - val_accuracy: 0.8020\n",
      "Epoch 1096/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7841 - val_loss: 0.4565 - val_accuracy: 0.7948\n",
      "Epoch 1097/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7858 - val_loss: 0.4538 - val_accuracy: 0.7984\n",
      "Epoch 1098/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7845 - val_loss: 0.4542 - val_accuracy: 0.7975\n",
      "Epoch 1099/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7867 - val_loss: 0.4619 - val_accuracy: 0.7876\n",
      "Epoch 1100/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7872 - val_loss: 0.4565 - val_accuracy: 0.7841\n",
      "Epoch 1101/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7908 - val_loss: 0.4756 - val_accuracy: 0.7796\n",
      "Epoch 1102/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7867 - val_loss: 0.4603 - val_accuracy: 0.7867\n",
      "Epoch 1103/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7897 - val_loss: 0.4642 - val_accuracy: 0.7661\n",
      "Epoch 1104/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7912 - val_loss: 0.4685 - val_accuracy: 0.7823\n",
      "Epoch 1105/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7908 - val_loss: 0.4740 - val_accuracy: 0.7841\n",
      "Epoch 1106/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7879 - val_loss: 0.4528 - val_accuracy: 0.7921\n",
      "Epoch 1107/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7874 - val_loss: 0.4543 - val_accuracy: 0.7966\n",
      "Epoch 1108/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7879 - val_loss: 0.4508 - val_accuracy: 0.8038\n",
      "Epoch 1109/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7883 - val_loss: 0.4535 - val_accuracy: 0.7957\n",
      "Epoch 1110/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7872 - val_loss: 0.4536 - val_accuracy: 0.7948\n",
      "Epoch 1111/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7867 - val_loss: 0.4579 - val_accuracy: 0.7921\n",
      "Epoch 1112/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7838 - val_loss: 0.4611 - val_accuracy: 0.7903\n",
      "Epoch 1113/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7834 - val_loss: 0.4529 - val_accuracy: 0.7966\n",
      "Epoch 1114/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7883 - val_loss: 0.4539 - val_accuracy: 0.7930\n",
      "Epoch 1115/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7908 - val_loss: 0.4685 - val_accuracy: 0.7796\n",
      "Epoch 1116/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.4721 - val_accuracy: 0.7805\n",
      "Epoch 1117/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7890 - val_loss: 0.4531 - val_accuracy: 0.7966\n",
      "Epoch 1118/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7881 - val_loss: 0.4597 - val_accuracy: 0.7957\n",
      "Epoch 1119/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7894 - val_loss: 0.4618 - val_accuracy: 0.7841\n",
      "Epoch 1120/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4663 - val_accuracy: 0.7706\n",
      "Epoch 1121/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7872 - val_loss: 0.5009 - val_accuracy: 0.7616\n",
      "Epoch 1122/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7863 - val_loss: 0.4597 - val_accuracy: 0.7796\n",
      "Epoch 1123/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7872 - val_loss: 0.4554 - val_accuracy: 0.7832\n",
      "Epoch 1124/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7914 - val_loss: 0.4621 - val_accuracy: 0.7787\n",
      "Epoch 1125/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7892 - val_loss: 0.4536 - val_accuracy: 0.7930\n",
      "Epoch 1126/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7919 - val_loss: 0.4633 - val_accuracy: 0.7778\n",
      "Epoch 1127/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7897 - val_loss: 0.4520 - val_accuracy: 0.7912\n",
      "Epoch 1128/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.7912 - val_loss: 0.4524 - val_accuracy: 0.7930\n",
      "Epoch 1129/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7892 - val_loss: 0.4600 - val_accuracy: 0.7814\n",
      "Epoch 1130/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7926 - val_loss: 0.4511 - val_accuracy: 0.8020\n",
      "Epoch 1131/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7923 - val_loss: 0.4527 - val_accuracy: 0.7912\n",
      "Epoch 1132/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7939 - val_loss: 0.4483 - val_accuracy: 0.7921\n",
      "Epoch 1133/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7897 - val_loss: 0.4610 - val_accuracy: 0.7903\n",
      "Epoch 1134/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7870 - val_loss: 0.4557 - val_accuracy: 0.7939\n",
      "Epoch 1135/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7919 - val_loss: 0.4465 - val_accuracy: 0.8038\n",
      "Epoch 1136/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7919 - val_loss: 0.4571 - val_accuracy: 0.7930\n",
      "Epoch 1137/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7923 - val_loss: 0.4621 - val_accuracy: 0.7912\n",
      "Epoch 1138/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7919 - val_loss: 0.4604 - val_accuracy: 0.7832\n",
      "Epoch 1139/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7892 - val_loss: 0.4741 - val_accuracy: 0.7742\n",
      "Epoch 1140/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7912 - val_loss: 0.4698 - val_accuracy: 0.7679\n",
      "Epoch 1141/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7897 - val_loss: 0.4747 - val_accuracy: 0.7858\n",
      "Epoch 1142/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.4452 - val_accuracy: 0.8011\n",
      "Epoch 1143/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7923 - val_loss: 0.4563 - val_accuracy: 0.7912\n",
      "Epoch 1144/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7908 - val_loss: 0.4603 - val_accuracy: 0.7975\n",
      "Epoch 1145/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7897 - val_loss: 0.4563 - val_accuracy: 0.7841\n",
      "Epoch 1146/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7881 - val_loss: 0.4477 - val_accuracy: 0.7993\n",
      "Epoch 1147/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.7874 - val_loss: 0.4678 - val_accuracy: 0.7805\n",
      "Epoch 1148/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4426 - accuracy: 0.7879 - val_loss: 0.4676 - val_accuracy: 0.7778\n",
      "Epoch 1149/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7872 - val_loss: 0.4754 - val_accuracy: 0.7823\n",
      "Epoch 1150/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7888 - val_loss: 0.4764 - val_accuracy: 0.7643\n",
      "Epoch 1151/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7816 - val_loss: 0.4837 - val_accuracy: 0.7894\n",
      "Epoch 1152/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7800 - val_loss: 0.4788 - val_accuracy: 0.7876\n",
      "Epoch 1153/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7845 - val_loss: 0.4672 - val_accuracy: 0.7849\n",
      "Epoch 1154/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7836 - val_loss: 0.4758 - val_accuracy: 0.7867\n",
      "Epoch 1155/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4575 - accuracy: 0.7764 - val_loss: 0.4730 - val_accuracy: 0.7787\n",
      "Epoch 1156/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7744 - val_loss: 0.4635 - val_accuracy: 0.7778\n",
      "Epoch 1157/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7834 - val_loss: 0.4711 - val_accuracy: 0.7760\n",
      "Epoch 1158/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7845 - val_loss: 0.4572 - val_accuracy: 0.7841\n",
      "Epoch 1159/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7903 - val_loss: 0.4634 - val_accuracy: 0.7858\n",
      "Epoch 1160/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4536 - accuracy: 0.7870 - val_loss: 0.4742 - val_accuracy: 0.7814\n",
      "Epoch 1161/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.7849 - val_loss: 0.4674 - val_accuracy: 0.7814\n",
      "Epoch 1162/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.7861 - val_loss: 0.4665 - val_accuracy: 0.7849\n",
      "Epoch 1163/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7854 - val_loss: 0.4651 - val_accuracy: 0.7832\n",
      "Epoch 1164/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.4684 - val_accuracy: 0.7832\n",
      "Epoch 1165/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7827 - val_loss: 0.4758 - val_accuracy: 0.7787\n",
      "Epoch 1166/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7836 - val_loss: 0.4651 - val_accuracy: 0.7841\n",
      "Epoch 1167/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7863 - val_loss: 0.4731 - val_accuracy: 0.7778\n",
      "Epoch 1168/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7823 - val_loss: 0.4637 - val_accuracy: 0.7858\n",
      "Epoch 1169/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.4669 - val_accuracy: 0.7823\n",
      "Epoch 1170/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7914 - val_loss: 0.4554 - val_accuracy: 0.7894\n",
      "Epoch 1171/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7901 - val_loss: 0.4560 - val_accuracy: 0.7823\n",
      "Epoch 1172/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7908 - val_loss: 0.4537 - val_accuracy: 0.7984\n",
      "Epoch 1173/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7870 - val_loss: 0.4552 - val_accuracy: 0.7876\n",
      "Epoch 1174/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7901 - val_loss: 0.4506 - val_accuracy: 0.7876\n",
      "Epoch 1175/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7930 - val_loss: 0.4658 - val_accuracy: 0.7894\n",
      "Epoch 1176/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7919 - val_loss: 0.4568 - val_accuracy: 0.7858\n",
      "Epoch 1177/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7883 - val_loss: 0.4557 - val_accuracy: 0.7957\n",
      "Epoch 1178/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7941 - val_loss: 0.4579 - val_accuracy: 0.7903\n",
      "Epoch 1179/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7948 - val_loss: 0.4635 - val_accuracy: 0.7885\n",
      "Epoch 1180/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7923 - val_loss: 0.4565 - val_accuracy: 0.7867\n",
      "Epoch 1181/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7888 - val_loss: 0.4535 - val_accuracy: 0.7930\n",
      "Epoch 1182/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7953 - val_loss: 0.4675 - val_accuracy: 0.7885\n",
      "Epoch 1183/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7953 - val_loss: 0.4686 - val_accuracy: 0.7876\n",
      "Epoch 1184/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7941 - val_loss: 0.4617 - val_accuracy: 0.7912\n",
      "Epoch 1185/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7926 - val_loss: 0.4587 - val_accuracy: 0.7885\n",
      "Epoch 1186/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4622 - val_accuracy: 0.7867\n",
      "Epoch 1187/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4685 - val_accuracy: 0.7796\n",
      "Epoch 1188/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7890 - val_loss: 0.4700 - val_accuracy: 0.7751\n",
      "Epoch 1189/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4744 - val_accuracy: 0.7760\n",
      "Epoch 1190/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7910 - val_loss: 0.4721 - val_accuracy: 0.7796\n",
      "Epoch 1191/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7838 - val_loss: 0.4646 - val_accuracy: 0.7849\n",
      "Epoch 1192/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.4567 - val_accuracy: 0.7894\n",
      "Epoch 1193/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7888 - val_loss: 0.4573 - val_accuracy: 0.7849\n",
      "Epoch 1194/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4606 - val_accuracy: 0.7832\n",
      "Epoch 1195/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7832 - val_loss: 0.4641 - val_accuracy: 0.7858\n",
      "Epoch 1196/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7836 - val_loss: 0.4596 - val_accuracy: 0.7841\n",
      "Epoch 1197/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7858 - val_loss: 0.4502 - val_accuracy: 0.7930\n",
      "Epoch 1198/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.4530 - val_accuracy: 0.7814\n",
      "Epoch 1199/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7910 - val_loss: 0.4546 - val_accuracy: 0.7867\n",
      "Epoch 1200/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7867 - val_loss: 0.4533 - val_accuracy: 0.7805\n",
      "Epoch 1201/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7932 - val_loss: 0.4662 - val_accuracy: 0.7930\n",
      "Epoch 1202/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7930 - val_loss: 0.4660 - val_accuracy: 0.7885\n",
      "Epoch 1203/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7919 - val_loss: 0.4517 - val_accuracy: 0.7939\n",
      "Epoch 1204/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4395 - accuracy: 0.7926 - val_loss: 0.4525 - val_accuracy: 0.7823\n",
      "Epoch 1205/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7888 - val_loss: 0.4576 - val_accuracy: 0.7921\n",
      "Epoch 1206/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7932 - val_loss: 0.4527 - val_accuracy: 0.7903\n",
      "Epoch 1207/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7912 - val_loss: 0.4631 - val_accuracy: 0.7823\n",
      "Epoch 1208/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7874 - val_loss: 0.4608 - val_accuracy: 0.7912\n",
      "Epoch 1209/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7890 - val_loss: 0.4645 - val_accuracy: 0.7912\n",
      "Epoch 1210/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7876 - val_loss: 0.4550 - val_accuracy: 0.7832\n",
      "Epoch 1211/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7901 - val_loss: 0.4552 - val_accuracy: 0.7841\n",
      "Epoch 1212/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.4561 - val_accuracy: 0.7867\n",
      "Epoch 1213/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4591 - val_accuracy: 0.7867\n",
      "Epoch 1214/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7876 - val_loss: 0.4552 - val_accuracy: 0.7921\n",
      "Epoch 1215/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7897 - val_loss: 0.4521 - val_accuracy: 0.7894\n",
      "Epoch 1216/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7883 - val_loss: 0.4576 - val_accuracy: 0.7876\n",
      "Epoch 1217/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7861 - val_loss: 0.4538 - val_accuracy: 0.7867\n",
      "Epoch 1218/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7856 - val_loss: 0.4571 - val_accuracy: 0.7832\n",
      "Epoch 1219/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7888 - val_loss: 0.4621 - val_accuracy: 0.7894\n",
      "Epoch 1220/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7888 - val_loss: 0.4570 - val_accuracy: 0.7841\n",
      "Epoch 1221/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7852 - val_loss: 0.4558 - val_accuracy: 0.7796\n",
      "Epoch 1222/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7836 - val_loss: 0.4687 - val_accuracy: 0.7849\n",
      "Epoch 1223/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7841 - val_loss: 0.4566 - val_accuracy: 0.7885\n",
      "Epoch 1224/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7845 - val_loss: 0.4566 - val_accuracy: 0.7939\n",
      "Epoch 1225/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7854 - val_loss: 0.4728 - val_accuracy: 0.7903\n",
      "Epoch 1226/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7863 - val_loss: 0.4724 - val_accuracy: 0.7894\n",
      "Epoch 1227/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7863 - val_loss: 0.4751 - val_accuracy: 0.7885\n",
      "Epoch 1228/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7829 - val_loss: 0.4756 - val_accuracy: 0.7876\n",
      "Epoch 1229/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7856 - val_loss: 0.4631 - val_accuracy: 0.7876\n",
      "Epoch 1230/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7863 - val_loss: 0.4622 - val_accuracy: 0.7930\n",
      "Epoch 1231/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7910 - val_loss: 0.4769 - val_accuracy: 0.7599\n",
      "Epoch 1232/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7901 - val_loss: 0.4712 - val_accuracy: 0.7724\n",
      "Epoch 1233/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7897 - val_loss: 0.4726 - val_accuracy: 0.7652\n",
      "Epoch 1234/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7843 - val_loss: 0.4605 - val_accuracy: 0.7939\n",
      "Epoch 1235/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7881 - val_loss: 0.4554 - val_accuracy: 0.7867\n",
      "Epoch 1236/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7897 - val_loss: 0.4558 - val_accuracy: 0.7966\n",
      "Epoch 1237/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7883 - val_loss: 0.4624 - val_accuracy: 0.7957\n",
      "Epoch 1238/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7881 - val_loss: 0.4574 - val_accuracy: 0.7939\n",
      "Epoch 1239/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7863 - val_loss: 0.4607 - val_accuracy: 0.7921\n",
      "Epoch 1240/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7870 - val_loss: 0.4613 - val_accuracy: 0.7993\n",
      "Epoch 1241/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7894 - val_loss: 0.4600 - val_accuracy: 0.7832\n",
      "Epoch 1242/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7854 - val_loss: 0.4634 - val_accuracy: 0.7948\n",
      "Epoch 1243/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7863 - val_loss: 0.4549 - val_accuracy: 0.7894\n",
      "Epoch 1244/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7892 - val_loss: 0.4593 - val_accuracy: 0.7903\n",
      "Epoch 1245/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7870 - val_loss: 0.4587 - val_accuracy: 0.7858\n",
      "Epoch 1246/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7832 - val_loss: 0.4636 - val_accuracy: 0.7841\n",
      "Epoch 1247/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7825 - val_loss: 0.4646 - val_accuracy: 0.7787\n",
      "Epoch 1248/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4503 - accuracy: 0.7867 - val_loss: 0.4686 - val_accuracy: 0.7760\n",
      "Epoch 1249/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.7888 - val_loss: 0.4710 - val_accuracy: 0.7832\n",
      "Epoch 1250/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7908 - val_loss: 0.4954 - val_accuracy: 0.7572\n",
      "Epoch 1251/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7890 - val_loss: 0.4752 - val_accuracy: 0.7867\n",
      "Epoch 1252/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7930 - val_loss: 0.4698 - val_accuracy: 0.7823\n",
      "Epoch 1253/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7881 - val_loss: 0.4637 - val_accuracy: 0.7885\n",
      "Epoch 1254/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7527\n",
      "Epoch 1255/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7901 - val_loss: 0.4557 - val_accuracy: 0.7930\n",
      "Epoch 1256/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7903 - val_loss: 0.4615 - val_accuracy: 0.7867\n",
      "Epoch 1257/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7914 - val_loss: 0.4723 - val_accuracy: 0.7930\n",
      "Epoch 1258/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7973 - val_loss: 0.4713 - val_accuracy: 0.7894\n",
      "Epoch 1259/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7881 - val_loss: 0.4639 - val_accuracy: 0.7796\n",
      "Epoch 1260/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7885 - val_loss: 0.4636 - val_accuracy: 0.7912\n",
      "Epoch 1261/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7885 - val_loss: 0.4614 - val_accuracy: 0.7930\n",
      "Epoch 1262/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7876 - val_loss: 0.4601 - val_accuracy: 0.7993\n",
      "Epoch 1263/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.4615 - val_accuracy: 0.7948\n",
      "Epoch 1264/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7908 - val_loss: 0.4605 - val_accuracy: 0.8020\n",
      "Epoch 1265/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4511 - accuracy: 0.7841 - val_loss: 0.4884 - val_accuracy: 0.7554\n",
      "Epoch 1266/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7811 - val_loss: 0.4604 - val_accuracy: 0.7975\n",
      "Epoch 1267/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7845 - val_loss: 0.4599 - val_accuracy: 0.7957\n",
      "Epoch 1268/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.7897 - val_loss: 0.4562 - val_accuracy: 0.7948\n",
      "Epoch 1269/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7841 - val_loss: 0.4588 - val_accuracy: 0.7858\n",
      "Epoch 1270/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7849 - val_loss: 0.4601 - val_accuracy: 0.7948\n",
      "Epoch 1271/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7872 - val_loss: 0.4511 - val_accuracy: 0.7939\n",
      "Epoch 1272/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7908 - val_loss: 0.4551 - val_accuracy: 0.7903\n",
      "Epoch 1273/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7890 - val_loss: 0.4536 - val_accuracy: 0.7903\n",
      "Epoch 1274/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4569 - val_accuracy: 0.7894\n",
      "Epoch 1275/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7905 - val_loss: 0.4497 - val_accuracy: 0.7939\n",
      "Epoch 1276/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7863 - val_loss: 0.4534 - val_accuracy: 0.7939\n",
      "Epoch 1277/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7879 - val_loss: 0.4662 - val_accuracy: 0.7769\n",
      "Epoch 1278/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7890 - val_loss: 0.4451 - val_accuracy: 0.8002\n",
      "Epoch 1279/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.7885 - val_loss: 0.4636 - val_accuracy: 0.7984\n",
      "Epoch 1280/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7905 - val_loss: 0.4531 - val_accuracy: 0.7966\n",
      "Epoch 1281/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7908 - val_loss: 0.4610 - val_accuracy: 0.7912\n",
      "Epoch 1282/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7854 - val_loss: 0.4559 - val_accuracy: 0.7957\n",
      "Epoch 1283/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7890 - val_loss: 0.4709 - val_accuracy: 0.7841\n",
      "Epoch 1284/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4501 - val_accuracy: 0.7993\n",
      "Epoch 1285/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7892 - val_loss: 0.4489 - val_accuracy: 0.7930\n",
      "Epoch 1286/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7910 - val_loss: 0.4451 - val_accuracy: 0.8047\n",
      "Epoch 1287/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7919 - val_loss: 0.4547 - val_accuracy: 0.7867\n",
      "Epoch 1288/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7872 - val_loss: 0.4622 - val_accuracy: 0.7885\n",
      "Epoch 1289/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7890 - val_loss: 0.4594 - val_accuracy: 0.7796\n",
      "Epoch 1290/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4451 - accuracy: 0.7876 - val_loss: 0.4506 - val_accuracy: 0.7876\n",
      "Epoch 1291/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7892 - val_loss: 0.4589 - val_accuracy: 0.7832\n",
      "Epoch 1292/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7854 - val_loss: 0.4477 - val_accuracy: 0.8020\n",
      "Epoch 1293/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7901 - val_loss: 0.4509 - val_accuracy: 0.7966\n",
      "Epoch 1294/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7885 - val_loss: 0.4556 - val_accuracy: 0.7921\n",
      "Epoch 1295/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7890 - val_loss: 0.4523 - val_accuracy: 0.7957\n",
      "Epoch 1296/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7926 - val_loss: 0.4598 - val_accuracy: 0.7930\n",
      "Epoch 1297/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7912 - val_loss: 0.4528 - val_accuracy: 0.7903\n",
      "Epoch 1298/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7923 - val_loss: 0.4561 - val_accuracy: 0.7858\n",
      "Epoch 1299/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7894 - val_loss: 0.4515 - val_accuracy: 0.7814\n",
      "Epoch 1300/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7919 - val_loss: 0.4536 - val_accuracy: 0.7876\n",
      "Epoch 1301/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7863 - val_loss: 0.4563 - val_accuracy: 0.7903\n",
      "Epoch 1302/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7874 - val_loss: 0.4518 - val_accuracy: 0.7966\n",
      "Epoch 1303/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7879 - val_loss: 0.4473 - val_accuracy: 0.7966\n",
      "Epoch 1304/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7863 - val_loss: 0.4452 - val_accuracy: 0.7957\n",
      "Epoch 1305/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7912 - val_loss: 0.4474 - val_accuracy: 0.7921\n",
      "Epoch 1306/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.4522 - val_accuracy: 0.7948\n",
      "Epoch 1307/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7937 - val_loss: 0.4494 - val_accuracy: 0.7921\n",
      "Epoch 1308/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7912 - val_loss: 0.4485 - val_accuracy: 0.7966\n",
      "Epoch 1309/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7897 - val_loss: 0.4499 - val_accuracy: 0.7948\n",
      "Epoch 1310/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.7879 - val_loss: 0.4650 - val_accuracy: 0.7832\n",
      "Epoch 1311/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4486 - val_accuracy: 0.7912\n",
      "Epoch 1312/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7867 - val_loss: 0.4539 - val_accuracy: 0.7832\n",
      "Epoch 1313/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7921 - val_loss: 0.4585 - val_accuracy: 0.7930\n",
      "Epoch 1314/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4576 - val_accuracy: 0.7876\n",
      "Epoch 1315/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.4655 - val_accuracy: 0.7885\n",
      "Epoch 1316/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7874 - val_loss: 0.4567 - val_accuracy: 0.7939\n",
      "Epoch 1317/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7894 - val_loss: 0.4720 - val_accuracy: 0.7823\n",
      "Epoch 1318/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7885 - val_loss: 0.5048 - val_accuracy: 0.7661\n",
      "Epoch 1319/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7809 - val_loss: 0.4590 - val_accuracy: 0.7903\n",
      "Epoch 1320/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7867 - val_loss: 0.4681 - val_accuracy: 0.7885\n",
      "Epoch 1321/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7881 - val_loss: 0.4632 - val_accuracy: 0.7841\n",
      "Epoch 1322/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7908 - val_loss: 0.4674 - val_accuracy: 0.7832\n",
      "Epoch 1323/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7901 - val_loss: 0.4576 - val_accuracy: 0.7867\n",
      "Epoch 1324/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7944 - val_loss: 0.4588 - val_accuracy: 0.7867\n",
      "Epoch 1325/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.7930 - val_loss: 0.4641 - val_accuracy: 0.7849\n",
      "Epoch 1326/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7901 - val_loss: 0.4701 - val_accuracy: 0.7769\n",
      "Epoch 1327/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.7919 - val_loss: 0.4682 - val_accuracy: 0.7760\n",
      "Epoch 1328/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7890 - val_loss: 0.4648 - val_accuracy: 0.7885\n",
      "Epoch 1329/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7914 - val_loss: 0.4701 - val_accuracy: 0.7769\n",
      "Epoch 1330/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7908 - val_loss: 0.4718 - val_accuracy: 0.7849\n",
      "Epoch 1331/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7908 - val_loss: 0.4670 - val_accuracy: 0.7903\n",
      "Epoch 1332/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7930 - val_loss: 0.4632 - val_accuracy: 0.7841\n",
      "Epoch 1333/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7921 - val_loss: 0.4685 - val_accuracy: 0.7849\n",
      "Epoch 1334/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.4631 - val_accuracy: 0.7841\n",
      "Epoch 1335/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7843 - val_loss: 0.4574 - val_accuracy: 0.7921\n",
      "Epoch 1336/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7872 - val_loss: 0.4538 - val_accuracy: 0.7921\n",
      "Epoch 1337/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7836 - val_loss: 0.4595 - val_accuracy: 0.7858\n",
      "Epoch 1338/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7870 - val_loss: 0.4591 - val_accuracy: 0.7841\n",
      "Epoch 1339/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7861 - val_loss: 0.4580 - val_accuracy: 0.7858\n",
      "Epoch 1340/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7901 - val_loss: 0.4570 - val_accuracy: 0.7903\n",
      "Epoch 1341/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4457 - accuracy: 0.7872 - val_loss: 0.4605 - val_accuracy: 0.7823\n",
      "Epoch 1342/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7845 - val_loss: 0.4622 - val_accuracy: 0.7894\n",
      "Epoch 1343/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7881 - val_loss: 0.4564 - val_accuracy: 0.7858\n",
      "Epoch 1344/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.4586 - val_accuracy: 0.7841\n",
      "Epoch 1345/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7888 - val_loss: 0.4654 - val_accuracy: 0.7841\n",
      "Epoch 1346/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7946 - val_loss: 0.4538 - val_accuracy: 0.7876\n",
      "Epoch 1347/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7888 - val_loss: 0.4571 - val_accuracy: 0.7894\n",
      "Epoch 1348/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7908 - val_loss: 0.4549 - val_accuracy: 0.7814\n",
      "Epoch 1349/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4541 - val_accuracy: 0.7894\n",
      "Epoch 1350/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7903 - val_loss: 0.4513 - val_accuracy: 0.7867\n",
      "Epoch 1351/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7908 - val_loss: 0.4614 - val_accuracy: 0.7867\n",
      "Epoch 1352/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7930 - val_loss: 0.4606 - val_accuracy: 0.7832\n",
      "Epoch 1353/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7903 - val_loss: 0.4674 - val_accuracy: 0.7823\n",
      "Epoch 1354/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7876 - val_loss: 0.4653 - val_accuracy: 0.7814\n",
      "Epoch 1355/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7852 - val_loss: 0.4657 - val_accuracy: 0.7733\n",
      "Epoch 1356/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7838 - val_loss: 0.4636 - val_accuracy: 0.7634\n",
      "Epoch 1357/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7852 - val_loss: 0.4609 - val_accuracy: 0.7805\n",
      "Epoch 1358/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7838 - val_loss: 0.4718 - val_accuracy: 0.7715\n",
      "Epoch 1359/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7856 - val_loss: 0.4766 - val_accuracy: 0.7590\n",
      "Epoch 1360/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.4707 - val_accuracy: 0.7715\n",
      "Epoch 1361/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7861 - val_loss: 0.4997 - val_accuracy: 0.7634\n",
      "Epoch 1362/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7836 - val_loss: 0.4740 - val_accuracy: 0.7608\n",
      "Epoch 1363/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7834 - val_loss: 0.4727 - val_accuracy: 0.7751\n",
      "Epoch 1364/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.4633 - val_accuracy: 0.7778\n",
      "Epoch 1365/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7858 - val_loss: 0.4741 - val_accuracy: 0.7706\n",
      "Epoch 1366/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7879 - val_loss: 0.4795 - val_accuracy: 0.7742\n",
      "Epoch 1367/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7885 - val_loss: 0.4645 - val_accuracy: 0.7805\n",
      "Epoch 1368/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7870 - val_loss: 0.4788 - val_accuracy: 0.7572\n",
      "Epoch 1369/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7874 - val_loss: 0.4617 - val_accuracy: 0.7832\n",
      "Epoch 1370/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7908 - val_loss: 0.4716 - val_accuracy: 0.7814\n",
      "Epoch 1371/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.4639 - val_accuracy: 0.7885\n",
      "Epoch 1372/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7870 - val_loss: 0.4622 - val_accuracy: 0.7876\n",
      "Epoch 1373/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7890 - val_loss: 0.4676 - val_accuracy: 0.7912\n",
      "Epoch 1374/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7876 - val_loss: 0.4634 - val_accuracy: 0.7894\n",
      "Epoch 1375/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7901 - val_loss: 0.4643 - val_accuracy: 0.7903\n",
      "Epoch 1376/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7881 - val_loss: 0.4592 - val_accuracy: 0.7858\n",
      "Epoch 1377/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7849 - val_loss: 0.4575 - val_accuracy: 0.8020\n",
      "Epoch 1378/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7892 - val_loss: 0.4608 - val_accuracy: 0.7966\n",
      "Epoch 1379/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4422 - accuracy: 0.7892 - val_loss: 0.4701 - val_accuracy: 0.7885\n",
      "Epoch 1380/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7892 - val_loss: 0.4703 - val_accuracy: 0.7894\n",
      "Epoch 1381/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7870 - val_loss: 0.4828 - val_accuracy: 0.7805\n",
      "Epoch 1382/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7908 - val_loss: 0.4813 - val_accuracy: 0.7912\n",
      "Epoch 1383/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7888 - val_loss: 0.4755 - val_accuracy: 0.7733\n",
      "Epoch 1384/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7874 - val_loss: 0.5156 - val_accuracy: 0.7401\n",
      "Epoch 1385/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7914 - val_loss: 0.4907 - val_accuracy: 0.7625\n",
      "Epoch 1386/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7888 - val_loss: 0.4865 - val_accuracy: 0.7643\n",
      "Epoch 1387/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7888 - val_loss: 0.4813 - val_accuracy: 0.7787\n",
      "Epoch 1388/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7856 - val_loss: 0.4636 - val_accuracy: 0.7841\n",
      "Epoch 1389/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7879 - val_loss: 0.4629 - val_accuracy: 0.7930\n",
      "Epoch 1390/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7861 - val_loss: 0.4534 - val_accuracy: 0.7930\n",
      "Epoch 1391/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7872 - val_loss: 0.4588 - val_accuracy: 0.7903\n",
      "Epoch 1392/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7867 - val_loss: 0.4936 - val_accuracy: 0.7661\n",
      "Epoch 1393/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7843 - val_loss: 0.4663 - val_accuracy: 0.7939\n",
      "Epoch 1394/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7879 - val_loss: 0.4529 - val_accuracy: 0.8020\n",
      "Epoch 1395/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7897 - val_loss: 0.4552 - val_accuracy: 0.8011\n",
      "Epoch 1396/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7881 - val_loss: 0.4519 - val_accuracy: 0.8002\n",
      "Epoch 1397/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7879 - val_loss: 0.4586 - val_accuracy: 0.7948\n",
      "Epoch 1398/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7872 - val_loss: 0.4542 - val_accuracy: 0.7975\n",
      "Epoch 1399/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7849 - val_loss: 0.4624 - val_accuracy: 0.7894\n",
      "Epoch 1400/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7825 - val_loss: 0.4597 - val_accuracy: 0.7930\n",
      "Epoch 1401/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7897 - val_loss: 0.4529 - val_accuracy: 0.7921\n",
      "Epoch 1402/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7838 - val_loss: 0.4551 - val_accuracy: 0.7939\n",
      "Epoch 1403/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7908 - val_loss: 0.4604 - val_accuracy: 0.7867\n",
      "Epoch 1404/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7881 - val_loss: 0.4502 - val_accuracy: 0.8002\n",
      "Epoch 1405/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4551 - val_accuracy: 0.8038\n",
      "Epoch 1406/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7858 - val_loss: 0.4527 - val_accuracy: 0.8020\n",
      "Epoch 1407/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7883 - val_loss: 0.4559 - val_accuracy: 0.7975\n",
      "Epoch 1408/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7890 - val_loss: 0.4594 - val_accuracy: 0.7957\n",
      "Epoch 1409/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7883 - val_loss: 0.4592 - val_accuracy: 0.7957\n",
      "Epoch 1410/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7894 - val_loss: 0.4523 - val_accuracy: 0.7948\n",
      "Epoch 1411/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7841 - val_loss: 0.4563 - val_accuracy: 0.7894\n",
      "Epoch 1412/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7872 - val_loss: 0.4602 - val_accuracy: 0.7858\n",
      "Epoch 1413/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7827 - val_loss: 0.4686 - val_accuracy: 0.7706\n",
      "Epoch 1414/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7818 - val_loss: 0.4614 - val_accuracy: 0.7814\n",
      "Epoch 1415/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7863 - val_loss: 0.4492 - val_accuracy: 0.7894\n",
      "Epoch 1416/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7856 - val_loss: 0.4503 - val_accuracy: 0.7885\n",
      "Epoch 1417/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7897 - val_loss: 0.4515 - val_accuracy: 0.7921\n",
      "Epoch 1418/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7883 - val_loss: 0.4519 - val_accuracy: 0.7867\n",
      "Epoch 1419/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7865 - val_loss: 0.4539 - val_accuracy: 0.7805\n",
      "Epoch 1420/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4561 - val_accuracy: 0.7858\n",
      "Epoch 1421/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7890 - val_loss: 0.4504 - val_accuracy: 0.8011\n",
      "Epoch 1422/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7897 - val_loss: 0.4538 - val_accuracy: 0.7921\n",
      "Epoch 1423/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7885 - val_loss: 0.4552 - val_accuracy: 0.7876\n",
      "Epoch 1424/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.7917 - val_loss: 0.4537 - val_accuracy: 0.7885\n",
      "Epoch 1425/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4426 - accuracy: 0.7905 - val_loss: 0.4564 - val_accuracy: 0.7876\n",
      "Epoch 1426/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7867 - val_loss: 0.4580 - val_accuracy: 0.7876\n",
      "Epoch 1427/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7926 - val_loss: 0.4535 - val_accuracy: 0.7939\n",
      "Epoch 1428/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7919 - val_loss: 0.4696 - val_accuracy: 0.7894\n",
      "Epoch 1429/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7905 - val_loss: 0.4593 - val_accuracy: 0.7921\n",
      "Epoch 1430/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7917 - val_loss: 0.4532 - val_accuracy: 0.7939\n",
      "Epoch 1431/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7912 - val_loss: 0.4541 - val_accuracy: 0.7948\n",
      "Epoch 1432/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7957 - val_loss: 0.4622 - val_accuracy: 0.7993\n",
      "Epoch 1433/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7928 - val_loss: 0.4627 - val_accuracy: 0.7885\n",
      "Epoch 1434/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7928 - val_loss: 0.4522 - val_accuracy: 0.7957\n",
      "Epoch 1435/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7935 - val_loss: 0.4595 - val_accuracy: 0.7966\n",
      "Epoch 1436/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7961 - val_loss: 0.4590 - val_accuracy: 0.7867\n",
      "Epoch 1437/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7932 - val_loss: 0.4488 - val_accuracy: 0.7966\n",
      "Epoch 1438/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.7923 - val_loss: 0.4473 - val_accuracy: 0.7966\n",
      "Epoch 1439/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7876 - val_loss: 0.4869 - val_accuracy: 0.7823\n",
      "Epoch 1440/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7838 - val_loss: 0.4550 - val_accuracy: 0.7957\n",
      "Epoch 1441/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7910 - val_loss: 0.4548 - val_accuracy: 0.7885\n",
      "Epoch 1442/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7894 - val_loss: 0.4674 - val_accuracy: 0.7796\n",
      "Epoch 1443/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7885 - val_loss: 0.4576 - val_accuracy: 0.7867\n",
      "Epoch 1444/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7919 - val_loss: 0.4621 - val_accuracy: 0.7876\n",
      "Epoch 1445/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4424 - accuracy: 0.7852 - val_loss: 0.4497 - val_accuracy: 0.7939\n",
      "Epoch 1446/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7881 - val_loss: 0.4518 - val_accuracy: 0.7948\n",
      "Epoch 1447/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7858 - val_loss: 0.4521 - val_accuracy: 0.7948\n",
      "Epoch 1448/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.4539 - val_accuracy: 0.7903\n",
      "Epoch 1449/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7879 - val_loss: 0.4608 - val_accuracy: 0.7867\n",
      "Epoch 1450/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7914 - val_loss: 0.4541 - val_accuracy: 0.7912\n",
      "Epoch 1451/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7888 - val_loss: 0.4549 - val_accuracy: 0.7885\n",
      "Epoch 1452/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7892 - val_loss: 0.4445 - val_accuracy: 0.7984\n",
      "Epoch 1453/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4431 - accuracy: 0.7894 - val_loss: 0.4457 - val_accuracy: 0.7939\n",
      "Epoch 1454/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7890 - val_loss: 0.4502 - val_accuracy: 0.7930\n",
      "Epoch 1455/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7888 - val_loss: 0.4511 - val_accuracy: 0.7903\n",
      "Epoch 1456/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7890 - val_loss: 0.4515 - val_accuracy: 0.7832\n",
      "Epoch 1457/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.7829 - val_loss: 0.4708 - val_accuracy: 0.7769\n",
      "Epoch 1458/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7845 - val_loss: 0.4537 - val_accuracy: 0.7832\n",
      "Epoch 1459/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7861 - val_loss: 0.4550 - val_accuracy: 0.7858\n",
      "Epoch 1460/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7885 - val_loss: 0.4680 - val_accuracy: 0.7814\n",
      "Epoch 1461/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7858 - val_loss: 0.4646 - val_accuracy: 0.7805\n",
      "Epoch 1462/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.7856 - val_loss: 0.4668 - val_accuracy: 0.7823\n",
      "Epoch 1463/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.7834 - val_loss: 0.4669 - val_accuracy: 0.7724\n",
      "Epoch 1464/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7845 - val_loss: 0.4615 - val_accuracy: 0.7858\n",
      "Epoch 1465/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7834 - val_loss: 0.4596 - val_accuracy: 0.7778\n",
      "Epoch 1466/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7825 - val_loss: 0.4572 - val_accuracy: 0.7849\n",
      "Epoch 1467/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7825 - val_loss: 0.4716 - val_accuracy: 0.7634\n",
      "Epoch 1468/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7863 - val_loss: 0.4610 - val_accuracy: 0.7778\n",
      "Epoch 1469/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7872 - val_loss: 0.4536 - val_accuracy: 0.7876\n",
      "Epoch 1470/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.4514 - val_accuracy: 0.7912\n",
      "Epoch 1471/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.7841 - val_loss: 0.4437 - val_accuracy: 0.7912\n",
      "Epoch 1472/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7914 - val_loss: 0.4491 - val_accuracy: 0.7867\n",
      "Epoch 1473/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7910 - val_loss: 0.4459 - val_accuracy: 0.7912\n",
      "Epoch 1474/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7919 - val_loss: 0.4494 - val_accuracy: 0.7903\n",
      "Epoch 1475/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7914 - val_loss: 0.4502 - val_accuracy: 0.7930\n",
      "Epoch 1476/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4585 - val_accuracy: 0.7796\n",
      "Epoch 1477/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7910 - val_loss: 0.4546 - val_accuracy: 0.7849\n",
      "Epoch 1478/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7935 - val_loss: 0.4579 - val_accuracy: 0.7814\n",
      "Epoch 1479/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4554 - val_accuracy: 0.7912\n",
      "Epoch 1480/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7926 - val_loss: 0.4562 - val_accuracy: 0.7832\n",
      "Epoch 1481/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7941 - val_loss: 0.4576 - val_accuracy: 0.7778\n",
      "Epoch 1482/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7939 - val_loss: 0.4587 - val_accuracy: 0.7885\n",
      "Epoch 1483/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7879 - val_loss: 0.4540 - val_accuracy: 0.7876\n",
      "Epoch 1484/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7921 - val_loss: 0.4549 - val_accuracy: 0.7948\n",
      "Epoch 1485/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7890 - val_loss: 0.4605 - val_accuracy: 0.7751\n",
      "Epoch 1486/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7874 - val_loss: 0.4550 - val_accuracy: 0.7805\n",
      "Epoch 1487/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7897 - val_loss: 0.4548 - val_accuracy: 0.7841\n",
      "Epoch 1488/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7894 - val_loss: 0.4601 - val_accuracy: 0.7849\n",
      "Epoch 1489/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4576 - val_accuracy: 0.7841\n",
      "Epoch 1490/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7825 - val_loss: 0.4578 - val_accuracy: 0.7769\n",
      "Epoch 1491/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7827 - val_loss: 0.4546 - val_accuracy: 0.7787\n",
      "Epoch 1492/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7811 - val_loss: 0.4693 - val_accuracy: 0.7858\n",
      "Epoch 1493/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.7865 - val_loss: 0.4515 - val_accuracy: 0.7885\n",
      "Epoch 1494/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7928 - val_loss: 0.4681 - val_accuracy: 0.7912\n",
      "Epoch 1495/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7883 - val_loss: 0.4642 - val_accuracy: 0.7805\n",
      "Epoch 1496/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7894 - val_loss: 0.4687 - val_accuracy: 0.7769\n",
      "Epoch 1497/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7926 - val_loss: 0.4623 - val_accuracy: 0.7885\n",
      "Epoch 1498/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7905 - val_loss: 0.4583 - val_accuracy: 0.7948\n",
      "Epoch 1499/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7897 - val_loss: 0.4553 - val_accuracy: 0.7939\n",
      "Epoch 1500/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7888 - val_loss: 0.4602 - val_accuracy: 0.7867\n",
      "Epoch 1501/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7863 - val_loss: 0.4518 - val_accuracy: 0.7912\n",
      "Epoch 1502/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7894 - val_loss: 0.4546 - val_accuracy: 0.7975\n",
      "Epoch 1503/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7935 - val_loss: 0.4596 - val_accuracy: 0.7921\n",
      "Epoch 1504/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7888 - val_loss: 0.4636 - val_accuracy: 0.7903\n",
      "Epoch 1505/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4625 - val_accuracy: 0.7849\n",
      "Epoch 1506/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4808 - val_accuracy: 0.7832\n",
      "Epoch 1507/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7914 - val_loss: 0.4661 - val_accuracy: 0.7939\n",
      "Epoch 1508/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7948 - val_loss: 0.4703 - val_accuracy: 0.7885\n",
      "Epoch 1509/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7914 - val_loss: 0.4637 - val_accuracy: 0.7984\n",
      "Epoch 1510/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.7919 - val_loss: 0.4800 - val_accuracy: 0.7903\n",
      "Epoch 1511/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.4738 - val_accuracy: 0.7778\n",
      "Epoch 1512/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4438 - accuracy: 0.7912 - val_loss: 0.4676 - val_accuracy: 0.7858\n",
      "Epoch 1513/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7912 - val_loss: 0.4724 - val_accuracy: 0.7966\n",
      "Epoch 1514/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7928 - val_loss: 0.4660 - val_accuracy: 0.7930\n",
      "Epoch 1515/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7892 - val_loss: 0.4630 - val_accuracy: 0.7984\n",
      "Epoch 1516/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.4650 - val_accuracy: 0.7885\n",
      "Epoch 1517/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.7872 - val_loss: 0.4596 - val_accuracy: 0.7876\n",
      "Epoch 1518/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7921 - val_loss: 0.4621 - val_accuracy: 0.7921\n",
      "Epoch 1519/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7912 - val_loss: 0.4708 - val_accuracy: 0.7849\n",
      "Epoch 1520/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7903 - val_loss: 0.4651 - val_accuracy: 0.7841\n",
      "Epoch 1521/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7912 - val_loss: 0.4635 - val_accuracy: 0.7930\n",
      "Epoch 1522/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7888 - val_loss: 0.4629 - val_accuracy: 0.7858\n",
      "Epoch 1523/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7890 - val_loss: 0.4668 - val_accuracy: 0.7876\n",
      "Epoch 1524/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7905 - val_loss: 0.4620 - val_accuracy: 0.7894\n",
      "Epoch 1525/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7879 - val_loss: 0.4618 - val_accuracy: 0.7894\n",
      "Epoch 1526/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7905 - val_loss: 0.4608 - val_accuracy: 0.7984\n",
      "Epoch 1527/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7912 - val_loss: 0.4610 - val_accuracy: 0.7867\n",
      "Epoch 1528/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7894 - val_loss: 0.4729 - val_accuracy: 0.7787\n",
      "Epoch 1529/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7892 - val_loss: 0.4739 - val_accuracy: 0.7742\n",
      "Epoch 1530/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.7901 - val_loss: 0.4688 - val_accuracy: 0.7832\n",
      "Epoch 1531/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7897 - val_loss: 0.4575 - val_accuracy: 0.7921\n",
      "Epoch 1532/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7903 - val_loss: 0.4631 - val_accuracy: 0.7841\n",
      "Epoch 1533/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7892 - val_loss: 0.4613 - val_accuracy: 0.7805\n",
      "Epoch 1534/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7883 - val_loss: 0.4590 - val_accuracy: 0.7867\n",
      "Epoch 1535/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7894 - val_loss: 0.4569 - val_accuracy: 0.7894\n",
      "Epoch 1536/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7879 - val_loss: 0.4559 - val_accuracy: 0.7957\n",
      "Epoch 1537/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7841 - val_loss: 0.4511 - val_accuracy: 0.7814\n",
      "Epoch 1538/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7885 - val_loss: 0.4593 - val_accuracy: 0.7814\n",
      "Epoch 1539/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7858 - val_loss: 0.4792 - val_accuracy: 0.7814\n",
      "Epoch 1540/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7849 - val_loss: 0.4579 - val_accuracy: 0.7796\n",
      "Epoch 1541/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7885 - val_loss: 0.4501 - val_accuracy: 0.7930\n",
      "Epoch 1542/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7897 - val_loss: 0.4627 - val_accuracy: 0.7903\n",
      "Epoch 1543/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7894 - val_loss: 0.4607 - val_accuracy: 0.7912\n",
      "Epoch 1544/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7894 - val_loss: 0.4576 - val_accuracy: 0.7814\n",
      "Epoch 1545/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7926 - val_loss: 0.4574 - val_accuracy: 0.7894\n",
      "Epoch 1546/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7928 - val_loss: 0.4844 - val_accuracy: 0.7841\n",
      "Epoch 1547/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7841 - val_loss: 0.4682 - val_accuracy: 0.7849\n",
      "Epoch 1548/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7890 - val_loss: 0.4602 - val_accuracy: 0.7823\n",
      "Epoch 1549/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7863 - val_loss: 0.4644 - val_accuracy: 0.7832\n",
      "Epoch 1550/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7897 - val_loss: 0.4632 - val_accuracy: 0.7742\n",
      "Epoch 1551/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7901 - val_loss: 0.4591 - val_accuracy: 0.7778\n",
      "Epoch 1552/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7867 - val_loss: 0.4709 - val_accuracy: 0.7876\n",
      "Epoch 1553/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7879 - val_loss: 0.4752 - val_accuracy: 0.7697\n",
      "Epoch 1554/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7899 - val_loss: 0.4695 - val_accuracy: 0.7823\n",
      "Epoch 1555/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4640 - val_accuracy: 0.7903\n",
      "Epoch 1556/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7950 - val_loss: 0.4539 - val_accuracy: 0.7894\n",
      "Epoch 1557/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7872 - val_loss: 0.4540 - val_accuracy: 0.7832\n",
      "Epoch 1558/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7910 - val_loss: 0.4499 - val_accuracy: 0.7867\n",
      "Epoch 1559/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7908 - val_loss: 0.4489 - val_accuracy: 0.7876\n",
      "Epoch 1560/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.4467 - val_accuracy: 0.7849\n",
      "Epoch 1561/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7885 - val_loss: 0.4655 - val_accuracy: 0.7688\n",
      "Epoch 1562/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7861 - val_loss: 0.4638 - val_accuracy: 0.7751\n",
      "Epoch 1563/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7883 - val_loss: 0.4573 - val_accuracy: 0.7724\n",
      "Epoch 1564/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7888 - val_loss: 0.4641 - val_accuracy: 0.7805\n",
      "Epoch 1565/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7872 - val_loss: 0.4588 - val_accuracy: 0.7805\n",
      "Epoch 1566/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7872 - val_loss: 0.4539 - val_accuracy: 0.7778\n",
      "Epoch 1567/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7888 - val_loss: 0.4527 - val_accuracy: 0.7876\n",
      "Epoch 1568/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7863 - val_loss: 0.4482 - val_accuracy: 0.7841\n",
      "Epoch 1569/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7890 - val_loss: 0.4489 - val_accuracy: 0.7841\n",
      "Epoch 1570/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7901 - val_loss: 0.4544 - val_accuracy: 0.7814\n",
      "Epoch 1571/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7879 - val_loss: 0.4540 - val_accuracy: 0.7894\n",
      "Epoch 1572/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7903 - val_loss: 0.4563 - val_accuracy: 0.7867\n",
      "Epoch 1573/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7863 - val_loss: 0.4548 - val_accuracy: 0.7823\n",
      "Epoch 1574/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7874 - val_loss: 0.4565 - val_accuracy: 0.7814\n",
      "Epoch 1575/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7892 - val_loss: 0.4556 - val_accuracy: 0.7858\n",
      "Epoch 1576/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7854 - val_loss: 0.4594 - val_accuracy: 0.7814\n",
      "Epoch 1577/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7905 - val_loss: 0.4518 - val_accuracy: 0.7841\n",
      "Epoch 1578/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7861 - val_loss: 0.4441 - val_accuracy: 0.7841\n",
      "Epoch 1579/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7881 - val_loss: 0.4520 - val_accuracy: 0.7849\n",
      "Epoch 1580/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.7930 - val_loss: 0.4559 - val_accuracy: 0.7805\n",
      "Epoch 1581/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4406 - accuracy: 0.7910 - val_loss: 0.4654 - val_accuracy: 0.7894\n",
      "Epoch 1582/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7919 - val_loss: 0.4525 - val_accuracy: 0.7823\n",
      "Epoch 1583/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.7932 - val_loss: 0.4552 - val_accuracy: 0.7876\n",
      "Epoch 1584/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7957 - val_loss: 0.4464 - val_accuracy: 0.7984\n",
      "Epoch 1585/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.7939 - val_loss: 0.4583 - val_accuracy: 0.7957\n",
      "Epoch 1586/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7959 - val_loss: 0.4529 - val_accuracy: 0.7849\n",
      "Epoch 1587/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4358 - accuracy: 0.7975 - val_loss: 0.4594 - val_accuracy: 0.7885\n",
      "Epoch 1588/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.7950 - val_loss: 0.4563 - val_accuracy: 0.7930\n",
      "Epoch 1589/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7930 - val_loss: 0.4619 - val_accuracy: 0.7867\n",
      "Epoch 1590/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7881 - val_loss: 0.4626 - val_accuracy: 0.7841\n",
      "Epoch 1591/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7926 - val_loss: 0.4645 - val_accuracy: 0.7903\n",
      "Epoch 1592/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7892 - val_loss: 0.4612 - val_accuracy: 0.7930\n",
      "Epoch 1593/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.7908 - val_loss: 0.4753 - val_accuracy: 0.7841\n",
      "Epoch 1594/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7937 - val_loss: 0.4856 - val_accuracy: 0.7796\n",
      "Epoch 1595/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7919 - val_loss: 0.4653 - val_accuracy: 0.7849\n",
      "Epoch 1596/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7923 - val_loss: 0.4965 - val_accuracy: 0.7572\n",
      "Epoch 1597/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7827 - val_loss: 0.4755 - val_accuracy: 0.7688\n",
      "Epoch 1598/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7858 - val_loss: 0.4742 - val_accuracy: 0.7894\n",
      "Epoch 1599/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7892 - val_loss: 0.4691 - val_accuracy: 0.7867\n",
      "Epoch 1600/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.7890 - val_loss: 0.4690 - val_accuracy: 0.7921\n",
      "Epoch 1601/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.7888 - val_loss: 0.4682 - val_accuracy: 0.7912\n",
      "Epoch 1602/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7914 - val_loss: 0.4732 - val_accuracy: 0.7832\n",
      "Epoch 1603/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7953 - val_loss: 0.4674 - val_accuracy: 0.7948\n",
      "Epoch 1604/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7921 - val_loss: 0.4625 - val_accuracy: 0.7903\n",
      "Epoch 1605/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7932 - val_loss: 0.4629 - val_accuracy: 0.7939\n",
      "Epoch 1606/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7926 - val_loss: 0.4849 - val_accuracy: 0.7751\n",
      "Epoch 1607/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7881 - val_loss: 0.4620 - val_accuracy: 0.7948\n",
      "Epoch 1608/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4371 - accuracy: 0.7903 - val_loss: 0.4650 - val_accuracy: 0.7921\n",
      "Epoch 1609/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.7926 - val_loss: 0.4679 - val_accuracy: 0.7841\n",
      "Epoch 1610/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7870 - val_loss: 0.4626 - val_accuracy: 0.7885\n",
      "Epoch 1611/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.4651 - val_accuracy: 0.7966\n",
      "Epoch 1612/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7939 - val_loss: 0.4604 - val_accuracy: 0.7984\n",
      "Epoch 1613/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7973 - val_loss: 0.4761 - val_accuracy: 0.7975\n",
      "Epoch 1614/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7932 - val_loss: 0.4582 - val_accuracy: 0.7930\n",
      "Epoch 1615/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7926 - val_loss: 0.4610 - val_accuracy: 0.7912\n",
      "Epoch 1616/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7923 - val_loss: 0.4624 - val_accuracy: 0.7930\n",
      "Epoch 1617/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.7897 - val_loss: 0.4599 - val_accuracy: 0.7912\n",
      "Epoch 1618/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7881 - val_loss: 0.4598 - val_accuracy: 0.7966\n",
      "Epoch 1619/2000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7921 - val_loss: 0.4693 - val_accuracy: 0.7903\n",
      "Epoch 1620/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7867 - val_loss: 0.4711 - val_accuracy: 0.7858\n",
      "Epoch 1621/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7894 - val_loss: 0.4616 - val_accuracy: 0.7984\n",
      "Epoch 1622/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7883 - val_loss: 0.4622 - val_accuracy: 0.7966\n",
      "Epoch 1623/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7912 - val_loss: 0.4626 - val_accuracy: 0.7912\n",
      "Epoch 1624/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7897 - val_loss: 0.4569 - val_accuracy: 0.7948\n",
      "Epoch 1625/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.7903 - val_loss: 0.4563 - val_accuracy: 0.7939\n",
      "Epoch 1626/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7908 - val_loss: 0.4570 - val_accuracy: 0.7975\n",
      "Epoch 1627/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7892 - val_loss: 0.4517 - val_accuracy: 0.7993\n",
      "Epoch 1628/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7876 - val_loss: 0.4586 - val_accuracy: 0.7903\n",
      "Epoch 1629/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7908 - val_loss: 0.4746 - val_accuracy: 0.7921\n",
      "Epoch 1630/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.4600 - val_accuracy: 0.7948\n",
      "Epoch 1631/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7870 - val_loss: 0.4663 - val_accuracy: 0.7948\n",
      "Epoch 1632/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7881 - val_loss: 0.4637 - val_accuracy: 0.7885\n",
      "Epoch 1633/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7876 - val_loss: 0.4603 - val_accuracy: 0.7930\n",
      "Epoch 1634/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.7881 - val_loss: 0.4595 - val_accuracy: 0.7957\n",
      "Epoch 1635/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7894 - val_loss: 0.4601 - val_accuracy: 0.7894\n",
      "Epoch 1636/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7885 - val_loss: 0.4692 - val_accuracy: 0.7867\n",
      "Epoch 1637/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7863 - val_loss: 0.4532 - val_accuracy: 0.7984\n",
      "Epoch 1638/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7885 - val_loss: 0.4522 - val_accuracy: 0.7984\n",
      "Epoch 1639/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7890 - val_loss: 0.4622 - val_accuracy: 0.7975\n",
      "Epoch 1640/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7852 - val_loss: 0.4578 - val_accuracy: 0.7930\n",
      "Epoch 1641/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7910 - val_loss: 0.4521 - val_accuracy: 0.8002\n",
      "Epoch 1642/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7903 - val_loss: 0.4633 - val_accuracy: 0.7984\n",
      "Epoch 1643/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7892 - val_loss: 0.4604 - val_accuracy: 0.7984\n",
      "Epoch 1644/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4542 - val_accuracy: 0.7903\n",
      "Epoch 1645/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.4588 - val_accuracy: 0.7849\n",
      "Epoch 1646/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.7883 - val_loss: 0.4606 - val_accuracy: 0.7894\n",
      "Epoch 1647/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7905 - val_loss: 0.4541 - val_accuracy: 0.7948\n",
      "Epoch 1648/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7905 - val_loss: 0.4563 - val_accuracy: 0.7885\n",
      "Epoch 1649/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7921 - val_loss: 0.4515 - val_accuracy: 0.7993\n",
      "Epoch 1650/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7935 - val_loss: 0.4557 - val_accuracy: 0.7921\n",
      "Epoch 1651/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4653 - val_accuracy: 0.7841\n",
      "Epoch 1652/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4545 - val_accuracy: 0.7858\n",
      "Epoch 1653/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4437 - accuracy: 0.7872 - val_loss: 0.4625 - val_accuracy: 0.7814\n",
      "Epoch 1654/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4443 - accuracy: 0.7894 - val_loss: 0.4610 - val_accuracy: 0.7823\n",
      "Epoch 1655/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7885 - val_loss: 0.4577 - val_accuracy: 0.7885\n",
      "Epoch 1656/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7883 - val_loss: 0.4538 - val_accuracy: 0.7867\n",
      "Epoch 1657/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4433 - accuracy: 0.7881 - val_loss: 0.4735 - val_accuracy: 0.7894\n",
      "Epoch 1658/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7885 - val_loss: 0.4649 - val_accuracy: 0.7832\n",
      "Epoch 1659/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7890 - val_loss: 0.4592 - val_accuracy: 0.7903\n",
      "Epoch 1660/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7881 - val_loss: 0.4672 - val_accuracy: 0.7867\n",
      "Epoch 1661/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7881 - val_loss: 0.4620 - val_accuracy: 0.7751\n",
      "Epoch 1662/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.7823 - val_loss: 0.4602 - val_accuracy: 0.7796\n",
      "Epoch 1663/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7885 - val_loss: 0.4798 - val_accuracy: 0.7823\n",
      "Epoch 1664/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7863 - val_loss: 0.4832 - val_accuracy: 0.7751\n",
      "Epoch 1665/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.7793 - val_loss: 0.4597 - val_accuracy: 0.7796\n",
      "Epoch 1666/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7872 - val_loss: 0.4555 - val_accuracy: 0.7849\n",
      "Epoch 1667/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7885 - val_loss: 0.4584 - val_accuracy: 0.7841\n",
      "Epoch 1668/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7890 - val_loss: 0.4693 - val_accuracy: 0.7706\n",
      "Epoch 1669/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4478 - val_accuracy: 0.7778\n",
      "Epoch 1670/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7867 - val_loss: 0.4483 - val_accuracy: 0.7858\n",
      "Epoch 1671/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.4755 - val_accuracy: 0.7733\n",
      "Epoch 1672/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7852 - val_loss: 0.4509 - val_accuracy: 0.7885\n",
      "Epoch 1673/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7892 - val_loss: 0.4566 - val_accuracy: 0.7849\n",
      "Epoch 1674/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.7841 - val_loss: 0.4586 - val_accuracy: 0.7841\n",
      "Epoch 1675/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7863 - val_loss: 0.4649 - val_accuracy: 0.7832\n",
      "Epoch 1676/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7914 - val_loss: 0.4616 - val_accuracy: 0.7885\n",
      "Epoch 1677/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7932 - val_loss: 0.4595 - val_accuracy: 0.7876\n",
      "Epoch 1678/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7937 - val_loss: 0.4577 - val_accuracy: 0.7912\n",
      "Epoch 1679/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7941 - val_loss: 0.4581 - val_accuracy: 0.7948\n",
      "Epoch 1680/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7935 - val_loss: 0.4556 - val_accuracy: 0.7975\n",
      "Epoch 1681/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.7939 - val_loss: 0.4666 - val_accuracy: 0.7823\n",
      "Epoch 1682/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7937 - val_loss: 0.4687 - val_accuracy: 0.7966\n",
      "Epoch 1683/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.7946 - val_loss: 0.4639 - val_accuracy: 0.7841\n",
      "Epoch 1684/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4375 - accuracy: 0.7930 - val_loss: 0.4605 - val_accuracy: 0.7939\n",
      "Epoch 1685/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7935 - val_loss: 0.4768 - val_accuracy: 0.7787\n",
      "Epoch 1686/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4448 - accuracy: 0.7894 - val_loss: 0.4566 - val_accuracy: 0.7849\n",
      "Epoch 1687/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4428 - accuracy: 0.7930 - val_loss: 0.4679 - val_accuracy: 0.7849\n",
      "Epoch 1688/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7897 - val_loss: 0.4786 - val_accuracy: 0.7832\n",
      "Epoch 1689/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7908 - val_loss: 0.4626 - val_accuracy: 0.7876\n",
      "Epoch 1690/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7901 - val_loss: 0.4597 - val_accuracy: 0.7823\n",
      "Epoch 1691/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7883 - val_loss: 0.4508 - val_accuracy: 0.7957\n",
      "Epoch 1692/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7910 - val_loss: 0.4530 - val_accuracy: 0.7939\n",
      "Epoch 1693/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7881 - val_loss: 0.4569 - val_accuracy: 0.7912\n",
      "Epoch 1694/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7890 - val_loss: 0.4501 - val_accuracy: 0.8011\n",
      "Epoch 1695/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7919 - val_loss: 0.4563 - val_accuracy: 0.7912\n",
      "Epoch 1696/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7894 - val_loss: 0.4509 - val_accuracy: 0.7957\n",
      "Epoch 1697/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7903 - val_loss: 0.4524 - val_accuracy: 0.7903\n",
      "Epoch 1698/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7903 - val_loss: 0.4513 - val_accuracy: 0.7903\n",
      "Epoch 1699/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7894 - val_loss: 0.4510 - val_accuracy: 0.7849\n",
      "Epoch 1700/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7894 - val_loss: 0.4551 - val_accuracy: 0.7867\n",
      "Epoch 1701/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4629 - val_accuracy: 0.7769\n",
      "Epoch 1702/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.7814 - val_loss: 0.4690 - val_accuracy: 0.7796\n",
      "Epoch 1703/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7881 - val_loss: 0.4548 - val_accuracy: 0.7903\n",
      "Epoch 1704/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7879 - val_loss: 0.4662 - val_accuracy: 0.7706\n",
      "Epoch 1705/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7883 - val_loss: 0.4546 - val_accuracy: 0.7805\n",
      "Epoch 1706/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7858 - val_loss: 0.4596 - val_accuracy: 0.7841\n",
      "Epoch 1707/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7876 - val_loss: 0.4612 - val_accuracy: 0.7849\n",
      "Epoch 1708/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7888 - val_loss: 0.4481 - val_accuracy: 0.7849\n",
      "Epoch 1709/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7843 - val_loss: 0.4489 - val_accuracy: 0.7849\n",
      "Epoch 1710/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7879 - val_loss: 0.4489 - val_accuracy: 0.7849\n",
      "Epoch 1711/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7836 - val_loss: 0.4566 - val_accuracy: 0.7832\n",
      "Epoch 1712/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7879 - val_loss: 0.4562 - val_accuracy: 0.7814\n",
      "Epoch 1713/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7872 - val_loss: 0.4587 - val_accuracy: 0.7894\n",
      "Epoch 1714/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7885 - val_loss: 0.4531 - val_accuracy: 0.7849\n",
      "Epoch 1715/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7903 - val_loss: 0.4569 - val_accuracy: 0.7814\n",
      "Epoch 1716/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7867 - val_loss: 0.4627 - val_accuracy: 0.7885\n",
      "Epoch 1717/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7856 - val_loss: 0.4506 - val_accuracy: 0.7885\n",
      "Epoch 1718/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7883 - val_loss: 0.4605 - val_accuracy: 0.7894\n",
      "Epoch 1719/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7879 - val_loss: 0.4846 - val_accuracy: 0.7885\n",
      "Epoch 1720/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7863 - val_loss: 0.4559 - val_accuracy: 0.7948\n",
      "Epoch 1721/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7863 - val_loss: 0.4683 - val_accuracy: 0.7832\n",
      "Epoch 1722/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7809 - val_loss: 0.4575 - val_accuracy: 0.7832\n",
      "Epoch 1723/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7852 - val_loss: 0.4552 - val_accuracy: 0.7867\n",
      "Epoch 1724/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.7921 - val_loss: 0.4576 - val_accuracy: 0.7867\n",
      "Epoch 1725/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7883 - val_loss: 0.4528 - val_accuracy: 0.7876\n",
      "Epoch 1726/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7897 - val_loss: 0.4476 - val_accuracy: 0.7849\n",
      "Epoch 1727/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7885 - val_loss: 0.4602 - val_accuracy: 0.7939\n",
      "Epoch 1728/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7901 - val_loss: 0.4712 - val_accuracy: 0.7805\n",
      "Epoch 1729/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4433 - accuracy: 0.7861 - val_loss: 0.4527 - val_accuracy: 0.7841\n",
      "Epoch 1730/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7908 - val_loss: 0.4574 - val_accuracy: 0.7823\n",
      "Epoch 1731/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7908 - val_loss: 0.4591 - val_accuracy: 0.7841\n",
      "Epoch 1732/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7863 - val_loss: 0.4524 - val_accuracy: 0.7867\n",
      "Epoch 1733/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7856 - val_loss: 0.4583 - val_accuracy: 0.7796\n",
      "Epoch 1734/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7923 - val_loss: 0.4569 - val_accuracy: 0.7885\n",
      "Epoch 1735/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7894 - val_loss: 0.4742 - val_accuracy: 0.7814\n",
      "Epoch 1736/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7863 - val_loss: 0.4557 - val_accuracy: 0.7858\n",
      "Epoch 1737/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7890 - val_loss: 0.4578 - val_accuracy: 0.7858\n",
      "Epoch 1738/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.7885 - val_loss: 0.4668 - val_accuracy: 0.7841\n",
      "Epoch 1739/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7905 - val_loss: 0.4788 - val_accuracy: 0.7634\n",
      "Epoch 1740/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7894 - val_loss: 0.4632 - val_accuracy: 0.7814\n",
      "Epoch 1741/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7881 - val_loss: 0.4706 - val_accuracy: 0.7939\n",
      "Epoch 1742/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7908 - val_loss: 0.4658 - val_accuracy: 0.7957\n",
      "Epoch 1743/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7881 - val_loss: 0.4618 - val_accuracy: 0.7912\n",
      "Epoch 1744/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.7923 - val_loss: 0.4617 - val_accuracy: 0.7930\n",
      "Epoch 1745/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7908 - val_loss: 0.4572 - val_accuracy: 0.7939\n",
      "Epoch 1746/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7881 - val_loss: 0.4650 - val_accuracy: 0.7876\n",
      "Epoch 1747/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4490 - accuracy: 0.7849 - val_loss: 0.4795 - val_accuracy: 0.7697\n",
      "Epoch 1748/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.7870 - val_loss: 0.4604 - val_accuracy: 0.7876\n",
      "Epoch 1749/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7901 - val_loss: 0.4615 - val_accuracy: 0.7939\n",
      "Epoch 1750/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4666 - val_accuracy: 0.7939\n",
      "Epoch 1751/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7894 - val_loss: 0.4672 - val_accuracy: 0.7849\n",
      "Epoch 1752/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7861 - val_loss: 0.4630 - val_accuracy: 0.7876\n",
      "Epoch 1753/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4738 - val_accuracy: 0.7760\n",
      "Epoch 1754/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7901 - val_loss: 0.4754 - val_accuracy: 0.7724\n",
      "Epoch 1755/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7890 - val_loss: 0.4766 - val_accuracy: 0.7805\n",
      "Epoch 1756/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7872 - val_loss: 0.4634 - val_accuracy: 0.7885\n",
      "Epoch 1757/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7905 - val_loss: 0.4717 - val_accuracy: 0.7751\n",
      "Epoch 1758/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7905 - val_loss: 0.4563 - val_accuracy: 0.7903\n",
      "Epoch 1759/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7903 - val_loss: 0.4549 - val_accuracy: 0.7921\n",
      "Epoch 1760/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7867 - val_loss: 0.4559 - val_accuracy: 0.7921\n",
      "Epoch 1761/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7890 - val_loss: 0.4494 - val_accuracy: 0.7921\n",
      "Epoch 1762/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7883 - val_loss: 0.4484 - val_accuracy: 0.7930\n",
      "Epoch 1763/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7932 - val_loss: 0.4440 - val_accuracy: 0.7957\n",
      "Epoch 1764/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7903 - val_loss: 0.4551 - val_accuracy: 0.7912\n",
      "Epoch 1765/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7861 - val_loss: 0.4427 - val_accuracy: 0.7921\n",
      "Epoch 1766/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4535 - val_accuracy: 0.7876\n",
      "Epoch 1767/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7910 - val_loss: 0.4496 - val_accuracy: 0.7796\n",
      "Epoch 1768/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4448 - val_accuracy: 0.7876\n",
      "Epoch 1769/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.7883 - val_loss: 0.4521 - val_accuracy: 0.7894\n",
      "Epoch 1770/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7890 - val_loss: 0.4588 - val_accuracy: 0.7867\n",
      "Epoch 1771/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.4567 - val_accuracy: 0.7894\n",
      "Epoch 1772/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7867 - val_loss: 0.4578 - val_accuracy: 0.7805\n",
      "Epoch 1773/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7885 - val_loss: 0.4657 - val_accuracy: 0.7814\n",
      "Epoch 1774/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7912 - val_loss: 0.4533 - val_accuracy: 0.7894\n",
      "Epoch 1775/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7892 - val_loss: 0.4632 - val_accuracy: 0.7787\n",
      "Epoch 1776/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7903 - val_loss: 0.4577 - val_accuracy: 0.7885\n",
      "Epoch 1777/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7928 - val_loss: 0.4674 - val_accuracy: 0.7697\n",
      "Epoch 1778/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7935 - val_loss: 0.4535 - val_accuracy: 0.7930\n",
      "Epoch 1779/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7908 - val_loss: 0.4566 - val_accuracy: 0.7858\n",
      "Epoch 1780/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7910 - val_loss: 0.4472 - val_accuracy: 0.7894\n",
      "Epoch 1781/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7921 - val_loss: 0.4544 - val_accuracy: 0.7849\n",
      "Epoch 1782/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7897 - val_loss: 0.4601 - val_accuracy: 0.7787\n",
      "Epoch 1783/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7892 - val_loss: 0.4530 - val_accuracy: 0.7814\n",
      "Epoch 1784/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7944 - val_loss: 0.4547 - val_accuracy: 0.7885\n",
      "Epoch 1785/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7955 - val_loss: 0.4618 - val_accuracy: 0.7796\n",
      "Epoch 1786/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7935 - val_loss: 0.4631 - val_accuracy: 0.7796\n",
      "Epoch 1787/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.7941 - val_loss: 0.4658 - val_accuracy: 0.7814\n",
      "Epoch 1788/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7910 - val_loss: 0.4668 - val_accuracy: 0.7849\n",
      "Epoch 1789/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7908 - val_loss: 0.4772 - val_accuracy: 0.7679\n",
      "Epoch 1790/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7883 - val_loss: 0.4776 - val_accuracy: 0.7706\n",
      "Epoch 1791/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7829 - val_loss: 0.4677 - val_accuracy: 0.7787\n",
      "Epoch 1792/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7894 - val_loss: 0.4804 - val_accuracy: 0.7715\n",
      "Epoch 1793/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7914 - val_loss: 0.4736 - val_accuracy: 0.7894\n",
      "Epoch 1794/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7888 - val_loss: 0.4765 - val_accuracy: 0.7832\n",
      "Epoch 1795/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7897 - val_loss: 0.4776 - val_accuracy: 0.7769\n",
      "Epoch 1796/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4900 - val_accuracy: 0.7823\n",
      "Epoch 1797/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7905 - val_loss: 0.4740 - val_accuracy: 0.7876\n",
      "Epoch 1798/2000\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7867 - val_loss: 0.4830 - val_accuracy: 0.7867\n",
      "Epoch 1799/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7892 - val_loss: 0.4601 - val_accuracy: 0.7778\n",
      "Epoch 1800/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7908 - val_loss: 0.4625 - val_accuracy: 0.7903\n",
      "Epoch 1801/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7867 - val_loss: 0.4634 - val_accuracy: 0.7894\n",
      "Epoch 1802/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7910 - val_loss: 0.4583 - val_accuracy: 0.7930\n",
      "Epoch 1803/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7885 - val_loss: 0.4599 - val_accuracy: 0.7858\n",
      "Epoch 1804/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7890 - val_loss: 0.4641 - val_accuracy: 0.7876\n",
      "Epoch 1805/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.7905 - val_loss: 0.4528 - val_accuracy: 0.7966\n",
      "Epoch 1806/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7930 - val_loss: 0.4545 - val_accuracy: 0.7876\n",
      "Epoch 1807/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.7892 - val_loss: 0.4522 - val_accuracy: 0.7948\n",
      "Epoch 1808/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7905 - val_loss: 0.4543 - val_accuracy: 0.7975\n",
      "Epoch 1809/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.7928 - val_loss: 0.4531 - val_accuracy: 0.7984\n",
      "Epoch 1810/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7881 - val_loss: 0.4509 - val_accuracy: 0.7993\n",
      "Epoch 1811/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7890 - val_loss: 0.4595 - val_accuracy: 0.7885\n",
      "Epoch 1812/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7865 - val_loss: 0.4471 - val_accuracy: 0.7948\n",
      "Epoch 1813/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7890 - val_loss: 0.4532 - val_accuracy: 0.7993\n",
      "Epoch 1814/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7905 - val_loss: 0.4544 - val_accuracy: 0.7939\n",
      "Epoch 1815/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7861 - val_loss: 0.4522 - val_accuracy: 0.7796\n",
      "Epoch 1816/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7908 - val_loss: 0.4527 - val_accuracy: 0.7823\n",
      "Epoch 1817/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7914 - val_loss: 0.4604 - val_accuracy: 0.7661\n",
      "Epoch 1818/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7923 - val_loss: 0.4728 - val_accuracy: 0.7536\n",
      "Epoch 1819/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7939 - val_loss: 0.4535 - val_accuracy: 0.7778\n",
      "Epoch 1820/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7923 - val_loss: 0.4779 - val_accuracy: 0.7688\n",
      "Epoch 1821/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7908 - val_loss: 0.4653 - val_accuracy: 0.7715\n",
      "Epoch 1822/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7912 - val_loss: 0.4690 - val_accuracy: 0.7814\n",
      "Epoch 1823/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.4631 - val_accuracy: 0.7876\n",
      "Epoch 1824/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7937 - val_loss: 0.4639 - val_accuracy: 0.7912\n",
      "Epoch 1825/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7921 - val_loss: 0.4614 - val_accuracy: 0.7948\n",
      "Epoch 1826/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4378 - accuracy: 0.7885 - val_loss: 0.4665 - val_accuracy: 0.7867\n",
      "Epoch 1827/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7912 - val_loss: 0.4746 - val_accuracy: 0.7670\n",
      "Epoch 1828/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7894 - val_loss: 0.4628 - val_accuracy: 0.7796\n",
      "Epoch 1829/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7874 - val_loss: 0.4509 - val_accuracy: 0.7876\n",
      "Epoch 1830/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7888 - val_loss: 0.4524 - val_accuracy: 0.7841\n",
      "Epoch 1831/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7939 - val_loss: 0.4548 - val_accuracy: 0.7876\n",
      "Epoch 1832/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7921 - val_loss: 0.4733 - val_accuracy: 0.7778\n",
      "Epoch 1833/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7928 - val_loss: 0.4792 - val_accuracy: 0.7751\n",
      "Epoch 1834/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7885 - val_loss: 0.4916 - val_accuracy: 0.7581\n",
      "Epoch 1835/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7901 - val_loss: 0.4715 - val_accuracy: 0.7787\n",
      "Epoch 1836/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7897 - val_loss: 0.4840 - val_accuracy: 0.7679\n",
      "Epoch 1837/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4376 - accuracy: 0.7892 - val_loss: 0.4881 - val_accuracy: 0.7643\n",
      "Epoch 1838/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4415 - accuracy: 0.7872 - val_loss: 0.4898 - val_accuracy: 0.7608\n",
      "Epoch 1839/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7867 - val_loss: 0.4702 - val_accuracy: 0.7823\n",
      "Epoch 1840/2000\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.4395 - accuracy: 0.7870 - val_loss: 0.4666 - val_accuracy: 0.7787\n",
      "Epoch 1841/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.7919 - val_loss: 0.4721 - val_accuracy: 0.7751\n",
      "Epoch 1842/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7874 - val_loss: 0.4806 - val_accuracy: 0.7509\n",
      "Epoch 1843/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4354 - accuracy: 0.7899 - val_loss: 0.4712 - val_accuracy: 0.7903\n",
      "Epoch 1844/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4361 - accuracy: 0.7939 - val_loss: 0.4770 - val_accuracy: 0.7778\n",
      "Epoch 1845/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4814 - val_accuracy: 0.7778\n",
      "Epoch 1846/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4374 - accuracy: 0.7890 - val_loss: 0.4835 - val_accuracy: 0.7841\n",
      "Epoch 1847/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7890 - val_loss: 0.4858 - val_accuracy: 0.7769\n",
      "Epoch 1848/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4411 - accuracy: 0.7818 - val_loss: 0.4624 - val_accuracy: 0.7975\n",
      "Epoch 1849/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7897 - val_loss: 0.4611 - val_accuracy: 0.7930\n",
      "Epoch 1850/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7919 - val_loss: 0.4594 - val_accuracy: 0.7948\n",
      "Epoch 1851/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4366 - accuracy: 0.7921 - val_loss: 0.4641 - val_accuracy: 0.7858\n",
      "Epoch 1852/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.7935 - val_loss: 0.4521 - val_accuracy: 0.7939\n",
      "Epoch 1853/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.7930 - val_loss: 0.4537 - val_accuracy: 0.7993\n",
      "Epoch 1854/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7944 - val_loss: 0.4653 - val_accuracy: 0.7814\n",
      "Epoch 1855/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.4602 - val_accuracy: 0.7939\n",
      "Epoch 1856/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7901 - val_loss: 0.4584 - val_accuracy: 0.7948\n",
      "Epoch 1857/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.7903 - val_loss: 0.4608 - val_accuracy: 0.7867\n",
      "Epoch 1858/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4388 - accuracy: 0.7914 - val_loss: 0.4530 - val_accuracy: 0.7894\n",
      "Epoch 1859/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7937 - val_loss: 0.4605 - val_accuracy: 0.7867\n",
      "Epoch 1860/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7926 - val_loss: 0.4487 - val_accuracy: 0.7939\n",
      "Epoch 1861/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.7905 - val_loss: 0.4555 - val_accuracy: 0.7876\n",
      "Epoch 1862/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7861 - val_loss: 0.4536 - val_accuracy: 0.7885\n",
      "Epoch 1863/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7890 - val_loss: 0.4487 - val_accuracy: 0.7903\n",
      "Epoch 1864/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7926 - val_loss: 0.4537 - val_accuracy: 0.7876\n",
      "Epoch 1865/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.7941 - val_loss: 0.4648 - val_accuracy: 0.7885\n",
      "Epoch 1866/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7905 - val_loss: 0.4605 - val_accuracy: 0.7805\n",
      "Epoch 1867/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7935 - val_loss: 0.4531 - val_accuracy: 0.7930\n",
      "Epoch 1868/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7892 - val_loss: 0.4586 - val_accuracy: 0.7814\n",
      "Epoch 1869/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7832 - val_loss: 0.4509 - val_accuracy: 0.7858\n",
      "Epoch 1870/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4533 - accuracy: 0.7796 - val_loss: 0.4615 - val_accuracy: 0.7849\n",
      "Epoch 1871/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7903 - val_loss: 0.4488 - val_accuracy: 0.7912\n",
      "Epoch 1872/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4393 - accuracy: 0.7905 - val_loss: 0.4516 - val_accuracy: 0.7948\n",
      "Epoch 1873/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7908 - val_loss: 0.4506 - val_accuracy: 0.7957\n",
      "Epoch 1874/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7932 - val_loss: 0.4573 - val_accuracy: 0.7841\n",
      "Epoch 1875/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.7926 - val_loss: 0.4572 - val_accuracy: 0.7885\n",
      "Epoch 1876/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4393 - accuracy: 0.7905 - val_loss: 0.4558 - val_accuracy: 0.7832\n",
      "Epoch 1877/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7908 - val_loss: 0.4597 - val_accuracy: 0.7832\n",
      "Epoch 1878/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4394 - accuracy: 0.7923 - val_loss: 0.4639 - val_accuracy: 0.7760\n",
      "Epoch 1879/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7874 - val_loss: 0.4543 - val_accuracy: 0.7894\n",
      "Epoch 1880/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7926 - val_loss: 0.4590 - val_accuracy: 0.7841\n",
      "Epoch 1881/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7890 - val_loss: 0.4516 - val_accuracy: 0.7903\n",
      "Epoch 1882/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7905 - val_loss: 0.4570 - val_accuracy: 0.7858\n",
      "Epoch 1883/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7917 - val_loss: 0.4582 - val_accuracy: 0.7849\n",
      "Epoch 1884/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.7890 - val_loss: 0.4555 - val_accuracy: 0.7814\n",
      "Epoch 1885/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.7932 - val_loss: 0.4597 - val_accuracy: 0.7805\n",
      "Epoch 1886/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7932 - val_loss: 0.4575 - val_accuracy: 0.7885\n",
      "Epoch 1887/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.7926 - val_loss: 0.4541 - val_accuracy: 0.7796\n",
      "Epoch 1888/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7892 - val_loss: 0.4551 - val_accuracy: 0.7921\n",
      "Epoch 1889/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7858 - val_loss: 0.4565 - val_accuracy: 0.7867\n",
      "Epoch 1890/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7843 - val_loss: 0.4647 - val_accuracy: 0.7769\n",
      "Epoch 1891/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4475 - accuracy: 0.7872 - val_loss: 0.4672 - val_accuracy: 0.7769\n",
      "Epoch 1892/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4630 - val_accuracy: 0.7841\n",
      "Epoch 1893/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4446 - accuracy: 0.7914 - val_loss: 0.4600 - val_accuracy: 0.7841\n",
      "Epoch 1894/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.7852 - val_loss: 0.4610 - val_accuracy: 0.7778\n",
      "Epoch 1895/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.7881 - val_loss: 0.4592 - val_accuracy: 0.7841\n",
      "Epoch 1896/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7892 - val_loss: 0.4543 - val_accuracy: 0.7948\n",
      "Epoch 1897/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7867 - val_loss: 0.4492 - val_accuracy: 0.7885\n",
      "Epoch 1898/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7870 - val_loss: 0.4536 - val_accuracy: 0.7939\n",
      "Epoch 1899/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7892 - val_loss: 0.4573 - val_accuracy: 0.7939\n",
      "Epoch 1900/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7888 - val_loss: 0.4628 - val_accuracy: 0.7805\n",
      "Epoch 1901/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.7885 - val_loss: 0.4572 - val_accuracy: 0.7921\n",
      "Epoch 1902/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.7899 - val_loss: 0.4593 - val_accuracy: 0.7867\n",
      "Epoch 1903/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4604 - val_accuracy: 0.7841\n",
      "Epoch 1904/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7926 - val_loss: 0.4526 - val_accuracy: 0.7832\n",
      "Epoch 1905/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7930 - val_loss: 0.4618 - val_accuracy: 0.7841\n",
      "Epoch 1906/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7937 - val_loss: 0.4697 - val_accuracy: 0.7805\n",
      "Epoch 1907/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.7928 - val_loss: 0.4630 - val_accuracy: 0.7841\n",
      "Epoch 1908/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.7928 - val_loss: 0.4726 - val_accuracy: 0.7867\n",
      "Epoch 1909/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.7919 - val_loss: 0.4683 - val_accuracy: 0.7787\n",
      "Epoch 1910/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.7935 - val_loss: 0.4710 - val_accuracy: 0.7823\n",
      "Epoch 1911/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.4676 - val_accuracy: 0.7858\n",
      "Epoch 1912/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7874 - val_loss: 0.4671 - val_accuracy: 0.7832\n",
      "Epoch 1913/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7897 - val_loss: 0.4723 - val_accuracy: 0.7921\n",
      "Epoch 1914/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7885 - val_loss: 0.4899 - val_accuracy: 0.7778\n",
      "Epoch 1915/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7870 - val_loss: 0.4832 - val_accuracy: 0.7832\n",
      "Epoch 1916/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4424 - accuracy: 0.7874 - val_loss: 0.4927 - val_accuracy: 0.7643\n",
      "Epoch 1917/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7870 - val_loss: 0.4822 - val_accuracy: 0.7697\n",
      "Epoch 1918/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4427 - accuracy: 0.7890 - val_loss: 0.4572 - val_accuracy: 0.7912\n",
      "Epoch 1919/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.7908 - val_loss: 0.4617 - val_accuracy: 0.7885\n",
      "Epoch 1920/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4469 - accuracy: 0.7856 - val_loss: 0.4809 - val_accuracy: 0.7787\n",
      "Epoch 1921/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7883 - val_loss: 0.4599 - val_accuracy: 0.7832\n",
      "Epoch 1922/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.7867 - val_loss: 0.4596 - val_accuracy: 0.7858\n",
      "Epoch 1923/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7908 - val_loss: 0.4588 - val_accuracy: 0.7849\n",
      "Epoch 1924/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4425 - accuracy: 0.7892 - val_loss: 0.4578 - val_accuracy: 0.7787\n",
      "Epoch 1925/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4387 - accuracy: 0.7888 - val_loss: 0.4595 - val_accuracy: 0.7823\n",
      "Epoch 1926/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7932 - val_loss: 0.4625 - val_accuracy: 0.7814\n",
      "Epoch 1927/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.4596 - val_accuracy: 0.7778\n",
      "Epoch 1928/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4408 - accuracy: 0.7926 - val_loss: 0.4480 - val_accuracy: 0.7975\n",
      "Epoch 1929/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7923 - val_loss: 0.4522 - val_accuracy: 0.7885\n",
      "Epoch 1930/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7919 - val_loss: 0.4555 - val_accuracy: 0.7903\n",
      "Epoch 1931/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7919 - val_loss: 0.4511 - val_accuracy: 0.7894\n",
      "Epoch 1932/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7912 - val_loss: 0.4534 - val_accuracy: 0.7885\n",
      "Epoch 1933/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.7883 - val_loss: 0.4582 - val_accuracy: 0.7769\n",
      "Epoch 1934/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7905 - val_loss: 0.4529 - val_accuracy: 0.7849\n",
      "Epoch 1935/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4487 - val_accuracy: 0.7849\n",
      "Epoch 1936/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.7910 - val_loss: 0.4551 - val_accuracy: 0.7769\n",
      "Epoch 1937/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7903 - val_loss: 0.4699 - val_accuracy: 0.7697\n",
      "Epoch 1938/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.7892 - val_loss: 0.4673 - val_accuracy: 0.7706\n",
      "Epoch 1939/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4440 - accuracy: 0.7874 - val_loss: 0.4631 - val_accuracy: 0.7706\n",
      "Epoch 1940/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7901 - val_loss: 0.4974 - val_accuracy: 0.7706\n",
      "Epoch 1941/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7921 - val_loss: 0.4627 - val_accuracy: 0.7724\n",
      "Epoch 1942/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.7910 - val_loss: 0.4656 - val_accuracy: 0.7796\n",
      "Epoch 1943/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.7879 - val_loss: 0.4491 - val_accuracy: 0.7796\n",
      "Epoch 1944/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4367 - accuracy: 0.7872 - val_loss: 0.4598 - val_accuracy: 0.7814\n",
      "Epoch 1945/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4393 - accuracy: 0.7879 - val_loss: 0.4655 - val_accuracy: 0.7796\n",
      "Epoch 1946/2000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: 0.4388 - accuracy: 0.7905 - val_loss: 0.4541 - val_accuracy: 0.7823\n",
      "Epoch 1947/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4382 - accuracy: 0.7921 - val_loss: 0.4398 - val_accuracy: 0.7957\n",
      "Epoch 1948/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4440 - accuracy: 0.7858 - val_loss: 0.4417 - val_accuracy: 0.7948\n",
      "Epoch 1949/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4434 - accuracy: 0.7874 - val_loss: 0.4563 - val_accuracy: 0.7876\n",
      "Epoch 1950/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7870 - val_loss: 0.4544 - val_accuracy: 0.7939\n",
      "Epoch 1951/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4651 - val_accuracy: 0.7948\n",
      "Epoch 1952/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4534 - val_accuracy: 0.7957\n",
      "Epoch 1953/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4380 - accuracy: 0.7964 - val_loss: 0.4446 - val_accuracy: 0.7939\n",
      "Epoch 1954/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7901 - val_loss: 0.4472 - val_accuracy: 0.7921\n",
      "Epoch 1955/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.7885 - val_loss: 0.4559 - val_accuracy: 0.7948\n",
      "Epoch 1956/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7863 - val_loss: 0.4480 - val_accuracy: 0.7957\n",
      "Epoch 1957/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7885 - val_loss: 0.4686 - val_accuracy: 0.7787\n",
      "Epoch 1958/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7894 - val_loss: 0.4540 - val_accuracy: 0.7912\n",
      "Epoch 1959/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7921 - val_loss: 0.4531 - val_accuracy: 0.7948\n",
      "Epoch 1960/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4364 - accuracy: 0.7932 - val_loss: 0.4859 - val_accuracy: 0.7715\n",
      "Epoch 1961/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7923 - val_loss: 0.4564 - val_accuracy: 0.7849\n",
      "Epoch 1962/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.7948 - val_loss: 0.4532 - val_accuracy: 0.7921\n",
      "Epoch 1963/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7917 - val_loss: 0.4472 - val_accuracy: 0.7912\n",
      "Epoch 1964/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7923 - val_loss: 0.4462 - val_accuracy: 0.7912\n",
      "Epoch 1965/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.7926 - val_loss: 0.4392 - val_accuracy: 0.7975\n",
      "Epoch 1966/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7939 - val_loss: 0.4474 - val_accuracy: 0.7921\n",
      "Epoch 1967/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7897 - val_loss: 0.4442 - val_accuracy: 0.7921\n",
      "Epoch 1968/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4407 - accuracy: 0.7910 - val_loss: 0.4443 - val_accuracy: 0.7984\n",
      "Epoch 1969/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.4618 - val_accuracy: 0.7841\n",
      "Epoch 1970/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7919 - val_loss: 0.4451 - val_accuracy: 0.7921\n",
      "Epoch 1971/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4371 - accuracy: 0.7921 - val_loss: 0.4474 - val_accuracy: 0.7894\n",
      "Epoch 1972/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7950 - val_loss: 0.4547 - val_accuracy: 0.7984\n",
      "Epoch 1973/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7946 - val_loss: 0.4441 - val_accuracy: 0.7948\n",
      "Epoch 1974/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4365 - accuracy: 0.7919 - val_loss: 0.4462 - val_accuracy: 0.7930\n",
      "Epoch 1975/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4383 - accuracy: 0.7944 - val_loss: 0.4403 - val_accuracy: 0.7903\n",
      "Epoch 1976/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7890 - val_loss: 0.4406 - val_accuracy: 0.7948\n",
      "Epoch 1977/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4413 - val_accuracy: 0.7876\n",
      "Epoch 1978/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.7937 - val_loss: 0.4439 - val_accuracy: 0.7930\n",
      "Epoch 1979/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.7905 - val_loss: 0.4764 - val_accuracy: 0.7921\n",
      "Epoch 1980/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7903 - val_loss: 0.4516 - val_accuracy: 0.7948\n",
      "Epoch 1981/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7894 - val_loss: 0.4453 - val_accuracy: 0.7921\n",
      "Epoch 1982/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7912 - val_loss: 0.4477 - val_accuracy: 0.7885\n",
      "Epoch 1983/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.7897 - val_loss: 0.4433 - val_accuracy: 0.7858\n",
      "Epoch 1984/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7937 - val_loss: 0.4503 - val_accuracy: 0.7858\n",
      "Epoch 1985/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7872 - val_loss: 0.5013 - val_accuracy: 0.7464\n",
      "Epoch 1986/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4574 - accuracy: 0.7820 - val_loss: 0.4608 - val_accuracy: 0.7805\n",
      "Epoch 1987/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7867 - val_loss: 0.4473 - val_accuracy: 0.7921\n",
      "Epoch 1988/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7894 - val_loss: 0.4505 - val_accuracy: 0.7841\n",
      "Epoch 1989/2000\n",
      "70/70 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7903 - val_loss: 0.4528 - val_accuracy: 0.7832\n",
      "Epoch 1990/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7921 - val_loss: 0.4494 - val_accuracy: 0.7823\n",
      "Epoch 1991/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7928 - val_loss: 0.4477 - val_accuracy: 0.7948\n",
      "Epoch 1992/2000\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.7930 - val_loss: 0.4450 - val_accuracy: 0.7849\n",
      "Epoch 1993/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7914 - val_loss: 0.4530 - val_accuracy: 0.7876\n",
      "Epoch 1994/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.7935 - val_loss: 0.4476 - val_accuracy: 0.7903\n",
      "Epoch 1995/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7901 - val_loss: 0.4497 - val_accuracy: 0.7841\n",
      "Epoch 1996/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7910 - val_loss: 0.4516 - val_accuracy: 0.7849\n",
      "Epoch 1997/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7919 - val_loss: 0.4442 - val_accuracy: 0.7939\n",
      "Epoch 1998/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7926 - val_loss: 0.4649 - val_accuracy: 0.7814\n",
      "Epoch 1999/2000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4436 - accuracy: 0.7874 - val_loss: 0.4546 - val_accuracy: 0.7894\n",
      "Epoch 2000/2000\n",
      "70/70 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.4519 - val_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "# ''' Adam Optimizer\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0005, # need fine-tune\n",
    "    beta_1=0.9, # need fine-tune\n",
    "    beta_2=0.999, # need fine-tune\n",
    "    epsilon=1e-07, # need fine-tune\n",
    "    amsgrad=False,\n",
    "    name='Adam'\n",
    ")\n",
    "# '''\n",
    "\n",
    "# Normal Gradient Descent\n",
    "# optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.0005, use_locking=False, name='GradientDescent')\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              # tfa.metrics.F1Score(num_classes=2)用法需要再研究一下\n",
    "    \n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=256).batch(64) # 需要确定是否要用mini-batch 感觉没必要\n",
    "train_dataset = train_dataset.batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((validation_x, validation_y))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "history = model.fit(train_dataset, epochs=2000, validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1[0].plot(history.history['loss'], label=\"Training Loss\")\n",
    "ax1[0].plot(history.history['val_loss'], label=\"Validation Loss\")\n",
    "ax1[1].plot(history.history['accuracy'], label=\"Training Accuracy\")\n",
    "ax1[1].plot(history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
    "ax1[0].set_xlabel('Epoch')\n",
    "ax1[1].set_xlabel('Epoch')\n",
    "ax1[0].set_ylabel('Binary Cross Entropy Loss')\n",
    "ax1[1].set_ylabel('Accuracy')\n",
    "ax1[0].set_title('Learning Curve respected to BCE')\n",
    "ax1[1].set_title('Learning Curve respected to Accuracy')\n",
    "ax1[0].legend()\n",
    "ax1[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 10\n",
      "Epoch 1/500\n",
      "79/79 [==============================] - 2s 6ms/step - loss: 2.2057 - accuracy: 0.9010\n",
      "Epoch 2/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 3.2970 - accuracy: 0.7863\n",
      "Epoch 3/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.9437 - accuracy: 0.7609\n",
      "Epoch 4/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 2.2156 - accuracy: 0.7726\n",
      "Epoch 5/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 2.0397 - accuracy: 0.7352\n",
      "Epoch 6/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.8224 - accuracy: 0.5846\n",
      "Epoch 7/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.1366 - accuracy: 0.5356\n",
      "Epoch 8/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.3122\n",
      "Epoch 9/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.1763 - accuracy: 0.6304\n",
      "Epoch 10/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.4998\n",
      "Epoch 11/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.5022\n",
      "Epoch 12/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6949 - accuracy: 0.5020\n",
      "Epoch 13/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.4996\n",
      "Epoch 14/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7005 - accuracy: 0.4542\n",
      "Epoch 15/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6965 - accuracy: 0.4767\n",
      "Epoch 16/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5030\n",
      "Epoch 17/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.9746 - accuracy: 0.5990\n",
      "Epoch 18/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.0288 - accuracy: 0.4900\n",
      "Epoch 19/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6956 - accuracy: 0.4922\n",
      "Epoch 20/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.4992\n",
      "Epoch 21/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.4898\n",
      "Epoch 22/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7051 - accuracy: 0.4644\n",
      "Epoch 23/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5014\n",
      "Epoch 24/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5205\n",
      "Epoch 25/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7016 - accuracy: 0.5121\n",
      "Epoch 26/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5378\n",
      "Epoch 27/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5502\n",
      "Epoch 28/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.4954\n",
      "Epoch 29/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7368 - accuracy: 0.5968\n",
      "Epoch 30/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.4956\n",
      "Epoch 31/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5090\n",
      "Epoch 32/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5219\n",
      "Epoch 33/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5245\n",
      "Epoch 34/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.5235\n",
      "Epoch 35/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.5227\n",
      "Epoch 36/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.7341 - accuracy: 0.4558\n",
      "Epoch 37/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5193\n",
      "Epoch 38/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5528\n",
      "Epoch 39/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.5335\n",
      "Epoch 40/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5645\n",
      "Epoch 41/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5564\n",
      "Epoch 42/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5635\n",
      "Epoch 43/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6968 - accuracy: 0.5554\n",
      "Epoch 44/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5715\n",
      "Epoch 45/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5573\n",
      "Epoch 46/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.5757\n",
      "Epoch 47/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6571 - accuracy: 0.5767\n",
      "Epoch 48/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.8652 - accuracy: 0.5177\n",
      "Epoch 49/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5281\n",
      "Epoch 50/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5789\n",
      "Epoch 51/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6906 - accuracy: 0.5866\n",
      "Epoch 52/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5910\n",
      "Epoch 53/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5396\n",
      "Epoch 54/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6837 - accuracy: 0.6006\n",
      "Epoch 55/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7036 - accuracy: 0.5233\n",
      "Epoch 56/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.5942\n",
      "Epoch 57/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7229 - accuracy: 0.4956\n",
      "Epoch 58/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7030 - accuracy: 0.5548\n",
      "Epoch 59/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7297 - accuracy: 0.5518\n",
      "Epoch 60/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6977 - accuracy: 0.6002\n",
      "Epoch 61/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6950 - accuracy: 0.5617\n",
      "Epoch 62/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5852\n",
      "Epoch 63/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6817 - accuracy: 0.5950\n",
      "Epoch 64/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6979 - accuracy: 0.5631\n",
      "Epoch 65/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.5824\n",
      "Epoch 66/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6854 - accuracy: 0.5751\n",
      "Epoch 67/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5878\n",
      "Epoch 68/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.5759\n",
      "Epoch 69/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7157 - accuracy: 0.4966\n",
      "Epoch 70/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.6157\n",
      "Epoch 71/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7166 - accuracy: 0.4912\n",
      "Epoch 72/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7268 - accuracy: 0.4685\n",
      "Epoch 73/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6883 - accuracy: 0.6006\n",
      "Epoch 74/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6798 - accuracy: 0.5685\n",
      "Epoch 75/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7224 - accuracy: 0.5135\n",
      "Epoch 76/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5816\n",
      "Epoch 77/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.6043\n",
      "Epoch 78/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.6029\n",
      "Epoch 79/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6826 - accuracy: 0.6063\n",
      "Epoch 80/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.5938\n",
      "Epoch 81/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6810 - accuracy: 0.5984\n",
      "Epoch 82/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.6012\n",
      "Epoch 83/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6778 - accuracy: 0.5984\n",
      "Epoch 84/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.5950\n",
      "Epoch 85/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6745 - accuracy: 0.5976\n",
      "Epoch 86/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6998 - accuracy: 0.5496\n",
      "Epoch 87/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6832 - accuracy: 0.6012\n",
      "Epoch 88/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6956 - accuracy: 0.5478\n",
      "Epoch 89/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.6157\n",
      "Epoch 90/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6808 - accuracy: 0.6099\n",
      "Epoch 91/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5942\n",
      "Epoch 92/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.6141\n",
      "Epoch 93/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.5920\n",
      "Epoch 94/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.5972\n",
      "Epoch 95/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.6018\n",
      "Epoch 96/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.5360\n",
      "Epoch 97/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.6087\n",
      "Epoch 98/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6655 - accuracy: 0.6033\n",
      "Epoch 99/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6857 - accuracy: 0.5593\n",
      "Epoch 100/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.6113\n",
      "Epoch 101/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6571 - accuracy: 0.5960\n",
      "Epoch 102/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6961 - accuracy: 0.6071\n",
      "Epoch 103/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.5615\n",
      "Epoch 104/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6862 - accuracy: 0.5854\n",
      "Epoch 105/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7049 - accuracy: 0.5894\n",
      "Epoch 106/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6845 - accuracy: 0.5739\n",
      "Epoch 107/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.6197\n",
      "Epoch 108/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6691 - accuracy: 0.5621\n",
      "Epoch 109/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6736 - accuracy: 0.6358\n",
      "Epoch 110/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7572 - accuracy: 0.5822\n",
      "Epoch 111/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.5552\n",
      "Epoch 112/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5980\n",
      "Epoch 113/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.6103\n",
      "Epoch 114/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.5958\n",
      "Epoch 115/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.6205\n",
      "Epoch 116/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6975 - accuracy: 0.6308\n",
      "Epoch 117/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.5743\n",
      "Epoch 118/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6989 - accuracy: 0.5912\n",
      "Epoch 119/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5783\n",
      "Epoch 120/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6726 - accuracy: 0.6266\n",
      "Epoch 121/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.6211\n",
      "Epoch 122/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6629 - accuracy: 0.6219\n",
      "Epoch 123/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.6049\n",
      "Epoch 124/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.6103\n",
      "Epoch 125/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6666 - accuracy: 0.6012\n",
      "Epoch 126/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6675 - accuracy: 0.6173\n",
      "Epoch 127/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6743 - accuracy: 0.6169\n",
      "Epoch 128/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.6143\n",
      "Epoch 129/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6466 - accuracy: 0.6213\n",
      "Epoch 130/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6824 - accuracy: 0.6199\n",
      "Epoch 131/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6498 - accuracy: 0.6225\n",
      "Epoch 132/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6764 - accuracy: 0.6384\n",
      "Epoch 133/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6669 - accuracy: 0.6278\n",
      "Epoch 134/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6656 - accuracy: 0.6262\n",
      "Epoch 135/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6633 - accuracy: 0.6314\n",
      "Epoch 136/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6638 - accuracy: 0.6304\n",
      "Epoch 137/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6627 - accuracy: 0.6350\n",
      "Epoch 138/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6628 - accuracy: 0.6314\n",
      "Epoch 139/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6612 - accuracy: 0.6372\n",
      "Epoch 140/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6629 - accuracy: 0.6312\n",
      "Epoch 141/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6604 - accuracy: 0.6364\n",
      "Epoch 142/500\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6605 - accuracy: 0.6332: 0s - loss: 0\n",
      "Epoch 143/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.6380\n",
      "Epoch 144/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6592 - accuracy: 0.6302\n",
      "Epoch 145/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6573 - accuracy: 0.6352\n",
      "Epoch 146/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.6274\n",
      "Epoch 147/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.6376\n",
      "Epoch 148/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6712 - accuracy: 0.6073\n",
      "Epoch 149/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.6260\n",
      "Epoch 150/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6522 - accuracy: 0.6296\n",
      "Epoch 151/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6018\n",
      "Epoch 152/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.6179\n",
      "Epoch 153/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6606 - accuracy: 0.6270\n",
      "Epoch 154/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6581 - accuracy: 0.6442\n",
      "Epoch 155/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6569 - accuracy: 0.6410\n",
      "Epoch 156/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6372 - accuracy: 0.6476\n",
      "Epoch 157/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.6290\n",
      "Epoch 158/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6122 - accuracy: 0.6378\n",
      "Epoch 159/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.6464\n",
      "Epoch 160/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.6410\n",
      "Epoch 161/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.6332\n",
      "Epoch 162/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.6585\n",
      "Epoch 163/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6569 - accuracy: 0.6400\n",
      "Epoch 164/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.6513\n",
      "Epoch 165/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6414\n",
      "Epoch 166/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6732\n",
      "Epoch 167/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.6119\n",
      "Epoch 168/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.7025 - accuracy: 0.6358\n",
      "Epoch 169/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6344\n",
      "Epoch 170/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6780 - accuracy: 0.6109\n",
      "Epoch 171/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6424\n",
      "Epoch 172/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.6428\n",
      "Epoch 173/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.6442\n",
      "Epoch 174/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6454 - accuracy: 0.6499\n",
      "Epoch 175/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6557 - accuracy: 0.6432\n",
      "Epoch 176/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.6434\n",
      "Epoch 177/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6585\n",
      "Epoch 178/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5864 - accuracy: 0.6450\n",
      "Epoch 179/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6993\n",
      "Epoch 180/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.8170 - accuracy: 0.5856\n",
      "Epoch 181/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7358 - accuracy: 0.6045\n",
      "Epoch 182/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.6394\n",
      "Epoch 183/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.6932\n",
      "Epoch 184/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.5727\n",
      "Epoch 185/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5695\n",
      "Epoch 186/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6605 - accuracy: 0.6181\n",
      "Epoch 187/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.6436\n",
      "Epoch 188/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.6233\n",
      "Epoch 189/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6416\n",
      "Epoch 190/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.6613\n",
      "Epoch 191/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5978 - accuracy: 0.6794\n",
      "Epoch 192/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6607 - accuracy: 0.6543\n",
      "Epoch 193/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6479\n",
      "Epoch 194/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6593\n",
      "Epoch 195/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.6645\n",
      "Epoch 196/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.6647\n",
      "Epoch 197/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.6603\n",
      "Epoch 198/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6031 - accuracy: 0.6750\n",
      "Epoch 199/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.6840\n",
      "Epoch 200/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6376\n",
      "Epoch 201/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6676 - accuracy: 0.6489\n",
      "Epoch 202/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.6131\n",
      "Epoch 203/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6573 - accuracy: 0.6477\n",
      "Epoch 204/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6523\n",
      "Epoch 205/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.6543\n",
      "Epoch 206/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6431 - accuracy: 0.6589\n",
      "Epoch 207/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6140 - accuracy: 0.6306\n",
      "Epoch 208/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.6233\n",
      "Epoch 209/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.6485\n",
      "Epoch 210/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6552 - accuracy: 0.6529\n",
      "Epoch 211/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6583\n",
      "Epoch 212/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5937 - accuracy: 0.6609\n",
      "Epoch 213/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6531 - accuracy: 0.6023\n",
      "Epoch 214/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6741 - accuracy: 0.6436\n",
      "Epoch 215/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6009 - accuracy: 0.6091\n",
      "Epoch 216/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6566 - accuracy: 0.6350\n",
      "Epoch 217/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6432 - accuracy: 0.6591\n",
      "Epoch 218/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.5952 - accuracy: 0.6513\n",
      "Epoch 219/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6697\n",
      "Epoch 220/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6052 - accuracy: 0.6987\n",
      "Epoch 221/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.6667\n",
      "Epoch 222/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.6609\n",
      "Epoch 223/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.6555\n",
      "Epoch 224/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6571\n",
      "Epoch 225/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6461 - accuracy: 0.6499\n",
      "Epoch 226/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.6595\n",
      "Epoch 227/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6517\n",
      "Epoch 228/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6353 - accuracy: 0.6561\n",
      "Epoch 229/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6366 - accuracy: 0.6549\n",
      "Epoch 230/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.6547\n",
      "Epoch 231/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6573\n",
      "Epoch 232/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.6523\n",
      "Epoch 233/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.6547\n",
      "Epoch 234/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.6563\n",
      "Epoch 235/500\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.62 - 0s 5ms/step - loss: 0.6370 - accuracy: 0.6525\n",
      "Epoch 236/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.6623\n",
      "Epoch 237/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6547\n",
      "Epoch 238/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.6571\n",
      "Epoch 239/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6541\n",
      "Epoch 240/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6357 - accuracy: 0.6535\n",
      "Epoch 241/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.6559\n",
      "Epoch 242/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6553\n",
      "Epoch 243/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.6591\n",
      "Epoch 244/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6353 - accuracy: 0.6567\n",
      "Epoch 245/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6332 - accuracy: 0.6599\n",
      "Epoch 246/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.6535\n",
      "Epoch 247/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.6573\n",
      "Epoch 248/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6547\n",
      "Epoch 249/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6340 - accuracy: 0.6583\n",
      "Epoch 250/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.6551\n",
      "Epoch 251/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.6593\n",
      "Epoch 252/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.6593\n",
      "Epoch 253/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.6589\n",
      "Epoch 254/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.6527\n",
      "Epoch 255/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.6591\n",
      "Epoch 256/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.6557\n",
      "Epoch 257/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.6591\n",
      "Epoch 258/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.6517\n",
      "Epoch 259/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6575\n",
      "Epoch 260/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6354 - accuracy: 0.6557\n",
      "Epoch 261/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.6545\n",
      "Epoch 262/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.6583\n",
      "Epoch 263/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6553\n",
      "Epoch 264/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.6561\n",
      "Epoch 265/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.6549\n",
      "Epoch 266/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.6515\n",
      "Epoch 267/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.6569\n",
      "Epoch 268/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.6543\n",
      "Epoch 269/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6342 - accuracy: 0.6543\n",
      "Epoch 270/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.6575\n",
      "Epoch 271/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.6533\n",
      "Epoch 272/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6547\n",
      "Epoch 273/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6337 - accuracy: 0.6547\n",
      "Epoch 274/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6352 - accuracy: 0.6527\n",
      "Epoch 275/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.6551\n",
      "Epoch 276/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6525\n",
      "Epoch 277/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6337 - accuracy: 0.6531\n",
      "Epoch 278/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.6543\n",
      "Epoch 279/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.6539\n",
      "Epoch 280/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.6527\n",
      "Epoch 281/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.6539\n",
      "Epoch 282/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.6545\n",
      "Epoch 283/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.6541\n",
      "Epoch 284/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6545\n",
      "Epoch 285/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.6541\n",
      "Epoch 286/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.6547\n",
      "Epoch 287/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.6555\n",
      "Epoch 288/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.6529\n",
      "Epoch 289/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.6426\n",
      "Epoch 290/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.6250\n",
      "Epoch 291/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6513 - accuracy: 0.6340\n",
      "Epoch 292/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6328 - accuracy: 0.6485\n",
      "Epoch 293/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.6539\n",
      "Epoch 294/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6319 - accuracy: 0.6509\n",
      "Epoch 295/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.6547\n",
      "Epoch 296/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.6535\n",
      "Epoch 297/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6294 - accuracy: 0.6537\n",
      "Epoch 298/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.6491\n",
      "Epoch 299/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6290 - accuracy: 0.6517\n",
      "Epoch 300/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.6551\n",
      "Epoch 301/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6275 - accuracy: 0.6549\n",
      "Epoch 302/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6287 - accuracy: 0.6539\n",
      "Epoch 303/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.6579\n",
      "Epoch 304/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.6553\n",
      "Epoch 305/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6292 - accuracy: 0.6495\n",
      "Epoch 306/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6243 - accuracy: 0.6573\n",
      "Epoch 307/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6311 - accuracy: 0.6527\n",
      "Epoch 308/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.6549\n",
      "Epoch 309/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6244 - accuracy: 0.6581\n",
      "Epoch 310/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6242 - accuracy: 0.6557\n",
      "Epoch 311/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.6575\n",
      "Epoch 312/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.6539\n",
      "Epoch 313/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.6579\n",
      "Epoch 314/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.6539\n",
      "Epoch 315/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.6472\n",
      "Epoch 316/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6375 - accuracy: 0.6416\n",
      "Epoch 317/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6310 - accuracy: 0.6470\n",
      "Epoch 318/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.6519\n",
      "Epoch 319/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6217 - accuracy: 0.6569\n",
      "Epoch 320/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 0.6591\n",
      "Epoch 321/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6200 - accuracy: 0.6597\n",
      "Epoch 322/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.6611\n",
      "Epoch 323/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6312 - accuracy: 0.6392\n",
      "Epoch 324/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.6428\n",
      "Epoch 325/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6567\n",
      "Epoch 326/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.6587\n",
      "Epoch 327/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.6525\n",
      "Epoch 328/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6201 - accuracy: 0.6549\n",
      "Epoch 329/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.6470\n",
      "Epoch 330/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.6089\n",
      "Epoch 331/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.6386\n",
      "Epoch 332/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6322 - accuracy: 0.6322\n",
      "Epoch 333/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6148 - accuracy: 0.6573\n",
      "Epoch 334/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.6424\n",
      "Epoch 335/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6354 - accuracy: 0.6368\n",
      "Epoch 336/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6310 - accuracy: 0.6446\n",
      "Epoch 337/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6313 - accuracy: 0.6352\n",
      "Epoch 338/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6176 - accuracy: 0.6523\n",
      "Epoch 339/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6425 - accuracy: 0.6223\n",
      "Epoch 340/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.6328\n",
      "Epoch 341/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.6348\n",
      "Epoch 342/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.6501\n",
      "Epoch 343/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.6499\n",
      "Epoch 344/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.6519\n",
      "Epoch 345/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6266 - accuracy: 0.6450\n",
      "Epoch 346/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6521\n",
      "Epoch 347/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.6583\n",
      "Epoch 348/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.6563\n",
      "Epoch 349/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6223 - accuracy: 0.6583\n",
      "Epoch 350/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.6621\n",
      "Epoch 351/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.6567\n",
      "Epoch 352/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.6551\n",
      "Epoch 353/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6367 - accuracy: 0.6121\n",
      "Epoch 354/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6278 - accuracy: 0.6468\n",
      "Epoch 355/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6158 - accuracy: 0.6545\n",
      "Epoch 356/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.6567\n",
      "Epoch 357/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.6593\n",
      "Epoch 358/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.6141\n",
      "Epoch 359/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6255 - accuracy: 0.6450\n",
      "Epoch 360/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6525\n",
      "Epoch 361/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6203\n",
      "Epoch 362/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.6527\n",
      "Epoch 363/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.6627\n",
      "Epoch 364/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.6531\n",
      "Epoch 365/500\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.6221 - accuracy: 0.6591\n",
      "Epoch 366/500\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.6129 - accuracy: 0.6501\n",
      "Epoch 367/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.6635\n",
      "Epoch 368/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6131 - accuracy: 0.6503\n",
      "Epoch 369/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.6659\n",
      "Epoch 370/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6416 - accuracy: 0.6282\n",
      "Epoch 371/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.6529\n",
      "Epoch 372/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6171 - accuracy: 0.6579\n",
      "Epoch 373/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6118 - accuracy: 0.6577\n",
      "Epoch 374/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.6665\n",
      "Epoch 375/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.6515\n",
      "Epoch 376/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6497\n",
      "Epoch 377/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.5774 - accuracy: 0.6551\n",
      "Epoch 378/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.6384\n",
      "Epoch 379/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.6424\n",
      "Epoch 380/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6311 - accuracy: 0.6314\n",
      "Epoch 381/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6171 - accuracy: 0.6489\n",
      "Epoch 382/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.6569\n",
      "Epoch 383/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6397 - accuracy: 0.6468\n",
      "Epoch 384/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.6567\n",
      "Epoch 385/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6092 - accuracy: 0.6605\n",
      "Epoch 386/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.6625\n",
      "Epoch 387/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6167 - accuracy: 0.6613\n",
      "Epoch 388/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.6657\n",
      "Epoch 389/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6113 - accuracy: 0.6442\n",
      "Epoch 390/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6126 - accuracy: 0.6734\n",
      "Epoch 391/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6292 - accuracy: 0.6432\n",
      "Epoch 392/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.6627\n",
      "Epoch 393/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.5880\n",
      "Epoch 394/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.6372\n",
      "Epoch 395/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5512\n",
      "Epoch 396/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6605 - accuracy: 0.5783\n",
      "Epoch 397/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6416 - accuracy: 0.6571\n",
      "Epoch 398/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.6517\n",
      "Epoch 399/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.6549\n",
      "Epoch 400/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6633\n",
      "Epoch 401/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.6595\n",
      "Epoch 402/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6561\n",
      "Epoch 403/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.6631\n",
      "Epoch 404/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.6589\n",
      "Epoch 405/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6631\n",
      "Epoch 406/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.6597\n",
      "Epoch 407/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6114 - accuracy: 0.6601\n",
      "Epoch 408/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.6615\n",
      "Epoch 409/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.6637\n",
      "Epoch 410/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6625\n",
      "Epoch 411/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.6639\n",
      "Epoch 412/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.6631\n",
      "Epoch 413/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6077 - accuracy: 0.6647\n",
      "Epoch 414/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.6617\n",
      "Epoch 415/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.6653\n",
      "Epoch 416/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6079 - accuracy: 0.6625\n",
      "Epoch 417/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6241 - accuracy: 0.6623\n",
      "Epoch 418/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.6569\n",
      "Epoch 419/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.6352\n",
      "Epoch 420/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.6388\n",
      "Epoch 421/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.5641\n",
      "Epoch 422/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6293 - accuracy: 0.5838\n",
      "Epoch 423/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.6597\n",
      "Epoch 424/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.6703\n",
      "Epoch 425/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6025 - accuracy: 0.6623\n",
      "Epoch 426/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.6625\n",
      "Epoch 427/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.6629\n",
      "Epoch 428/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.6710\n",
      "Epoch 429/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5973 - accuracy: 0.6695\n",
      "Epoch 430/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.6720\n",
      "Epoch 431/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6000 - accuracy: 0.6647\n",
      "Epoch 432/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6710\n",
      "Epoch 433/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.6649\n",
      "Epoch 434/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.6577\n",
      "Epoch 435/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.5892\n",
      "Epoch 436/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6310 - accuracy: 0.6436\n",
      "Epoch 437/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.6689\n",
      "Epoch 438/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.6637\n",
      "Epoch 439/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6597\n",
      "Epoch 440/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.6730\n",
      "Epoch 441/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.6211\n",
      "Epoch 442/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6440\n",
      "Epoch 443/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.6063\n",
      "Epoch 444/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.6452\n",
      "Epoch 445/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6066 - accuracy: 0.6617\n",
      "Epoch 446/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6225 - accuracy: 0.6617\n",
      "Epoch 447/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.6609\n",
      "Epoch 448/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6139 - accuracy: 0.6623\n",
      "Epoch 449/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6104 - accuracy: 0.6533\n",
      "Epoch 450/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6127 - accuracy: 0.6547\n",
      "Epoch 451/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.6595\n",
      "Epoch 452/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.6543\n",
      "Epoch 453/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.6613\n",
      "Epoch 454/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.6607\n",
      "Epoch 455/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6209 - accuracy: 0.6635\n",
      "Epoch 456/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.6659\n",
      "Epoch 457/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.6517\n",
      "Epoch 458/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.6708\n",
      "Epoch 459/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.6633\n",
      "Epoch 460/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6165 - accuracy: 0.6661\n",
      "Epoch 461/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5806 - accuracy: 0.6569\n",
      "Epoch 462/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.6750\n",
      "Epoch 463/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6065 - accuracy: 0.6633\n",
      "Epoch 464/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.6611\n",
      "Epoch 465/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.6671\n",
      "Epoch 466/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5967 - accuracy: 0.6639\n",
      "Epoch 467/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6042 - accuracy: 0.6655\n",
      "Epoch 468/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.6621\n",
      "Epoch 469/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.6599\n",
      "Epoch 470/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.6521\n",
      "Epoch 471/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5947 - accuracy: 0.6752\n",
      "Epoch 472/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5587 - accuracy: 0.6794\n",
      "Epoch 473/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6569\n",
      "Epoch 474/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.6436\n",
      "Epoch 475/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6173 - accuracy: 0.6474\n",
      "Epoch 476/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.6495\n",
      "Epoch 477/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.6766\n",
      "Epoch 478/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6068 - accuracy: 0.6667\n",
      "Epoch 479/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.6577\n",
      "Epoch 480/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.6736\n",
      "Epoch 481/500\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.6326 - accuracy: 0.6436\n",
      "Epoch 482/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6184 - accuracy: 0.6601\n",
      "Epoch 483/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.6623\n",
      "Epoch 484/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6058 - accuracy: 0.6643\n",
      "Epoch 485/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5760 - accuracy: 0.6561\n",
      "Epoch 486/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6200 - accuracy: 0.6243\n",
      "Epoch 487/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.6880\n",
      "Epoch 488/500\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.57 - 0s 5ms/step - loss: 0.6850 - accuracy: 0.6004\n",
      "Epoch 489/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6353 - accuracy: 0.6372\n",
      "Epoch 490/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.6675\n",
      "Epoch 491/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6067 - accuracy: 0.6641\n",
      "Epoch 492/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.6645\n",
      "Epoch 493/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.6615\n",
      "Epoch 494/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6254 - accuracy: 0.6085\n",
      "Epoch 495/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6820 - accuracy: 0.5532\n",
      "Epoch 496/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.6595\n",
      "Epoch 497/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5624 - accuracy: 0.6617\n",
      "Epoch 498/500\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6508 - accuracy: 0.6006\n",
      "Epoch 499/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.6300\n",
      "Epoch 500/500\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6323 - accuracy: 0.6227\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-7493d72e4846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \"\"\"\n\u001b[0;32m-> 1068\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \"\"\"\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1462\u001b[0m                                     pos_label)\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                          str(average_options))\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mujoco/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=207, shuffle=True)\n",
    "metrics = {'F1': f1_score, 'Accuracy': accuracy_score}\n",
    "results = {'predicted':[], 'actual':[]}\n",
    "scores = {'F1': [], 'Accuracy': []}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    # Split the dataset\n",
    "    print(f\"Fold {i+1} of {n_folds}\")\n",
    "    train_x, validation_x = X.loc[train_index], X.loc[test_index]\n",
    "    train_y, validation_y = y[train_index], y[test_index]\n",
    "    \n",
    "    # Prepare the training dataset\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=32).batch(64)\n",
    "\n",
    "    # Prepare the validation dataset\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((validation_x, validation_y))\n",
    "    val_dataset = val_dataset.batch(64)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(4,)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "    ])\n",
    "\n",
    "    # ''' Adam Optimizer\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=0.0005, # need fine-tune\n",
    "        beta_1=0.9, # need fine-tune\n",
    "        beta_2=0.999, # need fine-tune\n",
    "        epsilon=1e-07, # need fine-tune\n",
    "        amsgrad=False,\n",
    "        name='Adam'\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model with the training set\n",
    "    model.fit(train_dataset, epochs=500) # converges at around 500\n",
    "    \n",
    "    predictions = model.predict(validation_x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for metric, fn in metrics.items():\n",
    "        scores[metric].append(fn(validation_y, predictions))\n",
    "        \n",
    "    results['predicted'].extend(predictions)\n",
    "    results['actual'].extend(list(validation_y))\n",
    "        \n",
    "print(f'\\nMetrics averaged over {n_folds} trials:')\n",
    "for metric, result in scores.items():\n",
    "    print(f\"{metric}: {np.mean(result).round(2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-6564e5e324aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wloqZRuQa2xV"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'feature_names_in_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4ac29045a275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Calculate probability for each pixel point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mresultant_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_frogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-4ac29045a275>\u001b[0m in \u001b[0;36mpredict_frogs\u001b[0;34m(predictor_image, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpredictor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Reorder variables to be in same order as model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpredictor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Location of null values so that we can skip them (prediction model will break if nulls are present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnull_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'feature_names_in_'"
     ]
    }
   ],
   "source": [
    "def predict_frogs(predictor_image, model):\n",
    "    \"\"\"Returns a (1, n, m) xarray where each pixel value corresponds to the probability of a frog occurrence.\n",
    "    \n",
    "    Takes in the multi-band image outputted by the `create_predictor_image` function as well as the\n",
    "    trained model and returns the predictions for each pixel value. Firstly, the $x$ and $y$ indexes\n",
    "    in the predictor image are stacked into one multi-index $z=(x, y)$ to produce an $k\\times n$\n",
    "    array, which is the format required to feed into our logistic regression model. Then, the array\n",
    "    is fed into the model, returning the model's predictions for the frog likelihood at each pixel. \n",
    "    The predicted probabilities are then indexed by the same multi-index $z$ as before, which allows \n",
    "    the array to be unstacked and returned as a one-band image, ready for plotting.\n",
    "\n",
    "    Arguments:\n",
    "    predictor_image -- (K, n, m) xarray, where K is the number of predictor variables.\n",
    "    model -- sklearn model with K predictor variables.\n",
    "    \"\"\"\n",
    "    # Stack up pixels so they are in the appropriate format for the model\n",
    "    predictor_image = predictor_image.stack(z=(\"y\", \"x\")).transpose()\n",
    "    # Reorder variables to be in same order as model\n",
    "    predictor_image = predictor_image.sel(band=model.feature_names_in_)\n",
    "    # Location of null values so that we can skip them (prediction model will break if nulls are present)\n",
    "    null_pixels = (np.sum(predictor_image.isnull(), axis=-1) > 0)\n",
    "    # Empty probabilities array\n",
    "    probabilities = np.zeros((len(null_pixels), 2))\n",
    "    # Calculate probability for each non-null pixel point\n",
    "    probabilities[~null_pixels] = model.predict_proba(\n",
    "        predictor_image[~null_pixels]\n",
    "    )\n",
    "    # Set null pixels to a probability of null\n",
    "    probabilities[null_pixels] = np.array([np.nan, np.nan])\n",
    "    # Just take probability of frog (class=1)\n",
    "    probabilities = probabilities[:,1]\n",
    "    # Add the coordinates to the probabilities, saving them in an xarray\n",
    "    resultant_image = xr.DataArray(\n",
    "        data=probabilities,\n",
    "        dims=['z'],\n",
    "        coords=dict(\n",
    "            z=predictor_image.z\n",
    "        )\n",
    "    )\n",
    "    # Unstack the image\n",
    "    resultant_image = resultant_image.unstack()\n",
    "    return resultant_image\n",
    "\n",
    "# Calculate probability for each pixel point \n",
    "resultant_image = predict_frogs(weather_data, full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zblp18BIa6D6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCRy9XHxa-sV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqpK59NHbI4O"
   },
   "source": [
    "To Do Test for Submission"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Level1_Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
